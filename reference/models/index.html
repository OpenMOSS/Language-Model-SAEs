<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://lm-saes.readthedocs.io/reference/models/">
      
      
        <link rel="prev" href="../../style-guide/">
      
      
        <link rel="next" href="../training/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.3">
    
    
      
        <title>Models - Language Model SAEs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:300,300i,400,400i,700,700i%7CIBM+Plex+Mono:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"IBM Plex Sans";--md-code-font:"IBM Plex Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
      <link rel="stylesheet" href="../../assets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Language Model SAEs" class="md-header__button md-logo" aria-label="Language Model SAEs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Language Model SAEs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Models
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/OpenMOSS/Language-Model-SAEs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Language Model SAEs" class="md-nav__button md-logo" aria-label="Language Model SAEs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    Language Model SAEs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/OpenMOSS/Language-Model-SAEs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../train-saes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Train SAEs
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3">
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Sparse Dictionaries
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Sparse Dictionaries
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/sae/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sparse Autoencoder
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/transcoder/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transcoder
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/lorsa/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Low-Rank Sparse Attention
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../analyze-saes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Analyze SAEs
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed-guidelines/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Distributed Guidelines
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Key Concepts
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../style-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Style Guide
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" checked>
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Code Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Code Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseSAEConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;BaseSAEConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.sae_type" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sae_type
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.d_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;d_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.expansion_factor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;expansion_factor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.use_decoder_bias" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;use_decoder_bias
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.act_fn" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;act_fn
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.norm_activation" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;norm_activation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.sparsity_include_decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sparsity_include_decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.top_k" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;top_k
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.use_triton_kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;use_triton_kernel
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sparsity_threshold_for_triton_spmm_kernel
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.jumprelu_threshold_window" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;jumprelu_threshold_window
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.d_sae" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;d_sae
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.associated_hook_points" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;associated_hook_points
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.from_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;from_pretrained
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.SAEConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SAEConfig
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SparseAutoEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;SparseAutoEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.set_decoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_decoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.set_encoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_encoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.standardize_parameters_of_dataset_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;standardize_parameters_of_dataset_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.encode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.decode_coo" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode_coo
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.init_W_D_with_active_subspace" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_W_D_with_active_subspace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.CrossCoderConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CrossCoderConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;CrossCoderConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoderConfig.hook_points" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_points
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CrossCoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;CrossCoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.specs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;specs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.init_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.encode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.decode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.standardize_parameters_of_dataset_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;standardize_parameters_of_dataset_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.compute_training_metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_training_metrics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CLTConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;CLTConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.hook_points_in" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_points_in
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.hook_points_out" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_points_out
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.decode_with_csr" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;decode_with_csr
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.sparsity_threshold_for_csr" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sparsity_threshold_for_csr
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.n_layers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;n_layers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.n_decoders" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;n_decoders
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.associated_hook_points" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;associated_hook_points
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CrossLayerTranscoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;CrossLayerTranscoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.specs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;specs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.init_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.get_decoder_weights" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_decoder_weights
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.encode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.encode_single_layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode_single_layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decoder_bias_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_bias_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.set_encoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_encoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.keep_only_decoders_for_layer_from" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;keep_only_decoders_for_layer_from
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decoder_norm_per_feature" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm_per_feature
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decoder_norm_per_decoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm_per_decoder
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.standardize_parameters_of_dataset_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;standardize_parameters_of_dataset_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.prepare_input" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_input
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.prepare_input_single_layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_input_single_layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.prepare_label" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_label
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.compute_training_metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_training_metrics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.compute_loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_loss
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.LorsaConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LorsaConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;LorsaConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.LorsaConfig.associated_hook_points" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;associated_hook_points
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LowRankSparseAttention
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;LowRankSparseAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.init_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.init_lorsa_with_mhsa" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_lorsa_with_mhsa
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.init_W_D_with_active_subspace_per_head" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_W_D_with_active_subspace_per_head
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.init_W_V_with_active_subspace_per_head" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_W_V_with_active_subspace_per_head
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.decoder_bias_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_bias_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.transform_to_unit_decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transform_to_unit_decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.standardize_parameters_of_dataset_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;standardize_parameters_of_dataset_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.compute_hidden_pre" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_hidden_pre
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.encode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.decode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.set_decoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_decoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.set_encoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_encoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.prepare_input" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_input
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.prepare_label" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_label
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MOLTConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;MOLTConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.hook_point_in" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_point_in
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.hook_point_out" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_point_out
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.rank_counts" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank_counts
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.d_sae" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;d_sae
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.available_ranks" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;available_ranks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.num_rank_types" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;num_rank_types
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.generate_rank_assignments" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;generate_rank_assignments
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.get_local_rank_assignments" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_local_rank_assignments
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MixtureOfLinearTransform
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;MixtureOfLinearTransform">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.set_encoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_encoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.decode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.compute_training_metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_training_metrics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Training
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../activation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Activation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runners/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Runners
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infrastructure/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Infrastructure
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseSAEConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;BaseSAEConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.sae_type" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sae_type
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.d_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;d_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.expansion_factor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;expansion_factor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.use_decoder_bias" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;use_decoder_bias
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.act_fn" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;act_fn
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.norm_activation" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;norm_activation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.sparsity_include_decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sparsity_include_decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.top_k" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;top_k
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.use_triton_kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;use_triton_kernel
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sparsity_threshold_for_triton_spmm_kernel
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.jumprelu_threshold_window" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;jumprelu_threshold_window
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.d_sae" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;d_sae
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.associated_hook_points" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;associated_hook_points
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.BaseSAEConfig.from_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;from_pretrained
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.SAEConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SAEConfig
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SparseAutoEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;SparseAutoEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.set_decoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_decoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.set_encoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_encoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.standardize_parameters_of_dataset_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;standardize_parameters_of_dataset_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.encode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.decode_coo" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode_coo
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.SparseAutoEncoder.init_W_D_with_active_subspace" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_W_D_with_active_subspace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.CrossCoderConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CrossCoderConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;CrossCoderConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoderConfig.hook_points" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_points
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CrossCoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;CrossCoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.specs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;specs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.init_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.encode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.decode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.standardize_parameters_of_dataset_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;standardize_parameters_of_dataset_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.compute_training_metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_training_metrics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossCoder.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CLTConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;CLTConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.hook_points_in" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_points_in
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.hook_points_out" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_points_out
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.decode_with_csr" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;decode_with_csr
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.sparsity_threshold_for_csr" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sparsity_threshold_for_csr
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.n_layers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;n_layers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.n_decoders" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;n_decoders
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CLTConfig.associated_hook_points" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;associated_hook_points
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CrossLayerTranscoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;CrossLayerTranscoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.specs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;specs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.init_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.get_decoder_weights" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_decoder_weights
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.encode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.encode_single_layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode_single_layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decoder_bias_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_bias_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.set_encoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_encoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.keep_only_decoders_for_layer_from" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;keep_only_decoders_for_layer_from
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decoder_norm_per_feature" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm_per_feature
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.decoder_norm_per_decoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm_per_decoder
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.standardize_parameters_of_dataset_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;standardize_parameters_of_dataset_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.prepare_input" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_input
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.prepare_input_single_layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_input_single_layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.prepare_label" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_label
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.compute_training_metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_training_metrics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.compute_loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_loss
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.CrossLayerTranscoder.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.LorsaConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LorsaConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;LorsaConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.LorsaConfig.associated_hook_points" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;associated_hook_points
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LowRankSparseAttention
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;LowRankSparseAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.init_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.init_lorsa_with_mhsa" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_lorsa_with_mhsa
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.init_W_D_with_active_subspace_per_head" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_W_D_with_active_subspace_per_head
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.init_W_V_with_active_subspace_per_head" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;init_W_V_with_active_subspace_per_head
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.decoder_bias_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_bias_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.transform_to_unit_decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transform_to_unit_decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.standardize_parameters_of_dataset_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;standardize_parameters_of_dataset_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.compute_hidden_pre" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_hidden_pre
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.encode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.decode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.set_decoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_decoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.set_encoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_encoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.prepare_input" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_input
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.LowRankSparseAttention.prepare_label" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_label
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MOLTConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;MOLTConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.hook_point_in" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_point_in
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.hook_point_out" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;hook_point_out
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.rank_counts" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank_counts
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.d_sae" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;d_sae
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.available_ranks" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;available_ranks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.num_rank_types" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;num_rank_types
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.generate_rank_assignments" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;generate_rank_assignments
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MOLTConfig.get_local_rank_assignments" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_local_rank_assignments
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MixtureOfLinearTransform
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="&nbsp;MixtureOfLinearTransform">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.dim_maps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;dim_maps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.encoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;encoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.decoder_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decoder_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.set_encoder_to_fixed_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;set_encoder_to_fixed_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.decode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;decode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.compute_training_metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;compute_training_metrics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lm_saes.MixtureOfLinearTransform.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="models">Models</h1>
<p>Sparse dictionary model architectures and their configuration classes.</p>


<div class="doc doc-object doc-class">



<h2 id="lm_saes.BaseSAEConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseSAEConfig</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="lm_saes.config.BaseModelConfig">BaseModelConfig</span></code>, <code><span title="abc.ABC">ABC</span></code></p>

        <p>Base class for SAE configs with common settings that are able to apply to various SAE variants. This class should not be used directly but only as a base config class for other SAE variants like SAEConfig, CrossCoderConfig, etc.</p>

    

        <p>Fields:</p>
        <ul>
            <li>
              <code><span title="lm_saes.abstract_sae.BaseSAEConfig.device">device</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.abstract_sae.BaseSAEConfig.dtype">dtype</span></code>
                (<code><span title="torch.dtype">dtype</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sae_type


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.sae_type)" href="#lm_saes.BaseSAEConfig.sae_type">sae_type</a></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            d_model


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.d_model)" href="#lm_saes.BaseSAEConfig.d_model">d_model</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            expansion_factor


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.expansion_factor)" href="#lm_saes.BaseSAEConfig.expansion_factor">expansion_factor</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_decoder_bias


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.use_decoder_bias)" href="#lm_saes.BaseSAEConfig.use_decoder_bias">use_decoder_bias</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            act_fn


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.act_fn)" href="#lm_saes.BaseSAEConfig.act_fn">act_fn</a></code>
                (<code><span title="typing.Literal">Literal</span>['relu', 'jumprelu', 'topk', 'batchtopk', 'batchlayertopk', 'layertopk']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            norm_activation


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.norm_activation)" href="#lm_saes.BaseSAEConfig.norm_activation">norm_activation</a></code>
                (<code><span title="typing.Literal">Literal</span>['token-wise', 'batch-wise', 'dataset-wise', 'inference']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_include_decoder_norm


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.sparsity_include_decoder_norm)" href="#lm_saes.BaseSAEConfig.sparsity_include_decoder_norm">sparsity_include_decoder_norm</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            top_k


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.top_k)" href="#lm_saes.BaseSAEConfig.top_k">top_k</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_triton_kernel


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.use_triton_kernel)" href="#lm_saes.BaseSAEConfig.use_triton_kernel">use_triton_kernel</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_threshold_for_triton_spmm_kernel


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel)" href="#lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel">sparsity_threshold_for_triton_spmm_kernel</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            jumprelu_threshold_window


  
      pydantic-field
   (lm_saes.abstract_sae.BaseSAEConfig.jumprelu_threshold_window)" href="#lm_saes.BaseSAEConfig.jumprelu_threshold_window">jumprelu_threshold_window</a></code>
                (<code><span title="float">float</span></code>)
            </li>
        </ul>




<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.sae_type" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">sae_type</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">sae_type</span><span class="p">:</span> <span class="n"><span title="str">str</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The type of the sparse dictionary. Must be one of the registered SAE types.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.d_model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">d_model</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">d_model</span><span class="p">:</span> <span class="n"><span title="int">int</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The dimension of the input/label activation space. In common settings where activations come from a transformer, this is the dimension of the model (may also known as hidden_size).</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.expansion_factor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">expansion_factor</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">expansion_factor</span><span class="p">:</span> <span class="n"><span title="float">float</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The expansion factor of the sparse dictionary. The hidden dimension of the sparse dictionary <code>d_sae</code> is <code>d_model * expansion_factor</code>.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.use_decoder_bias" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">use_decoder_bias</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">use_decoder_bias</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">True</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Whether to use a bias term in the decoder. Including bias term may make it easier to train a better sparse dictionary, in exchange for increased architectural complexity.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.act_fn" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">act_fn</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">act_fn</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="s2">"relu"</span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="s2">"jumprelu"</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="s2">"topk"</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="s2">"batchtopk"</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="s2">"batchlayertopk"</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="s2">"layertopk"</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">]</span> <span class="o">=</span> <span class="s2">"relu"</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The activation function to use for the sparse dictionary. Currently supported activation functions are <code>relu</code>, <code>jumprelu</code>, <code>topk</code>, <code>batchtopk</code>, <code>batchlayertopk</code>, and <code>layertopk</code>.</p>
<ul>
<li><code>relu</code>: ReLU activation function. Used in the most vanilla SAE settings.</li>
<li><code>jumprelu</code>: JumpReLU activation function, adding a trainable element-wise threshold that pre-activations must pass to be activated, which is formally defined as :math:<code>f(x) = \max(0, x - \theta)</code> where :math:<code>\theta</code> is the threshold. Proposed in <a href="https://arxiv.org/abs/2407.14435">Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders</a>.</li>
<li><code>topk</code>: TopK activation function. Retains the top K activations per sample, zeroing out the rest. Proposed in <a href="https://openreview.net/forum?id=tcsZt9ZNKD">Scaling and evaluating sparse autoencoders</a>.</li>
<li><code>batchtopk</code>: BatchTopK activation function. Batch TopK relaxes TopK function to batch-level, ing the top <code>k * batch_size</code> activations per batch and zeroing out the rest. This allows more adaptive allocation of latents on each sample. Proposed in <a href="https://arxiv.org/abs/2412.06410">BatchTopK Sparse Autoencoders</a>.</li>
<li><code>batchlayertopk</code>: (For CrossLayerTranscoder only) Extension of BatchTopK to layer-and-batch-aware, retaining the top <code>k * batch_size * n_layers</code> activations per batch and layer and zeroing out the rest.</li>
<li><code>layertopk</code>: (For CrossLayerTranscoder only) Extension of BatchTopK to layer-aware, retaining the top <code>k * n_layers</code> activations per layer and zeroing out the rest. Note that this activation function does not take batch dimension into account.</li>
</ul>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.norm_activation" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">norm_activation</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">norm_activation</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="s2">"token-wise"</span><span class="p">,</span> <span class="s2">"batch-wise"</span><span class="p">,</span> <span class="s2">"dataset-wise"</span><span class="p">,</span> <span class="s2">"inference"</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">]</span> <span class="o">=</span> <span class="s2">"dataset-wise"</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The activation normalization strategy to use for the input/label activations. During call of <code>normalize_activations</code> (which will be called by the Trainer during training), the input/label activations will be normalized to an average norm of :math:<code>\sqrt{d_{model}}</code>. This allows easier hyperparameter (mostly learning rate) transfer between different scale of model activations, since the MSE loss without normalization is proportional to the square of the activation norm.</p>
<p>Different activation normalization strategy determines in what view the norm is <em>averaged</em>, with the following options:
- <code>token-wise</code>: Norm is directly computed for activation from each token. No averaging is performed.
- <code>batch-wise</code>: Norm is computed for each batch, then averaged over the batch dimension.
- <code>dataset-wise</code>: Norm is computed from several samples from the activation. Compared to <code>batch-wise</code>, <code>dataset-wise</code> gives a fixed value of average norm for all activations, preserving the linearity of pre-activation encoding and decoding.
- <code>inference</code>: No normalization is performed. A inference mode is produced after calling <code>standardize_parameters_of_dataset_norm</code> method, which folds the dataset-wise average norm into the weights and biases of the model. Switching to <code>inference</code> mode doesn't affect the encoding and decoding as a whole, that is, the reconstructed activations keep the same as the denormalized reconstructed activations in <code>dataset-wise</code> mode. However, the feature activations will reflect the activation scale. This allows real magnitude of feature activations to present during inference.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.sparsity_include_decoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">sparsity_include_decoder_norm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">sparsity_include_decoder_norm</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">True</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Whether to include the decoder norm term in feature activation gating. If true, the pre-activation hidden states will be scaled by the decoder norm before applying the activation function, and then scale back after the activation function. Formally, considering activation function :math:<code>f(x)</code>, an activation gating function :math:<code>g(x)</code> is defined as :math:<code>g(x) = f(x) / x</code> (element-wise division). When <code>sparsity_include_decoder_norm</code> is True, we replace :math:<code>f(x)</code> with :math:<code>x * g(x * || W_     ext{dec} ||)</code>. This effectively suppresses the training dynamics that model tries to increase the decoder norm in exchange of a smaller feature activation magnitude, resulting in lower sparsity loss (L1 norm).</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.top_k" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">top_k</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">top_k</span><span class="p">:</span> <span class="n"><span title="int">int</span></span> <span class="o">=</span> <span class="mi">50</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The k value to use for the topk family of activation functions. For vanilla TopK, the L0 norm of the feature activations will be exactly equal to <code>top_k</code>.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.use_triton_kernel" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">use_triton_kernel</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">use_triton_kernel</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Whether to use the Triton SpMM kernel for the sparse matrix multiplication. Currently only supported for vanilla SAE.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">sparsity_threshold_for_triton_spmm_kernel</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">sparsity_threshold_for_triton_spmm_kernel</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">0.996</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The sparsity threshold for the Triton SpMM kernel. Only when feature activation sparsity reaches this threshold, the Triton SpMM kernel will be used for the sparse matrix multiplication. This is useful for JumpReLU or TopK with a k annealing schedule, where the sparsity is not guaranteed throughout the training.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.jumprelu_threshold_window" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">jumprelu_threshold_window</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">jumprelu_threshold_window</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">2.0</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The window size for the JumpReLU threshold. When pre-activations are element-wise in the window-neighborhood of the threshold, the threshold will begin to receive gradient. See <a href="https://transformer-circuits.pub/2025/january-update/index.html#DL">Anthropic's Circuits Update - January 2025</a> for more details on how JumpReLU is optimized (where they refer to this window as :math:<code>\epsilon</code>).</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.d_sae" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">d_sae</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">d_sae</span><span class="p">:</span> <span class="n"><span title="int">int</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The hidden dimension of the sparse dictionary. Calculated as <code>d_model * expansion_factor</code>.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.BaseSAEConfig.associated_hook_points" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">associated_hook_points</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">associated_hook_points</span><span class="p">:</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>List of hook points used by the SAE, including all input and label hook points. This is used to retrieve useful data from the input activation source.</p>

    </div>

</div>




<div class="doc doc-object doc-function">


<h3 id="lm_saes.BaseSAEConfig.from_pretrained" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">from_pretrained</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">pretrained_name_or_path</span><span class="p">:</span> <span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Load the config of the sparse dictionary from a pretrained name or path. Config is read from <pretrained_name_or_path>/config.json (for local storage) or <repo_id>/<name>/config.json (for HuggingFace Hub).</name></repo_id></pretrained_name_or_path></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pretrained_name_or_path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The path to the pretrained sparse dictionary.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional keyword arguments to pass to the config constructor.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/abstract_sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="nd">@classmethod</span>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="k">def</span><span class="w"> </span><span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_name_or_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="w">    </span><span class="sd">"""Load the config of the sparse dictionary from a pretrained name or path. Config is read from &lt;pretrained_name_or_path&gt;/config.json (for local storage) or &lt;repo_id&gt;/&lt;name&gt;/config.json (for HuggingFace Hub).</span>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">    Args:</span>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">        pretrained_name_or_path (str): The path to the pretrained sparse dictionary.</span>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">        **kwargs: Additional keyword arguments to pass to the config constructor.</span>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">    """</span>
</span><span id="__span-0-159"><a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="n">sae_type</span> <span class="o">=</span> <span class="n">auto_infer_pretrained_sae_type</span><span class="p">(</span><span class="n">pretrained_name_or_path</span><span class="p">)</span>
</span><span id="__span-0-160"><a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="k">if</span> <span class="n">sae_type</span> <span class="o">==</span> <span class="n">PretrainedSAEType</span><span class="o">.</span><span class="n">LOCAL</span><span class="p">:</span>
</span><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_name_or_path</span><span class="p">,</span> <span class="s2">"config.json"</span><span class="p">)</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a>    <span class="k">elif</span> <span class="n">sae_type</span> <span class="o">==</span> <span class="n">PretrainedSAEType</span><span class="o">.</span><span class="n">HUGGINGFACE</span><span class="p">:</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a>        <span class="n">repo_id</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">pretrained_name_or_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">":"</span><span class="p">)</span>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a>        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">hf_hub_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">/config.json"</span><span class="p">),</span> <span class="s2">"config.json"</span><span class="p">)</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="k">elif</span> <span class="n">sae_type</span> <span class="o">==</span> <span class="n">PretrainedSAEType</span><span class="o">.</span><span class="n">SAELENS</span><span class="p">:</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>            <span class="s2">"Currently not support directly generating config from SAELens. Try converting the whole model from SAELens through `from_saelens` or `from_pretrained` method instead."</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a>        <span class="p">)</span>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unsupported pretrained type: </span><span class="si">{</span><span class="n">sae_type</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="n">sae_config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="k">if</span> <span class="bp">cls</span> <span class="ow">is</span> <span class="n">BaseSAEConfig</span><span class="p">:</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="bp">cls</span> <span class="o">=</span> <span class="n">SAE_TYPE_TO_CONFIG_CLASS</span><span class="p">[</span><span class="n">sae_config</span><span class="p">[</span><span class="s2">"sae_type"</span><span class="p">]]</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">model_validate</span><span class="p">({</span><span class="o">**</span><span class="n">sae_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">})</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.SAEConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SAEConfig</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            BaseSAEConfig


  
      pydantic-model
   (lm_saes.abstract_sae.BaseSAEConfig)" href="#lm_saes.BaseSAEConfig">BaseSAEConfig</a></code></p>

    

        <p>Fields:</p>
        <ul>
            <li>
              <code><span title="lm_saes.sae.SAEConfig.device">device</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.sae.SAEConfig.dtype">dtype</span></code>
                (<code><span title="torch.dtype">dtype</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            d_model


  
      pydantic-field
   (lm_saes.sae.SAEConfig.d_model)" href="#lm_saes.BaseSAEConfig.d_model">d_model</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            expansion_factor


  
      pydantic-field
   (lm_saes.sae.SAEConfig.expansion_factor)" href="#lm_saes.BaseSAEConfig.expansion_factor">expansion_factor</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_decoder_bias


  
      pydantic-field
   (lm_saes.sae.SAEConfig.use_decoder_bias)" href="#lm_saes.BaseSAEConfig.use_decoder_bias">use_decoder_bias</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            act_fn


  
      pydantic-field
   (lm_saes.sae.SAEConfig.act_fn)" href="#lm_saes.BaseSAEConfig.act_fn">act_fn</a></code>
                (<code><span title="typing.Literal">Literal</span>['relu', 'jumprelu', 'topk', 'batchtopk', 'batchlayertopk', 'layertopk']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            norm_activation


  
      pydantic-field
   (lm_saes.sae.SAEConfig.norm_activation)" href="#lm_saes.BaseSAEConfig.norm_activation">norm_activation</a></code>
                (<code><span title="typing.Literal">Literal</span>['token-wise', 'batch-wise', 'dataset-wise', 'inference']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_include_decoder_norm


  
      pydantic-field
   (lm_saes.sae.SAEConfig.sparsity_include_decoder_norm)" href="#lm_saes.BaseSAEConfig.sparsity_include_decoder_norm">sparsity_include_decoder_norm</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            top_k


  
      pydantic-field
   (lm_saes.sae.SAEConfig.top_k)" href="#lm_saes.BaseSAEConfig.top_k">top_k</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_triton_kernel


  
      pydantic-field
   (lm_saes.sae.SAEConfig.use_triton_kernel)" href="#lm_saes.BaseSAEConfig.use_triton_kernel">use_triton_kernel</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_threshold_for_triton_spmm_kernel


  
      pydantic-field
   (lm_saes.sae.SAEConfig.sparsity_threshold_for_triton_spmm_kernel)" href="#lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel">sparsity_threshold_for_triton_spmm_kernel</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            jumprelu_threshold_window


  
      pydantic-field
   (lm_saes.sae.SAEConfig.jumprelu_threshold_window)" href="#lm_saes.BaseSAEConfig.jumprelu_threshold_window">jumprelu_threshold_window</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.sae.SAEConfig.sae_type">sae_type</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.sae.SAEConfig.hook_point_in">hook_point_in</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.sae.SAEConfig.hook_point_out">hook_point_out</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.sae.SAEConfig.use_glu_encoder">use_glu_encoder</span></code>
                (<code><span title="bool">bool</span></code>)
            </li>
        </ul>




<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.SparseAutoEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SparseAutoEncoder</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">SparseAutoEncoder</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">cfg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            SAEConfig


  
      pydantic-model
   (lm_saes.sae.SAEConfig)" href="#lm_saes.SAEConfig">SAEConfig</a></span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n"><span title="torch.distributed.DeviceMesh">DeviceMesh</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="lm_saes.abstract_sae.AbstractSparseAutoEncoder">AbstractSparseAutoEncoder</span></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-38"><a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">SAEConfig</span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n">DeviceMesh</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="nb">super</span><span class="p">(</span><span class="n">SparseAutoEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41"></a>
</span><span id="__span-0-42"><a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-43"><a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-44"><a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-45"><a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-46"><a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-47"><a id="__codelineno-0-47" name="__codelineno-0-47"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-48"><a id="__codelineno-0-48" name="__codelineno-0-48"></a>
</span><span id="__span-0-49"><a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_glu_encoder</span><span class="p">:</span>
</span><span id="__span-0-50"><a id="__codelineno-0-50" name="__codelineno-0-50"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">W_E_glu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-51"><a id="__codelineno-0-51" name="__codelineno-0-51"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_E_glu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-52"><a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-53"><a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-54"><a id="__codelineno-0-54" name="__codelineno-0-54"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-55"><a id="__codelineno-0-55" name="__codelineno-0-55"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-56"><a id="__codelineno-0-56" name="__codelineno-0-56"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-57"><a id="__codelineno-0-57" name="__codelineno-0-57"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-58"><a id="__codelineno-0-58" name="__codelineno-0-58"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-59"><a id="__codelineno-0-59" name="__codelineno-0-59"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-60"><a id="__codelineno-0-60" name="__codelineno-0-60"></a>            <span class="p">)</span>
</span><span id="__span-0-61"><a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="p">)</span>
</span><span id="__span-0-62"><a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-63"><a id="__codelineno-0-63" name="__codelineno-0-63"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-64"><a id="__codelineno-0-64" name="__codelineno-0-64"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-65"><a id="__codelineno-0-65" name="__codelineno-0-65"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-66"><a id="__codelineno-0-66" name="__codelineno-0-66"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-67"><a id="__codelineno-0-67" name="__codelineno-0-67"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-68"><a id="__codelineno-0-68" name="__codelineno-0-68"></a>            <span class="p">)</span>
</span><span id="__span-0-69"><a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="p">)</span>
</span><span id="__span-0-70"><a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-71"><a id="__codelineno-0-71" name="__codelineno-0-71"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-72"><a id="__codelineno-0-72" name="__codelineno-0-72"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-73"><a id="__codelineno-0-73" name="__codelineno-0-73"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-74"><a id="__codelineno-0-74" name="__codelineno-0-74"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-75"><a id="__codelineno-0-75" name="__codelineno-0-75"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-76"><a id="__codelineno-0-76" name="__codelineno-0-76"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-77"><a id="__codelineno-0-77" name="__codelineno-0-77"></a>            <span class="p">)</span>
</span><span id="__span-0-78"><a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="p">)</span>
</span><span id="__span-0-79"><a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-80"><a id="__codelineno-0-80" name="__codelineno-0-80"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-81"><a id="__codelineno-0-81" name="__codelineno-0-81"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-82"><a id="__codelineno-0-82" name="__codelineno-0-82"></a>                    <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-83"><a id="__codelineno-0-83" name="__codelineno-0-83"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-84"><a id="__codelineno-0-84" name="__codelineno-0-84"></a>                    <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-85"><a id="__codelineno-0-85" name="__codelineno-0-85"></a>                    <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-86"><a id="__codelineno-0-86" name="__codelineno-0-86"></a>                <span class="p">)</span>
</span><span id="__span-0-87"><a id="__codelineno-0-87" name="__codelineno-0-87"></a>            <span class="p">)</span>
</span><span id="__span-0-88"><a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_glu_encoder</span><span class="p">:</span>
</span><span id="__span-0-89"><a id="__codelineno-0-89" name="__codelineno-0-89"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">W_E_glu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-90"><a id="__codelineno-0-90" name="__codelineno-0-90"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-91"><a id="__codelineno-0-91" name="__codelineno-0-91"></a>                    <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-92"><a id="__codelineno-0-92" name="__codelineno-0-92"></a>                    <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-93"><a id="__codelineno-0-93" name="__codelineno-0-93"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-94"><a id="__codelineno-0-94" name="__codelineno-0-94"></a>                    <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-95"><a id="__codelineno-0-95" name="__codelineno-0-95"></a>                    <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_E_glu"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-96"><a id="__codelineno-0-96" name="__codelineno-0-96"></a>                <span class="p">)</span>
</span><span id="__span-0-97"><a id="__codelineno-0-97" name="__codelineno-0-97"></a>            <span class="p">)</span>
</span><span id="__span-0-98"><a id="__codelineno-0-98" name="__codelineno-0-98"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_E_glu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-99"><a id="__codelineno-0-99" name="__codelineno-0-99"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-100"><a id="__codelineno-0-100" name="__codelineno-0-100"></a>                    <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-101"><a id="__codelineno-0-101" name="__codelineno-0-101"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-102"><a id="__codelineno-0-102" name="__codelineno-0-102"></a>                    <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-103"><a id="__codelineno-0-103" name="__codelineno-0-103"></a>                    <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_E_glu"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-104"><a id="__codelineno-0-104" name="__codelineno-0-104"></a>                <span class="p">)</span>
</span><span id="__span-0-105"><a id="__codelineno-0-105" name="__codelineno-0-105"></a>            <span class="p">)</span>
</span><span id="__span-0-106"><a id="__codelineno-0-106" name="__codelineno-0-106"></a>
</span><span id="__span-0-107"><a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">hook_hidden_pre</span> <span class="o">=</span> <span class="n">HookPoint</span><span class="p">()</span>
</span><span id="__span-0-108"><a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">hook_feature_acts</span> <span class="o">=</span> <span class="n">HookPoint</span><span class="p">()</span>
</span><span id="__span-0-109"><a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">hook_reconstructed</span> <span class="o">=</span> <span class="n">HookPoint</span><span class="p">()</span>
</span></code></pre></div></td></tr></tbody></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.encoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the norm of the encoder weight.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-111"><a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="nd">@override</span>
</span><span id="__span-0-112"><a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="k">def</span><span class="w"> </span><span class="nf">encoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="__span-0-113"><a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="w">    </span><span class="sd">"""Compute the norm of the encoder weight."""</span>
</span><span id="__span-0-114"><a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-115"><a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-116"><a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-117"><a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-118"><a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="k">return</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-119"><a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="o">.</span><span class="n">to_local</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">),</span>
</span><span id="__span-0-120"><a id="__codelineno-0-120" name="__codelineno-0-120"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-121"><a id="__codelineno-0-121" name="__codelineno-0-121"></a>            <span class="n">placements</span><span class="o">=</span><span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">keepdim</span> <span class="k">else</span> <span class="mi">0</span><span class="p">})</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-122"><a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.decoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the norm of the decoder weight.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-124"><a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="nd">@override</span>
</span><span id="__span-0-125"><a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-126"><a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="w">    </span><span class="sd">"""Compute the norm of the decoder weight."""</span>
</span><span id="__span-0-127"><a id="__codelineno-0-127" name="__codelineno-0-127"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-128"><a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-129"><a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-130"><a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-131"><a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="k">return</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-132"><a id="__codelineno-0-132" name="__codelineno-0-132"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">to_local</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">),</span>
</span><span id="__span-0-133"><a id="__codelineno-0-133" name="__codelineno-0-133"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-134"><a id="__codelineno-0-134" name="__codelineno-0-134"></a>            <span class="n">placements</span><span class="o">=</span><span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-135"><a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.set_decoder_to_fixed_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">set_decoder_to_fixed_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">set_decoder_to_fixed_norm</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n"><span title="float">float</span></span><span class="p">,</span> <span class="n">force_exact</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Set the decoder weights to a fixed norm.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="nd">@override</span>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="k">def</span><span class="w"> </span><span class="nf">set_decoder_to_fixed_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">force_exact</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="w">    </span><span class="sd">"""Set the decoder weights to a fixed norm."""</span>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="k">if</span> <span class="n">force_exact</span><span class="p">:</span>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">value</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">value</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="nb">min</span><span class="o">=</span><span class="n">value</span><span class="p">))</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.set_encoder_to_fixed_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">set_encoder_to_fixed_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">set_encoder_to_fixed_norm</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n"><span title="float">float</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Set the encoder weights to a fixed norm.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-160"><a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="k">def</span><span class="w"> </span><span class="nf">set_encoder_to_fixed_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="w">    </span><span class="sd">"""Set the encoder weights to a fixed norm."""</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">value</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.dim_maps" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">dim_maps</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">dim_maps</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="lm_saes.utils.distributed.DimMap">DimMap</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return a dictionary mapping parameter names to dimension maps.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="lm_saes.utils.distributed.DimMap">DimMap</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary mapping parameter names to DimMap objects.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="k">def</span><span class="w"> </span><span class="nf">dim_maps</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DimMap</span><span class="p">]:</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="w">    </span><span class="sd">"""Return a dictionary mapping parameter names to dimension maps.</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">        A dictionary mapping parameter names to DimMap objects.</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    """</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="n">parent_maps</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()</span>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="n">sae_maps</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="s2">"W_E"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="s2">"W_D"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="s2">"b_E"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="p">}</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="n">sae_maps</span><span class="p">[</span><span class="s2">"b_D"</span><span class="p">]</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({})</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_glu_encoder</span><span class="p">:</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="n">sae_maps</span><span class="p">[</span><span class="s2">"W_E_glu"</span><span class="p">]</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a>        <span class="n">sae_maps</span><span class="p">[</span><span class="s2">"b_E_glu"</span><span class="p">]</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">return</span> <span class="n">parent_maps</span> <span class="o">|</span> <span class="n">sae_maps</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.standardize_parameters_of_dataset_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">standardize_parameters_of_dataset_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">standardize_parameters_of_dataset_norm</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Standardize the parameters of the model to account for dataset_norm during inference.
This function should be called during inference by the Initializer.</p>
<p>During training, the activations correspond to an input <code>x</code> where the norm is sqrt(d_model).
However, during inference, the norm of the input <code>x</code> corresponds to the dataset_norm.
To ensure consistency between training and inference, the activations during inference
are scaled by the factor:</p>
<div class="language-text highlight"><pre><span></span><code>scaled_activation = training_activation * (dataset_norm / sqrt(d_model))
</code></pre></div>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dataset_average_activation_norm</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary where keys represent in or out and values
specify the average activation norm of the dataset during inference.</p>
<p>dataset_average_activation_norm = {
    self.cfg.hook_point_in: 1.0,
    self.cfg.hook_point_out: 1.0,
}</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>None</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updates the internal parameters to reflect the standardized activations and change the norm_activation to "inference" mode.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="k">def</span><span class="w"> </span><span class="nf">standardize_parameters_of_dataset_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># should be overridden by subclasses due to side effects</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="w">    </span><span class="sd">"""</span>
</span><span id="__span-0-192"><a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">    Standardize the parameters of the model to account for dataset_norm during inference.</span>
</span><span id="__span-0-193"><a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">    This function should be called during inference by the Initializer.</span>
</span><span id="__span-0-194"><a id="__codelineno-0-194" name="__codelineno-0-194"></a>
</span><span id="__span-0-195"><a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">    During training, the activations correspond to an input `x` where the norm is sqrt(d_model).</span>
</span><span id="__span-0-196"><a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">    However, during inference, the norm of the input `x` corresponds to the dataset_norm.</span>
</span><span id="__span-0-197"><a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">    To ensure consistency between training and inference, the activations during inference</span>
</span><span id="__span-0-198"><a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">    are scaled by the factor:</span>
</span><span id="__span-0-199"><a id="__codelineno-0-199" name="__codelineno-0-199"></a>
</span><span id="__span-0-200"><a id="__codelineno-0-200" name="__codelineno-0-200"></a><span class="sd">        scaled_activation = training_activation * (dataset_norm / sqrt(d_model))</span>
</span><span id="__span-0-201"><a id="__codelineno-0-201" name="__codelineno-0-201"></a>
</span><span id="__span-0-202"><a id="__codelineno-0-202" name="__codelineno-0-202"></a><span class="sd">    Args:</span>
</span><span id="__span-0-203"><a id="__codelineno-0-203" name="__codelineno-0-203"></a><span class="sd">        dataset_average_activation_norm (dict[str, float]):</span>
</span><span id="__span-0-204"><a id="__codelineno-0-204" name="__codelineno-0-204"></a><span class="sd">            A dictionary where keys represent in or out and values</span>
</span><span id="__span-0-205"><a id="__codelineno-0-205" name="__codelineno-0-205"></a><span class="sd">            specify the average activation norm of the dataset during inference.</span>
</span><span id="__span-0-206"><a id="__codelineno-0-206" name="__codelineno-0-206"></a>
</span><span id="__span-0-207"><a id="__codelineno-0-207" name="__codelineno-0-207"></a><span class="sd">            dataset_average_activation_norm = {</span>
</span><span id="__span-0-208"><a id="__codelineno-0-208" name="__codelineno-0-208"></a><span class="sd">                self.cfg.hook_point_in: 1.0,</span>
</span><span id="__span-0-209"><a id="__codelineno-0-209" name="__codelineno-0-209"></a><span class="sd">                self.cfg.hook_point_out: 1.0,</span>
</span><span id="__span-0-210"><a id="__codelineno-0-210" name="__codelineno-0-210"></a><span class="sd">            }</span>
</span><span id="__span-0-211"><a id="__codelineno-0-211" name="__codelineno-0-211"></a>
</span><span id="__span-0-212"><a id="__codelineno-0-212" name="__codelineno-0-212"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-213"><a id="__codelineno-0-213" name="__codelineno-0-213"></a><span class="sd">        None: Updates the internal parameters to reflect the standardized activations and change the norm_activation to "inference" mode.</span>
</span><span id="__span-0-214"><a id="__codelineno-0-214" name="__codelineno-0-214"></a><span class="sd">    """</span>
</span><span id="__span-0-215"><a id="__codelineno-0-215" name="__codelineno-0-215"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">norm_activation</span> <span class="o">==</span> <span class="s2">"dataset-wise"</span>
</span><span id="__span-0-216"><a id="__codelineno-0-216" name="__codelineno-0-216"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-217"><a id="__codelineno-0-217" name="__codelineno-0-217"></a>    <span class="n">input_norm_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-218"><a id="__codelineno-0-218" name="__codelineno-0-218"></a>        <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_point_in</span><span class="p">]</span>
</span><span id="__span-0-219"><a id="__codelineno-0-219" name="__codelineno-0-219"></a>    <span class="p">)</span>
</span><span id="__span-0-220"><a id="__codelineno-0-220" name="__codelineno-0-220"></a>    <span class="n">output_norm_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-221"><a id="__codelineno-0-221" name="__codelineno-0-221"></a>        <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_point_out</span><span class="p">]</span>
</span><span id="__span-0-222"><a id="__codelineno-0-222" name="__codelineno-0-222"></a>    <span class="p">)</span>
</span><span id="__span-0-223"><a id="__codelineno-0-223" name="__codelineno-0-223"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">input_norm_factor</span><span class="p">)</span>
</span><span id="__span-0-224"><a id="__codelineno-0-224" name="__codelineno-0-224"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-225"><a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">"Decoder bias should exist if use_decoder_bias is True"</span>
</span><span id="__span-0-226"><a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">output_norm_factor</span><span class="p">)</span>
</span><span id="__span-0-227"><a id="__codelineno-0-227" name="__codelineno-0-227"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">input_norm_factor</span> <span class="o">/</span> <span class="n">output_norm_factor</span><span class="p">)</span>
</span><span id="__span-0-228"><a id="__codelineno-0-228" name="__codelineno-0-228"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">norm_activation</span> <span class="o">=</span> <span class="s2">"inference"</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.encode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encode</span>


</h3>
          <div class="doc-overloads">
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="p">)</span>
</span></code></pre></div><div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">True</span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="p">]</span>
</span></code></pre></div>          </div>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="o">|</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="p">]</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode input tensor through the sparse autoencoder.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_model']</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor of shape (batch, d_model) or (batch, seq_len, d_model)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_hidden_pre</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, also return the pre-activation hidden states</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae'] | <span title="tuple">tuple</span>[<span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae'], <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae']]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If return_hidden_pre is False:
Feature activations tensor of shape (batch, d_sae) or (batch, seq_len, d_sae)</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae'] | <span title="tuple">tuple</span>[<span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae'], <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae']]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If return_hidden_pre is True:
Tuple of (feature_acts, hidden_pre) where both have shape (batch, d_sae) or (batch, seq_len, d_sae)</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-261"><a id="__codelineno-0-261" name="__codelineno-0-261"></a><span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-262"><a id="__codelineno-0-262" name="__codelineno-0-262"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-263"><a id="__codelineno-0-263" name="__codelineno-0-263"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-264"><a id="__codelineno-0-264" name="__codelineno-0-264"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">],</span>
</span><span id="__span-0-265"><a id="__codelineno-0-265" name="__codelineno-0-265"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-266"><a id="__codelineno-0-266" name="__codelineno-0-266"></a>    <span class="p">],</span>
</span><span id="__span-0-267"><a id="__codelineno-0-267" name="__codelineno-0-267"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-268"><a id="__codelineno-0-268" name="__codelineno-0-268"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-269"><a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-270"><a id="__codelineno-0-270" name="__codelineno-0-270"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">],</span>
</span><span id="__span-0-271"><a id="__codelineno-0-271" name="__codelineno-0-271"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-272"><a id="__codelineno-0-272" name="__codelineno-0-272"></a>    <span class="nb">tuple</span><span class="p">[</span>
</span><span id="__span-0-273"><a id="__codelineno-0-273" name="__codelineno-0-273"></a>        <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-274"><a id="__codelineno-0-274" name="__codelineno-0-274"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">],</span>
</span><span id="__span-0-275"><a id="__codelineno-0-275" name="__codelineno-0-275"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-276"><a id="__codelineno-0-276" name="__codelineno-0-276"></a>        <span class="p">],</span>
</span><span id="__span-0-277"><a id="__codelineno-0-277" name="__codelineno-0-277"></a>        <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-278"><a id="__codelineno-0-278" name="__codelineno-0-278"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">],</span>
</span><span id="__span-0-279"><a id="__codelineno-0-279" name="__codelineno-0-279"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-280"><a id="__codelineno-0-280" name="__codelineno-0-280"></a>        <span class="p">],</span>
</span><span id="__span-0-281"><a id="__codelineno-0-281" name="__codelineno-0-281"></a>    <span class="p">],</span>
</span><span id="__span-0-282"><a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="p">]:</span>
</span><span id="__span-0-283"><a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="w">    </span><span class="sd">"""Encode input tensor through the sparse autoencoder.</span>
</span><span id="__span-0-284"><a id="__codelineno-0-284" name="__codelineno-0-284"></a>
</span><span id="__span-0-285"><a id="__codelineno-0-285" name="__codelineno-0-285"></a><span class="sd">    Args:</span>
</span><span id="__span-0-286"><a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">        x: Input tensor of shape (batch, d_model) or (batch, seq_len, d_model)</span>
</span><span id="__span-0-287"><a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">        return_hidden_pre: If True, also return the pre-activation hidden states</span>
</span><span id="__span-0-288"><a id="__codelineno-0-288" name="__codelineno-0-288"></a>
</span><span id="__span-0-289"><a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-290"><a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="sd">        If return_hidden_pre is False:</span>
</span><span id="__span-0-291"><a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="sd">            Feature activations tensor of shape (batch, d_sae) or (batch, seq_len, d_sae)</span>
</span><span id="__span-0-292"><a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">        If return_hidden_pre is True:</span>
</span><span id="__span-0-293"><a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="sd">            Tuple of (feature_acts, hidden_pre) where both have shape (batch, d_sae) or (batch, seq_len, d_sae)</span>
</span><span id="__span-0-294"><a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="sd">    """</span>
</span><span id="__span-0-295"><a id="__codelineno-0-295" name="__codelineno-0-295"></a>    <span class="c1"># Pass through encoder</span>
</span><span id="__span-0-296"><a id="__codelineno-0-296" name="__codelineno-0-296"></a>    <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span>
</span><span id="__span-0-297"><a id="__codelineno-0-297" name="__codelineno-0-297"></a>
</span><span id="__span-0-298"><a id="__codelineno-0-298" name="__codelineno-0-298"></a>    <span class="c1"># Apply GLU if configured</span>
</span><span id="__span-0-299"><a id="__codelineno-0-299" name="__codelineno-0-299"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_glu_encoder</span><span class="p">:</span>
</span><span id="__span-0-300"><a id="__codelineno-0-300" name="__codelineno-0-300"></a>        <span class="n">hidden_pre_glu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_E_glu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_E_glu</span><span class="p">)</span>
</span><span id="__span-0-301"><a id="__codelineno-0-301" name="__codelineno-0-301"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">hidden_pre</span> <span class="o">*</span> <span class="n">hidden_pre_glu</span>
</span><span id="__span-0-302"><a id="__codelineno-0-302" name="__codelineno-0-302"></a>
</span><span id="__span-0-303"><a id="__codelineno-0-303" name="__codelineno-0-303"></a>    <span class="n">hidden_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hook_hidden_pre</span><span class="p">(</span><span class="n">hidden_pre</span><span class="p">)</span>
</span><span id="__span-0-304"><a id="__codelineno-0-304" name="__codelineno-0-304"></a>
</span><span id="__span-0-305"><a id="__codelineno-0-305" name="__codelineno-0-305"></a>    <span class="c1"># Scale feature activations by decoder norm if configured</span>
</span><span id="__span-0-306"><a id="__codelineno-0-306" name="__codelineno-0-306"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_include_decoder_norm</span><span class="p">:</span>
</span><span id="__span-0-307"><a id="__codelineno-0-307" name="__codelineno-0-307"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">hidden_pre</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">()</span>
</span><span id="__span-0-308"><a id="__codelineno-0-308" name="__codelineno-0-308"></a>
</span><span id="__span-0-309"><a id="__codelineno-0-309" name="__codelineno-0-309"></a>    <span class="n">feature_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">(</span><span class="n">hidden_pre</span><span class="p">)</span>
</span><span id="__span-0-310"><a id="__codelineno-0-310" name="__codelineno-0-310"></a>    <span class="n">feature_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hook_feature_acts</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">)</span>
</span><span id="__span-0-311"><a id="__codelineno-0-311" name="__codelineno-0-311"></a>
</span><span id="__span-0-312"><a id="__codelineno-0-312" name="__codelineno-0-312"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_include_decoder_norm</span><span class="p">:</span>
</span><span id="__span-0-313"><a id="__codelineno-0-313" name="__codelineno-0-313"></a>        <span class="n">feature_acts</span> <span class="o">=</span> <span class="n">feature_acts</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">()</span>
</span><span id="__span-0-314"><a id="__codelineno-0-314" name="__codelineno-0-314"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">hidden_pre</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">()</span>
</span><span id="__span-0-315"><a id="__codelineno-0-315" name="__codelineno-0-315"></a>
</span><span id="__span-0-316"><a id="__codelineno-0-316" name="__codelineno-0-316"></a>    <span class="k">if</span> <span class="n">return_hidden_pre</span><span class="p">:</span>
</span><span id="__span-0-317"><a id="__codelineno-0-317" name="__codelineno-0-317"></a>        <span class="k">return</span> <span class="n">feature_acts</span><span class="p">,</span> <span class="n">hidden_pre</span>
</span><span id="__span-0-318"><a id="__codelineno-0-318" name="__codelineno-0-318"></a>    <span class="k">return</span> <span class="n">feature_acts</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.decode_coo" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decode_coo</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decode_coo</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.sparse.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"seq_len d_model"</span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Decode feature activations back to model space using COO format.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-352"><a id="__codelineno-0-352" name="__codelineno-0-352"></a><span class="k">def</span><span class="w"> </span><span class="nf">decode_coo</span><span class="p">(</span>
</span><span id="__span-0-353"><a id="__codelineno-0-353" name="__codelineno-0-353"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-354"><a id="__codelineno-0-354" name="__codelineno-0-354"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-355"><a id="__codelineno-0-355" name="__codelineno-0-355"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"seq_len d_model"</span><span class="p">]:</span>
</span><span id="__span-0-356"><a id="__codelineno-0-356" name="__codelineno-0-356"></a><span class="w">    </span><span class="sd">"""Decode feature activations back to model space using COO format."""</span>
</span><span id="__span-0-357"><a id="__codelineno-0-357" name="__codelineno-0-357"></a>    <span class="n">reconstructed</span> <span class="o">=</span> <span class="n">feature_acts</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-0-358"><a id="__codelineno-0-358" name="__codelineno-0-358"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-359"><a id="__codelineno-0-359" name="__codelineno-0-359"></a>        <span class="n">reconstructed</span> <span class="o">=</span> <span class="n">reconstructed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span>
</span><span id="__span-0-360"><a id="__codelineno-0-360" name="__codelineno-0-360"></a>    <span class="k">return</span> <span class="n">reconstructed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.SparseAutoEncoder.init_W_D_with_active_subspace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">init_W_D_with_active_subspace</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">init_W_D_with_active_subspace</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span> <span class="n">d_active_subspace</span><span class="p">:</span> <span class="n"><span title="int">int</span></span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Initialize W_D with the active subspace.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>batch</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The batch.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>d_active_subspace</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dimension of the active subspace.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/sae.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-423"><a id="__codelineno-0-423" name="__codelineno-0-423"></a><span class="nd">@override</span>
</span><span id="__span-0-424"><a id="__codelineno-0-424" name="__codelineno-0-424"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-425"><a id="__codelineno-0-425" name="__codelineno-0-425"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>
</span><span id="__span-0-426"><a id="__codelineno-0-426" name="__codelineno-0-426"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_W_D_with_active_subspace</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">d_active_subspace</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="__span-0-427"><a id="__codelineno-0-427" name="__codelineno-0-427"></a><span class="w">    </span><span class="sd">"""Initialize W_D with the active subspace.</span>
</span><span id="__span-0-428"><a id="__codelineno-0-428" name="__codelineno-0-428"></a>
</span><span id="__span-0-429"><a id="__codelineno-0-429" name="__codelineno-0-429"></a><span class="sd">    Args:</span>
</span><span id="__span-0-430"><a id="__codelineno-0-430" name="__codelineno-0-430"></a><span class="sd">        batch: The batch.</span>
</span><span id="__span-0-431"><a id="__codelineno-0-431" name="__codelineno-0-431"></a><span class="sd">        d_active_subspace: The dimension of the active subspace.</span>
</span><span id="__span-0-432"><a id="__codelineno-0-432" name="__codelineno-0-432"></a><span class="sd">    """</span>
</span><span id="__span-0-433"><a id="__codelineno-0-433" name="__codelineno-0-433"></a>    <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_label</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="__span-0-434"><a id="__codelineno-0-434" name="__codelineno-0-434"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-435"><a id="__codelineno-0-435" name="__codelineno-0-435"></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">)</span>
</span><span id="__span-0-436"><a id="__codelineno-0-436" name="__codelineno-0-436"></a>        <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">to_local</span><span class="p">()</span>
</span><span id="__span-0-437"><a id="__codelineno-0-437" name="__codelineno-0-437"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">"data"</span><span class="p">),</span> <span class="n">group_src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-438"><a id="__codelineno-0-438" name="__codelineno-0-438"></a>    <span class="n">demeaned_label</span> <span class="o">=</span> <span class="n">label</span> <span class="o">-</span> <span class="n">label</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-439"><a id="__codelineno-0-439" name="__codelineno-0-439"></a>    <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">demeaned_label</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span><span id="__span-0-440"><a id="__codelineno-0-440" name="__codelineno-0-440"></a>    <span class="n">proj_weight</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">d_active_subspace</span><span class="p">]</span>  <span class="c1"># [d_model, d_active_subspace]</span>
</span><span id="__span-0-441"><a id="__codelineno-0-441" name="__codelineno-0-441"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="n">d_active_subspace</span><span class="p">]</span> <span class="o">@</span> <span class="n">proj_weight</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.CrossCoderConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">CrossCoderConfig</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            BaseSAEConfig


  
      pydantic-model
   (lm_saes.abstract_sae.BaseSAEConfig)" href="#lm_saes.BaseSAEConfig">BaseSAEConfig</a></code></p>

    

        <p>Fields:</p>
        <ul>
            <li>
              <code><span title="lm_saes.crosscoder.CrossCoderConfig.device">device</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.crosscoder.CrossCoderConfig.dtype">dtype</span></code>
                (<code><span title="torch.dtype">dtype</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            d_model


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.d_model)" href="#lm_saes.BaseSAEConfig.d_model">d_model</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            expansion_factor


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.expansion_factor)" href="#lm_saes.BaseSAEConfig.expansion_factor">expansion_factor</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_decoder_bias


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.use_decoder_bias)" href="#lm_saes.BaseSAEConfig.use_decoder_bias">use_decoder_bias</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            act_fn


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.act_fn)" href="#lm_saes.BaseSAEConfig.act_fn">act_fn</a></code>
                (<code><span title="typing.Literal">Literal</span>['relu', 'jumprelu', 'topk', 'batchtopk', 'batchlayertopk', 'layertopk']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            norm_activation


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.norm_activation)" href="#lm_saes.BaseSAEConfig.norm_activation">norm_activation</a></code>
                (<code><span title="typing.Literal">Literal</span>['token-wise', 'batch-wise', 'dataset-wise', 'inference']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_include_decoder_norm


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.sparsity_include_decoder_norm)" href="#lm_saes.BaseSAEConfig.sparsity_include_decoder_norm">sparsity_include_decoder_norm</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            top_k


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.top_k)" href="#lm_saes.BaseSAEConfig.top_k">top_k</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_triton_kernel


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.use_triton_kernel)" href="#lm_saes.BaseSAEConfig.use_triton_kernel">use_triton_kernel</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_threshold_for_triton_spmm_kernel


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.sparsity_threshold_for_triton_spmm_kernel)" href="#lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel">sparsity_threshold_for_triton_spmm_kernel</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            jumprelu_threshold_window


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.jumprelu_threshold_window)" href="#lm_saes.BaseSAEConfig.jumprelu_threshold_window">jumprelu_threshold_window</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.crosscoder.CrossCoderConfig.sae_type">sae_type</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            hook_points


  
      pydantic-field
   (lm_saes.crosscoder.CrossCoderConfig.hook_points)" href="#lm_saes.CrossCoderConfig.hook_points">hook_points</a></code>
                (<code><span title="list">list</span>[<span title="str">str</span>]</code>)
            </li>
        </ul>




<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CrossCoderConfig.hook_points" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">hook_points</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">hook_points</span><span class="p">:</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Hook points for each head. Crosscoder reads from these hook points (simultaneously) and writes to the same hook points.</p>

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.CrossCoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">CrossCoder</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">CrossCoder</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">cfg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            CrossCoderConfig


  
      pydantic-model
   (lm_saes.crosscoder.CrossCoderConfig)" href="#lm_saes.CrossCoderConfig">CrossCoderConfig</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">device_mesh</span><span class="p">:</span> <span class="n"><span title="torch.distributed.device_mesh.DeviceMesh">DeviceMesh</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="lm_saes.abstract_sae.AbstractSparseAutoEncoder">AbstractSparseAutoEncoder</span></code></p>



        <p>Sparse AutoEncoder model.</p>
<p>An autoencoder model that learns to compress the input activation tensor into a high-dimensional but sparse feature activation tensor.</p>
<p>Can also act as a transcoder model, which learns to compress the input activation tensor into a feature activation tensor, and then reconstruct a label activation tensor from the feature activation tensor.</p>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-81"><a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">CrossCoderConfig</span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DeviceMesh</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="__span-0-82"><a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="nb">super</span><span class="p">(</span><span class="n">CrossCoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-83"><a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
</span><span id="__span-0-84"><a id="__codelineno-0-84" name="__codelineno-0-84"></a>
</span><span id="__span-0-85"><a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="c1"># Assertions</span>
</span><span id="__span-0-86"><a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="k">assert</span> <span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_include_decoder_norm</span><span class="p">,</span> <span class="s2">"Sparsity should include decoder norm in CrossCoder"</span>
</span><span id="__span-0-87"><a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="k">assert</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">,</span> <span class="s2">"Decoder bias should be used in CrossCoder"</span>
</span><span id="__span-0-88"><a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="k">assert</span> <span class="ow">not</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_triton_kernel</span><span class="p">,</span> <span class="s2">"Triton kernel is not supported in CrossCoder"</span>
</span><span id="__span-0-89"><a id="__codelineno-0-89" name="__codelineno-0-89"></a>
</span><span id="__span-0-90"><a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="c1"># Initialize weights and biases</span>
</span><span id="__span-0-91"><a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-92"><a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-93"><a id="__codelineno-0-93" name="__codelineno-0-93"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-94"><a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="p">)</span>
</span><span id="__span-0-95"><a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-96"><a id="__codelineno-0-96" name="__codelineno-0-96"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-97"><a id="__codelineno-0-97" name="__codelineno-0-97"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-98"><a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="p">)</span>
</span><span id="__span-0-99"><a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-100"><a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-101"><a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-102"><a id="__codelineno-0-102" name="__codelineno-0-102"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-103"><a id="__codelineno-0-103" name="__codelineno-0-103"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span>
</span><span id="__span-0-104"><a id="__codelineno-0-104" name="__codelineno-0-104"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-105"><a id="__codelineno-0-105" name="__codelineno-0-105"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-106"><a id="__codelineno-0-106" name="__codelineno-0-106"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-107"><a id="__codelineno-0-107" name="__codelineno-0-107"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-108"><a id="__codelineno-0-108" name="__codelineno-0-108"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-109"><a id="__codelineno-0-109" name="__codelineno-0-109"></a>            <span class="p">)</span>
</span><span id="__span-0-110"><a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="p">)</span>
</span><span id="__span-0-111"><a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-112"><a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-113"><a id="__codelineno-0-113" name="__codelineno-0-113"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span>
</span><span id="__span-0-114"><a id="__codelineno-0-114" name="__codelineno-0-114"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-115"><a id="__codelineno-0-115" name="__codelineno-0-115"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-116"><a id="__codelineno-0-116" name="__codelineno-0-116"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-117"><a id="__codelineno-0-117" name="__codelineno-0-117"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-118"><a id="__codelineno-0-118" name="__codelineno-0-118"></a>            <span class="p">)</span>
</span><span id="__span-0-119"><a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="p">)</span>
</span><span id="__span-0-120"><a id="__codelineno-0-120" name="__codelineno-0-120"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-121"><a id="__codelineno-0-121" name="__codelineno-0-121"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-122"><a id="__codelineno-0-122" name="__codelineno-0-122"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span>
</span><span id="__span-0-123"><a id="__codelineno-0-123" name="__codelineno-0-123"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-124"><a id="__codelineno-0-124" name="__codelineno-0-124"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-125"><a id="__codelineno-0-125" name="__codelineno-0-125"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-126"><a id="__codelineno-0-126" name="__codelineno-0-126"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-127"><a id="__codelineno-0-127" name="__codelineno-0-127"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-128"><a id="__codelineno-0-128" name="__codelineno-0-128"></a>            <span class="p">)</span>
</span><span id="__span-0-129"><a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="p">)</span>
</span><span id="__span-0-130"><a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-131"><a id="__codelineno-0-131" name="__codelineno-0-131"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-132"><a id="__codelineno-0-132" name="__codelineno-0-132"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span>
</span><span id="__span-0-133"><a id="__codelineno-0-133" name="__codelineno-0-133"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-134"><a id="__codelineno-0-134" name="__codelineno-0-134"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-135"><a id="__codelineno-0-135" name="__codelineno-0-135"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-136"><a id="__codelineno-0-136" name="__codelineno-0-136"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-137"><a id="__codelineno-0-137" name="__codelineno-0-137"></a>            <span class="p">)</span>
</span><span id="__span-0-138"><a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CrossCoder.specs" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">specs</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">specs</span><span class="p">:</span> <span class="n"><span title="type">type</span></span><span class="p">[</span><span class="n"><span title="lm_saes.utils.tensor_specs.TensorSpecs">TensorSpecs</span></span><span class="p">]</span> <span class="o">=</span> <span class="n"><span title="lm_saes.crosscoder.CrossCoderSpecs">CrossCoderSpecs</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Tensor specs for CrossCoder with n_heads dimension.</p>

    </div>

</div>




<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossCoder.init_parameters" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">init_parameters</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">init_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Initialize the weights of the model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-140"><a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-141"><a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-142"><a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="w">    </span><span class="sd">"""Initialize the weights of the model."""</span>
</span><span id="__span-0-143"><a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">init_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="__span-0-144"><a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="c1"># Initialize a single head's weights</span>
</span><span id="__span-0-145"><a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="n">W_E_per_head</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-146"><a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-147"><a id="__codelineno-0-147" name="__codelineno-0-147"></a>    <span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">"encoder_uniform_bound"</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">"encoder_uniform_bound"</span><span class="p">])</span>
</span><span id="__span-0-148"><a id="__codelineno-0-148" name="__codelineno-0-148"></a>    <span class="n">W_D_per_head</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-149"><a id="__codelineno-0-149" name="__codelineno-0-149"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-150"><a id="__codelineno-0-150" name="__codelineno-0-150"></a>    <span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">"decoder_uniform_bound"</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">"decoder_uniform_bound"</span><span class="p">])</span>
</span><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a>    <span class="c1"># Repeat for all heads</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="n">W_E</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">W_E_per_head</span><span class="p">,</span> <span class="s2">"d_model d_sae -&gt; n_heads d_model d_sae"</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="n">W_D</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">W_D_per_head</span><span class="p">,</span> <span class="s2">"d_sae d_model -&gt; n_heads d_sae d_model"</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="n">b_E</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="n">b_D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-159"><a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"init_parameters_distributed"</span><span class="p">):</span>
</span><span id="__span-0-160"><a id="__codelineno-0-160" name="__codelineno-0-160"></a>            <span class="n">W_E_slices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_E"</span><span class="p">]</span><span class="o">.</span><span class="n">local_slices</span><span class="p">(</span>
</span><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a>                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a>            <span class="p">)</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a>            <span class="n">W_D_slices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_D"</span><span class="p">]</span><span class="o">.</span><span class="n">local_slices</span><span class="p">(</span>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a>                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a>            <span class="p">)</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a>            <span class="n">W_E_head_repeats</span> <span class="o">=</span> <span class="n">get_slice_length</span><span class="p">(</span><span class="n">W_E_slices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>            <span class="n">W_D_head_repeats</span> <span class="o">=</span> <span class="n">get_slice_length</span><span class="p">(</span><span class="n">W_D_slices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a>            <span class="n">W_E_local</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a>                <span class="n">W_E_per_head</span><span class="p">[</span><span class="o">*</span><span class="n">W_E_slices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]],</span> <span class="s2">"d_model d_sae -&gt; n_heads d_model d_sae"</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="n">W_E_head_repeats</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a>            <span class="p">)</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a>            <span class="n">W_D_local</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>                <span class="n">W_D_per_head</span><span class="p">[</span><span class="o">*</span><span class="n">W_D_slices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]],</span> <span class="s2">"d_sae d_model -&gt; n_heads d_sae d_model"</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="n">W_D_head_repeats</span>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a>            <span class="p">)</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a>            <span class="n">W_E</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a>                <span class="n">W_E_local</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>            <span class="p">)</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a>            <span class="n">W_D</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a>                <span class="n">W_D_local</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a>            <span class="p">)</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a>            <span class="n">b_E</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-183"><a id="__codelineno-0-183" name="__codelineno-0-183"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-184"><a id="__codelineno-0-184" name="__codelineno-0-184"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a>                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a>            <span class="p">)</span>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a>            <span class="n">b_D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span>
</span><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-192"><a id="__codelineno-0-192" name="__codelineno-0-192"></a>                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-193"><a id="__codelineno-0-193" name="__codelineno-0-193"></a>            <span class="p">)</span>
</span><span id="__span-0-194"><a id="__codelineno-0-194" name="__codelineno-0-194"></a>
</span><span id="__span-0-195"><a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="c1"># Assign to parameters</span>
</span><span id="__span-0-196"><a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_E</span><span class="p">)</span>
</span><span id="__span-0-197"><a id="__codelineno-0-197" name="__codelineno-0-197"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_D</span><span class="p">)</span>
</span><span id="__span-0-198"><a id="__codelineno-0-198" name="__codelineno-0-198"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">b_E</span><span class="p">)</span>
</span><span id="__span-0-199"><a id="__codelineno-0-199" name="__codelineno-0-199"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">b_D</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossCoder.encode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encode</span>


</h3>
          <div class="doc-overloads">
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">no_einsum</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">]</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="p">)</span>
</span></code></pre></div><div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_heads d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">True</span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">no_einsum</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_heads d_sae"</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_heads d_sae"</span><span class="p">]</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="p">]</span>
</span></code></pre></div>          </div>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_heads d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">no_einsum</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_heads d_sae"</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_sae"</span><span class="p">]</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="o">|</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_heads d_sae"</span><span class="p">]</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_heads d_sae"</span><span class="p">]</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="p">]</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode the input tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_heads d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_heads d_model']</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor of shape (..., n_heads, d_model).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_heads d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_heads d_sae'] | <span title="tuple">tuple</span>[<span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_heads d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_heads d_sae'], <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_heads d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_heads d_sae']]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Encoded tensor of shape (..., n_heads, d_sae).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-292"><a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="nd">@override</span>
</span><span id="__span-0-293"><a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"encode"</span><span class="p">)</span>
</span><span id="__span-0-294"><a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-295"><a id="__codelineno-0-295" name="__codelineno-0-295"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-296"><a id="__codelineno-0-296" name="__codelineno-0-296"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-297"><a id="__codelineno-0-297" name="__codelineno-0-297"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_heads d_model"</span><span class="p">],</span>
</span><span id="__span-0-298"><a id="__codelineno-0-298" name="__codelineno-0-298"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_model"</span><span class="p">],</span>
</span><span id="__span-0-299"><a id="__codelineno-0-299" name="__codelineno-0-299"></a>    <span class="p">],</span>
</span><span id="__span-0-300"><a id="__codelineno-0-300" name="__codelineno-0-300"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-301"><a id="__codelineno-0-301" name="__codelineno-0-301"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-302"><a id="__codelineno-0-302" name="__codelineno-0-302"></a>    <span class="n">no_einsum</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-303"><a id="__codelineno-0-303" name="__codelineno-0-303"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-304"><a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-305"><a id="__codelineno-0-305" name="__codelineno-0-305"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-306"><a id="__codelineno-0-306" name="__codelineno-0-306"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-307"><a id="__codelineno-0-307" name="__codelineno-0-307"></a>    <span class="nb">tuple</span><span class="p">[</span>
</span><span id="__span-0-308"><a id="__codelineno-0-308" name="__codelineno-0-308"></a>        <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-309"><a id="__codelineno-0-309" name="__codelineno-0-309"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-310"><a id="__codelineno-0-310" name="__codelineno-0-310"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-311"><a id="__codelineno-0-311" name="__codelineno-0-311"></a>        <span class="p">],</span>
</span><span id="__span-0-312"><a id="__codelineno-0-312" name="__codelineno-0-312"></a>        <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-313"><a id="__codelineno-0-313" name="__codelineno-0-313"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-314"><a id="__codelineno-0-314" name="__codelineno-0-314"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_heads d_sae"</span><span class="p">],</span>
</span><span id="__span-0-315"><a id="__codelineno-0-315" name="__codelineno-0-315"></a>        <span class="p">],</span>
</span><span id="__span-0-316"><a id="__codelineno-0-316" name="__codelineno-0-316"></a>    <span class="p">],</span>
</span><span id="__span-0-317"><a id="__codelineno-0-317" name="__codelineno-0-317"></a><span class="p">]:</span>
</span><span id="__span-0-318"><a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="w">    </span><span class="sd">"""Encode the input tensor.</span>
</span><span id="__span-0-319"><a id="__codelineno-0-319" name="__codelineno-0-319"></a>
</span><span id="__span-0-320"><a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="sd">    Args:</span>
</span><span id="__span-0-321"><a id="__codelineno-0-321" name="__codelineno-0-321"></a><span class="sd">        x: Input tensor of shape (..., n_heads, d_model).</span>
</span><span id="__span-0-322"><a id="__codelineno-0-322" name="__codelineno-0-322"></a>
</span><span id="__span-0-323"><a id="__codelineno-0-323" name="__codelineno-0-323"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-324"><a id="__codelineno-0-324" name="__codelineno-0-324"></a><span class="sd">        Encoded tensor of shape (..., n_heads, d_sae).</span>
</span><span id="__span-0-325"><a id="__codelineno-0-325" name="__codelineno-0-325"></a><span class="sd">    """</span>
</span><span id="__span-0-326"><a id="__codelineno-0-326" name="__codelineno-0-326"></a>    <span class="c1"># Apply encoding per head</span>
</span><span id="__span-0-327"><a id="__codelineno-0-327" name="__codelineno-0-327"></a>    <span class="n">hidden_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_encoding</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">no_einsum</span><span class="o">=</span><span class="n">no_einsum</span><span class="p">)</span>
</span><span id="__span-0-328"><a id="__codelineno-0-328" name="__codelineno-0-328"></a>
</span><span id="__span-0-329"><a id="__codelineno-0-329" name="__codelineno-0-329"></a>    <span class="c1"># Sum across heads and add bias</span>
</span><span id="__span-0-330"><a id="__codelineno-0-330" name="__codelineno-0-330"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hidden_pre</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-331"><a id="__codelineno-0-331" name="__codelineno-0-331"></a>        <span class="n">accumulated_hidden_pre</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hidden_pre</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># "... n_heads d_sae -&gt; ... d_sae"</span>
</span><span id="__span-0-332"><a id="__codelineno-0-332" name="__codelineno-0-332"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-333"><a id="__codelineno-0-333" name="__codelineno-0-333"></a>        <span class="n">accumulated_hidden_pre</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-334"><a id="__codelineno-0-334" name="__codelineno-0-334"></a>            <span class="n">DTensor</span><span class="p">,</span>
</span><span id="__span-0-335"><a id="__codelineno-0-335" name="__codelineno-0-335"></a>            <span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-336"><a id="__codelineno-0-336" name="__codelineno-0-336"></a>                <span class="n">DTensor</span><span class="p">,</span>
</span><span id="__span-0-337"><a id="__codelineno-0-337" name="__codelineno-0-337"></a>                <span class="n">local_map</span><span class="p">(</span>
</span><span id="__span-0-338"><a id="__codelineno-0-338" name="__codelineno-0-338"></a>                    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="__span-0-339"><a id="__codelineno-0-339" name="__codelineno-0-339"></a>                    <span class="nb">list</span><span class="p">(</span><span class="n">hidden_pre</span><span class="o">.</span><span class="n">placements</span><span class="p">),</span>
</span><span id="__span-0-340"><a id="__codelineno-0-340" name="__codelineno-0-340"></a>                <span class="p">)(</span><span class="n">hidden_pre</span><span class="p">),</span>
</span><span id="__span-0-341"><a id="__codelineno-0-341" name="__codelineno-0-341"></a>            <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">),</span>
</span><span id="__span-0-342"><a id="__codelineno-0-342" name="__codelineno-0-342"></a>        <span class="p">)</span>  <span class="c1"># "... n_heads d_sae -&gt; ... d_sae"</span>
</span><span id="__span-0-343"><a id="__codelineno-0-343" name="__codelineno-0-343"></a>
</span><span id="__span-0-344"><a id="__codelineno-0-344" name="__codelineno-0-344"></a>        <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"encode_redistribute_tensor_pre_repeat"</span><span class="p">):</span>
</span><span id="__span-0-345"><a id="__codelineno-0-345" name="__codelineno-0-345"></a>            <span class="n">accumulated_hidden_pre</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"data"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">redistribute</span><span class="p">(</span><span class="n">accumulated_hidden_pre</span><span class="p">)</span>
</span><span id="__span-0-346"><a id="__codelineno-0-346" name="__codelineno-0-346"></a>
</span><span id="__span-0-347"><a id="__codelineno-0-347" name="__codelineno-0-347"></a>    <span class="n">accumulated_hidden_pre</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
</span><span id="__span-0-348"><a id="__codelineno-0-348" name="__codelineno-0-348"></a>        <span class="n">accumulated_hidden_pre</span><span class="p">,</span> <span class="s2">"... d_sae -&gt; ... n_heads d_sae"</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span>
</span><span id="__span-0-349"><a id="__codelineno-0-349" name="__codelineno-0-349"></a>    <span class="p">)</span>
</span><span id="__span-0-350"><a id="__codelineno-0-350" name="__codelineno-0-350"></a>
</span><span id="__span-0-351"><a id="__codelineno-0-351" name="__codelineno-0-351"></a>    <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"encode_redistribute_tensor_post_repeat"</span><span class="p">):</span>
</span><span id="__span-0-352"><a id="__codelineno-0-352" name="__codelineno-0-352"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">accumulated_hidden_pre</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-353"><a id="__codelineno-0-353" name="__codelineno-0-353"></a>            <span class="n">accumulated_hidden_pre</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"data"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"head"</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">redistribute</span><span class="p">(</span>
</span><span id="__span-0-354"><a id="__codelineno-0-354" name="__codelineno-0-354"></a>                <span class="n">accumulated_hidden_pre</span>
</span><span id="__span-0-355"><a id="__codelineno-0-355" name="__codelineno-0-355"></a>            <span class="p">)</span>
</span><span id="__span-0-356"><a id="__codelineno-0-356" name="__codelineno-0-356"></a>
</span><span id="__span-0-357"><a id="__codelineno-0-357" name="__codelineno-0-357"></a>    <span class="c1"># Apply activation function</span>
</span><span id="__span-0-358"><a id="__codelineno-0-358" name="__codelineno-0-358"></a>    <span class="n">feature_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">(</span><span class="n">accumulated_hidden_pre</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">())</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">()</span>
</span><span id="__span-0-359"><a id="__codelineno-0-359" name="__codelineno-0-359"></a>
</span><span id="__span-0-360"><a id="__codelineno-0-360" name="__codelineno-0-360"></a>    <span class="k">if</span> <span class="n">return_hidden_pre</span><span class="p">:</span>
</span><span id="__span-0-361"><a id="__codelineno-0-361" name="__codelineno-0-361"></a>        <span class="k">return</span> <span class="n">feature_acts</span><span class="p">,</span> <span class="n">accumulated_hidden_pre</span>
</span><span id="__span-0-362"><a id="__codelineno-0-362" name="__codelineno-0-362"></a>    <span class="k">return</span> <span class="n">feature_acts</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossCoder.decode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decode</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">no_einsum</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Decode the encoded tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Encoded tensor of shape (n_heads, d_sae).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_model']</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Decoded tensor of shape (n_heads, d_model).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-426"><a id="__codelineno-0-426" name="__codelineno-0-426"></a><span class="nd">@override</span>
</span><span id="__span-0-427"><a id="__codelineno-0-427" name="__codelineno-0-427"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"decode"</span><span class="p">)</span>
</span><span id="__span-0-428"><a id="__codelineno-0-428" name="__codelineno-0-428"></a><span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span>
</span><span id="__span-0-429"><a id="__codelineno-0-429" name="__codelineno-0-429"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-430"><a id="__codelineno-0-430" name="__codelineno-0-430"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-431"><a id="__codelineno-0-431" name="__codelineno-0-431"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">],</span>
</span><span id="__span-0-432"><a id="__codelineno-0-432" name="__codelineno-0-432"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-433"><a id="__codelineno-0-433" name="__codelineno-0-433"></a>    <span class="p">],</span>
</span><span id="__span-0-434"><a id="__codelineno-0-434" name="__codelineno-0-434"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-435"><a id="__codelineno-0-435" name="__codelineno-0-435"></a>    <span class="n">no_einsum</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-436"><a id="__codelineno-0-436" name="__codelineno-0-436"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-437"><a id="__codelineno-0-437" name="__codelineno-0-437"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-438"><a id="__codelineno-0-438" name="__codelineno-0-438"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">],</span>
</span><span id="__span-0-439"><a id="__codelineno-0-439" name="__codelineno-0-439"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-440"><a id="__codelineno-0-440" name="__codelineno-0-440"></a><span class="p">]:</span>  <span class="c1"># may be overridden by subclasses</span>
</span><span id="__span-0-441"><a id="__codelineno-0-441" name="__codelineno-0-441"></a><span class="w">    </span><span class="sd">"""Decode the encoded tensor.</span>
</span><span id="__span-0-442"><a id="__codelineno-0-442" name="__codelineno-0-442"></a>
</span><span id="__span-0-443"><a id="__codelineno-0-443" name="__codelineno-0-443"></a><span class="sd">    Args:</span>
</span><span id="__span-0-444"><a id="__codelineno-0-444" name="__codelineno-0-444"></a><span class="sd">        x: Encoded tensor of shape (n_heads, d_sae).</span>
</span><span id="__span-0-445"><a id="__codelineno-0-445" name="__codelineno-0-445"></a>
</span><span id="__span-0-446"><a id="__codelineno-0-446" name="__codelineno-0-446"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-447"><a id="__codelineno-0-447" name="__codelineno-0-447"></a><span class="sd">        Decoded tensor of shape (n_heads, d_model).</span>
</span><span id="__span-0-448"><a id="__codelineno-0-448" name="__codelineno-0-448"></a><span class="sd">    """</span>
</span><span id="__span-0-449"><a id="__codelineno-0-449" name="__codelineno-0-449"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_decoding</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="n">no_einsum</span><span class="o">=</span><span class="n">no_einsum</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossCoder.decoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Calculate the norm of the decoder weights.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Norm of decoder weights of shape (n_heads, d_sae).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-451"><a id="__codelineno-0-451" name="__codelineno-0-451"></a><span class="nd">@override</span>
</span><span id="__span-0-452"><a id="__codelineno-0-452" name="__codelineno-0-452"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-453"><a id="__codelineno-0-453" name="__codelineno-0-453"></a><span class="w">    </span><span class="sd">"""Calculate the norm of the decoder weights.</span>
</span><span id="__span-0-454"><a id="__codelineno-0-454" name="__codelineno-0-454"></a>
</span><span id="__span-0-455"><a id="__codelineno-0-455" name="__codelineno-0-455"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-456"><a id="__codelineno-0-456" name="__codelineno-0-456"></a><span class="sd">        Norm of decoder weights of shape (n_heads, d_sae).</span>
</span><span id="__span-0-457"><a id="__codelineno-0-457" name="__codelineno-0-457"></a><span class="sd">    """</span>
</span><span id="__span-0-458"><a id="__codelineno-0-458" name="__codelineno-0-458"></a>    <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"decoder_norm_computation"</span><span class="p">):</span>
</span><span id="__span-0-459"><a id="__codelineno-0-459" name="__codelineno-0-459"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-460"><a id="__codelineno-0-460" name="__codelineno-0-460"></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span>
</span><span id="__span-0-461"><a id="__codelineno-0-461" name="__codelineno-0-461"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-462"><a id="__codelineno-0-462" name="__codelineno-0-462"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-463"><a id="__codelineno-0-463" name="__codelineno-0-463"></a>            <span class="k">return</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-464"><a id="__codelineno-0-464" name="__codelineno-0-464"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="o">.</span><span class="n">to_local</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">),</span>
</span><span id="__span-0-465"><a id="__codelineno-0-465" name="__codelineno-0-465"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-466"><a id="__codelineno-0-466" name="__codelineno-0-466"></a>                <span class="n">placements</span><span class="o">=</span><span class="n">DimMap</span><span class="p">({</span><span class="s2">"head"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-467"><a id="__codelineno-0-467" name="__codelineno-0-467"></a>            <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossCoder.encoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Calculate the norm of the encoder weights.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Norm of encoder weights of shape (n_heads, d_sae).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-469"><a id="__codelineno-0-469" name="__codelineno-0-469"></a><span class="nd">@override</span>
</span><span id="__span-0-470"><a id="__codelineno-0-470" name="__codelineno-0-470"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"encoder_norm"</span><span class="p">)</span>
</span><span id="__span-0-471"><a id="__codelineno-0-471" name="__codelineno-0-471"></a><span class="k">def</span><span class="w"> </span><span class="nf">encoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-472"><a id="__codelineno-0-472" name="__codelineno-0-472"></a><span class="w">    </span><span class="sd">"""Calculate the norm of the encoder weights.</span>
</span><span id="__span-0-473"><a id="__codelineno-0-473" name="__codelineno-0-473"></a>
</span><span id="__span-0-474"><a id="__codelineno-0-474" name="__codelineno-0-474"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-475"><a id="__codelineno-0-475" name="__codelineno-0-475"></a><span class="sd">        Norm of encoder weights of shape (n_heads, d_sae).</span>
</span><span id="__span-0-476"><a id="__codelineno-0-476" name="__codelineno-0-476"></a><span class="sd">    """</span>
</span><span id="__span-0-477"><a id="__codelineno-0-477" name="__codelineno-0-477"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossCoder.standardize_parameters_of_dataset_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">standardize_parameters_of_dataset_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">standardize_parameters_of_dataset_norm</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Standardize the parameters of the model to account for dataset_norm during inference.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span>
<span class="normal"><a href="#__codelineno-0-503">503</a></span>
<span class="normal"><a href="#__codelineno-0-504">504</a></span>
<span class="normal"><a href="#__codelineno-0-505">505</a></span>
<span class="normal"><a href="#__codelineno-0-506">506</a></span>
<span class="normal"><a href="#__codelineno-0-507">507</a></span>
<span class="normal"><a href="#__codelineno-0-508">508</a></span>
<span class="normal"><a href="#__codelineno-0-509">509</a></span>
<span class="normal"><a href="#__codelineno-0-510">510</a></span>
<span class="normal"><a href="#__codelineno-0-511">511</a></span>
<span class="normal"><a href="#__codelineno-0-512">512</a></span>
<span class="normal"><a href="#__codelineno-0-513">513</a></span>
<span class="normal"><a href="#__codelineno-0-514">514</a></span>
<span class="normal"><a href="#__codelineno-0-515">515</a></span>
<span class="normal"><a href="#__codelineno-0-516">516</a></span>
<span class="normal"><a href="#__codelineno-0-517">517</a></span>
<span class="normal"><a href="#__codelineno-0-518">518</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-499"><a id="__codelineno-0-499" name="__codelineno-0-499"></a><span class="nd">@override</span>
</span><span id="__span-0-500"><a id="__codelineno-0-500" name="__codelineno-0-500"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"standardize_parameters_of_dataset_norm"</span><span class="p">)</span>
</span><span id="__span-0-501"><a id="__codelineno-0-501" name="__codelineno-0-501"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-502"><a id="__codelineno-0-502" name="__codelineno-0-502"></a><span class="k">def</span><span class="w"> </span><span class="nf">standardize_parameters_of_dataset_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-0-503"><a id="__codelineno-0-503" name="__codelineno-0-503"></a><span class="w">    </span><span class="sd">"""</span>
</span><span id="__span-0-504"><a id="__codelineno-0-504" name="__codelineno-0-504"></a><span class="sd">    Standardize the parameters of the model to account for dataset_norm during inference.</span>
</span><span id="__span-0-505"><a id="__codelineno-0-505" name="__codelineno-0-505"></a><span class="sd">    """</span>
</span><span id="__span-0-506"><a id="__codelineno-0-506" name="__codelineno-0-506"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">norm_activation</span> <span class="o">==</span> <span class="s2">"dataset-wise"</span>
</span><span id="__span-0-507"><a id="__codelineno-0-507" name="__codelineno-0-507"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-508"><a id="__codelineno-0-508" name="__codelineno-0-508"></a>    <span class="n">norm_factors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
</span><span id="__span-0-509"><a id="__codelineno-0-509" name="__codelineno-0-509"></a>        <span class="p">[</span>
</span><span id="__span-0-510"><a id="__codelineno-0-510" name="__codelineno-0-510"></a>            <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span><span class="p">[</span><span class="n">hook_point</span><span class="p">]</span>
</span><span id="__span-0-511"><a id="__codelineno-0-511" name="__codelineno-0-511"></a>            <span class="k">for</span> <span class="n">hook_point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_points</span>
</span><span id="__span-0-512"><a id="__codelineno-0-512" name="__codelineno-0-512"></a>        <span class="p">],</span>
</span><span id="__span-0-513"><a id="__codelineno-0-513" name="__codelineno-0-513"></a>        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-514"><a id="__codelineno-0-514" name="__codelineno-0-514"></a>        <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-0-515"><a id="__codelineno-0-515" name="__codelineno-0-515"></a>    <span class="p">)</span>
</span><span id="__span-0-516"><a id="__codelineno-0-516" name="__codelineno-0-516"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">norm_factors</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-0-517"><a id="__codelineno-0-517" name="__codelineno-0-517"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">norm_factors</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-0-518"><a id="__codelineno-0-518" name="__codelineno-0-518"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">norm_activation</span> <span class="o">=</span> <span class="s2">"inference"</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossCoder.compute_training_metrics" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">compute_training_metrics</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_training_metrics</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">l_rec</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">l0</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">explained_variance</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="float">float</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute per-head training metrics for CrossCoder.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span>
<span class="normal"><a href="#__codelineno-0-645">645</a></span>
<span class="normal"><a href="#__codelineno-0-646">646</a></span>
<span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-617"><a id="__codelineno-0-617" name="__codelineno-0-617"></a><span class="nd">@override</span>
</span><span id="__span-0-618"><a id="__codelineno-0-618" name="__codelineno-0-618"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-619"><a id="__codelineno-0-619" name="__codelineno-0-619"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_training_metrics</span><span class="p">(</span>
</span><span id="__span-0-620"><a id="__codelineno-0-620" name="__codelineno-0-620"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-621"><a id="__codelineno-0-621" name="__codelineno-0-621"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-622"><a id="__codelineno-0-622" name="__codelineno-0-622"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-623"><a id="__codelineno-0-623" name="__codelineno-0-623"></a>    <span class="n">l_rec</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-624"><a id="__codelineno-0-624" name="__codelineno-0-624"></a>    <span class="n">l0</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-625"><a id="__codelineno-0-625" name="__codelineno-0-625"></a>    <span class="n">explained_variance</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-626"><a id="__codelineno-0-626" name="__codelineno-0-626"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-627"><a id="__codelineno-0-627" name="__codelineno-0-627"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-628"><a id="__codelineno-0-628" name="__codelineno-0-628"></a><span class="w">    </span><span class="sd">"""Compute per-head training metrics for CrossCoder."""</span>
</span><span id="__span-0-629"><a id="__codelineno-0-629" name="__codelineno-0-629"></a>    <span class="k">assert</span> <span class="n">explained_variance</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">explained_variance</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_points</span><span class="p">)</span>
</span><span id="__span-0-630"><a id="__codelineno-0-630" name="__codelineno-0-630"></a>    <span class="n">feature_act_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">specs</span><span class="o">.</span><span class="n">feature_acts</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">)</span>
</span><span id="__span-0-631"><a id="__codelineno-0-631" name="__codelineno-0-631"></a>    <span class="n">l0_spec</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">spec</span> <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">feature_act_spec</span> <span class="k">if</span> <span class="n">spec</span> <span class="o">!=</span> <span class="s2">"sae"</span><span class="p">)</span>
</span><span id="__span-0-632"><a id="__codelineno-0-632" name="__codelineno-0-632"></a>    <span class="n">l_rec_spec</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
</span><span id="__span-0-633"><a id="__codelineno-0-633" name="__codelineno-0-633"></a>        <span class="n">spec</span> <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">feature_act_spec</span> <span class="k">if</span> <span class="n">spec</span> <span class="o">!=</span> <span class="s2">"model"</span> <span class="ow">and</span> <span class="n">spec</span> <span class="o">!=</span> <span class="s2">"batch"</span> <span class="ow">and</span> <span class="n">spec</span> <span class="o">!=</span> <span class="s2">"context"</span>
</span><span id="__span-0-634"><a id="__codelineno-0-634" name="__codelineno-0-634"></a>    <span class="p">)</span>
</span><span id="__span-0-635"><a id="__codelineno-0-635" name="__codelineno-0-635"></a>    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="__span-0-636"><a id="__codelineno-0-636" name="__codelineno-0-636"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_points</span><span class="p">):</span>
</span><span id="__span-0-637"><a id="__codelineno-0-637" name="__codelineno-0-637"></a>        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="__span-0-638"><a id="__codelineno-0-638" name="__codelineno-0-638"></a>            <span class="p">{</span>
</span><span id="__span-0-639"><a id="__codelineno-0-639" name="__codelineno-0-639"></a>                <span class="sa">f</span><span class="s2">"crosscoder_metrics/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">/explained_variance"</span><span class="p">:</span> <span class="n">item</span><span class="p">(</span><span class="n">explained_variance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span>
</span><span id="__span-0-640"><a id="__codelineno-0-640" name="__codelineno-0-640"></a>                <span class="sa">f</span><span class="s2">"crosscoder_metrics/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">/l0"</span><span class="p">:</span> <span class="n">item</span><span class="p">(</span><span class="n">l0</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">l0_spec</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"heads"</span><span class="p">),</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span>
</span><span id="__span-0-641"><a id="__codelineno-0-641" name="__codelineno-0-641"></a>                <span class="sa">f</span><span class="s2">"crosscoder_metrics/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">/l_rec"</span><span class="p">:</span> <span class="n">item</span><span class="p">(</span><span class="n">l_rec</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">l_rec_spec</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"heads"</span><span class="p">),</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span>
</span><span id="__span-0-642"><a id="__codelineno-0-642" name="__codelineno-0-642"></a>            <span class="p">}</span>
</span><span id="__span-0-643"><a id="__codelineno-0-643" name="__codelineno-0-643"></a>        <span class="p">)</span>
</span><span id="__span-0-644"><a id="__codelineno-0-644" name="__codelineno-0-644"></a>    <span class="n">indices</span> <span class="o">=</span> <span class="n">feature_acts</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-645"><a id="__codelineno-0-645" name="__codelineno-0-645"></a>    <span class="n">activated_feature_acts</span> <span class="o">=</span> <span class="n">feature_acts</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-646"><a id="__codelineno-0-646" name="__codelineno-0-646"></a>    <span class="n">activated_decoder_norms</span> <span class="o">=</span> <span class="n">full_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">())[:,</span> <span class="n">indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="__span-0-647"><a id="__codelineno-0-647" name="__codelineno-0-647"></a>    <span class="n">mean_decoder_norm_non_activated_in_activated</span> <span class="o">=</span> <span class="n">item</span><span class="p">(</span><span class="n">activated_decoder_norms</span><span class="p">[</span><span class="n">activated_feature_acts</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span><span id="__span-0-648"><a id="__codelineno-0-648" name="__codelineno-0-648"></a>    <span class="n">mean_decoder_norm_activated_in_activated</span> <span class="o">=</span> <span class="n">item</span><span class="p">(</span><span class="n">activated_decoder_norms</span><span class="p">[</span><span class="n">activated_feature_acts</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span><span id="__span-0-649"><a id="__codelineno-0-649" name="__codelineno-0-649"></a>    <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="__span-0-650"><a id="__codelineno-0-650" name="__codelineno-0-650"></a>        <span class="p">{</span>
</span><span id="__span-0-651"><a id="__codelineno-0-651" name="__codelineno-0-651"></a>            <span class="s2">"crosscoder_metrics/mean_decoder_norm_non_activated_in_activated"</span><span class="p">:</span> <span class="n">mean_decoder_norm_non_activated_in_activated</span><span class="p">,</span>
</span><span id="__span-0-652"><a id="__codelineno-0-652" name="__codelineno-0-652"></a>            <span class="s2">"crosscoder_metrics/mean_decoder_norm_activated_in_activated"</span><span class="p">:</span> <span class="n">mean_decoder_norm_activated_in_activated</span><span class="p">,</span>
</span><span id="__span-0-653"><a id="__codelineno-0-653" name="__codelineno-0-653"></a>        <span class="p">}</span>
</span><span id="__span-0-654"><a id="__codelineno-0-654" name="__codelineno-0-654"></a>    <span class="p">)</span>
</span><span id="__span-0-655"><a id="__codelineno-0-655" name="__codelineno-0-655"></a>    <span class="k">return</span> <span class="n">metrics</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossCoder.dim_maps" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">dim_maps</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">dim_maps</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="lm_saes.utils.distributed.DimMap">DimMap</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return a dictionary mapping parameter names to dimension maps.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="lm_saes.utils.distributed.DimMap">DimMap</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary mapping parameter names to DimMap objects.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/crosscoder.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-662"><a id="__codelineno-0-662" name="__codelineno-0-662"></a><span class="k">def</span><span class="w"> </span><span class="nf">dim_maps</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DimMap</span><span class="p">]:</span>
</span><span id="__span-0-663"><a id="__codelineno-0-663" name="__codelineno-0-663"></a><span class="w">    </span><span class="sd">"""Return a dictionary mapping parameter names to dimension maps.</span>
</span><span id="__span-0-664"><a id="__codelineno-0-664" name="__codelineno-0-664"></a>
</span><span id="__span-0-665"><a id="__codelineno-0-665" name="__codelineno-0-665"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-666"><a id="__codelineno-0-666" name="__codelineno-0-666"></a><span class="sd">        A dictionary mapping parameter names to DimMap objects.</span>
</span><span id="__span-0-667"><a id="__codelineno-0-667" name="__codelineno-0-667"></a><span class="sd">    """</span>
</span><span id="__span-0-668"><a id="__codelineno-0-668" name="__codelineno-0-668"></a>    <span class="n">parent_maps</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()</span>
</span><span id="__span-0-669"><a id="__codelineno-0-669" name="__codelineno-0-669"></a>    <span class="n">crosscoder_maps</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-670"><a id="__codelineno-0-670" name="__codelineno-0-670"></a>        <span class="s2">"W_E"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"head"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">:</span> <span class="mi">2</span><span class="p">}),</span>
</span><span id="__span-0-671"><a id="__codelineno-0-671" name="__codelineno-0-671"></a>        <span class="s2">"W_D"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"head"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>
</span><span id="__span-0-672"><a id="__codelineno-0-672" name="__codelineno-0-672"></a>        <span class="s2">"b_E"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"head"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>
</span><span id="__span-0-673"><a id="__codelineno-0-673" name="__codelineno-0-673"></a>        <span class="s2">"b_D"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"head"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-674"><a id="__codelineno-0-674" name="__codelineno-0-674"></a>    <span class="p">}</span>
</span><span id="__span-0-675"><a id="__codelineno-0-675" name="__codelineno-0-675"></a>    <span class="k">return</span> <span class="n">parent_maps</span> <span class="o">|</span> <span class="n">crosscoder_maps</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.CLTConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">CLTConfig</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            BaseSAEConfig


  
      pydantic-model
   (lm_saes.abstract_sae.BaseSAEConfig)" href="#lm_saes.BaseSAEConfig">BaseSAEConfig</a></code></p>

        <p>Configuration for Cross Layer Transcoder (CLT).</p>
<p>A CLT consists of L encoders and L(L+1)/2 decoders where each encoder at layer L
reads from the residual stream at that layer and can decode to layers L through L-1.</p>

    

        <p>Fields:</p>
        <ul>
            <li>
              <code><span title="lm_saes.clt.CLTConfig.device">device</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.clt.CLTConfig.dtype">dtype</span></code>
                (<code><span title="torch.dtype">dtype</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            d_model


  
      pydantic-field
   (lm_saes.clt.CLTConfig.d_model)" href="#lm_saes.BaseSAEConfig.d_model">d_model</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            expansion_factor


  
      pydantic-field
   (lm_saes.clt.CLTConfig.expansion_factor)" href="#lm_saes.BaseSAEConfig.expansion_factor">expansion_factor</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_decoder_bias


  
      pydantic-field
   (lm_saes.clt.CLTConfig.use_decoder_bias)" href="#lm_saes.BaseSAEConfig.use_decoder_bias">use_decoder_bias</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            norm_activation


  
      pydantic-field
   (lm_saes.clt.CLTConfig.norm_activation)" href="#lm_saes.BaseSAEConfig.norm_activation">norm_activation</a></code>
                (<code><span title="typing.Literal">Literal</span>['token-wise', 'batch-wise', 'dataset-wise', 'inference']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_include_decoder_norm


  
      pydantic-field
   (lm_saes.clt.CLTConfig.sparsity_include_decoder_norm)" href="#lm_saes.BaseSAEConfig.sparsity_include_decoder_norm">sparsity_include_decoder_norm</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            top_k


  
      pydantic-field
   (lm_saes.clt.CLTConfig.top_k)" href="#lm_saes.BaseSAEConfig.top_k">top_k</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_triton_kernel


  
      pydantic-field
   (lm_saes.clt.CLTConfig.use_triton_kernel)" href="#lm_saes.BaseSAEConfig.use_triton_kernel">use_triton_kernel</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_threshold_for_triton_spmm_kernel


  
      pydantic-field
   (lm_saes.clt.CLTConfig.sparsity_threshold_for_triton_spmm_kernel)" href="#lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel">sparsity_threshold_for_triton_spmm_kernel</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            jumprelu_threshold_window


  
      pydantic-field
   (lm_saes.clt.CLTConfig.jumprelu_threshold_window)" href="#lm_saes.BaseSAEConfig.jumprelu_threshold_window">jumprelu_threshold_window</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.clt.CLTConfig.sae_type">sae_type</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.clt.CLTConfig.act_fn">act_fn</span></code>
                (<code><span title="typing.Literal">Literal</span>['relu', 'jumprelu', 'topk', 'batchtopk', 'batchlayertopk', 'layertopk']</code>)
            </li>
            <li>
              <code><span title="lm_saes.clt.CLTConfig.init_cross_layer_decoder_all_zero">init_cross_layer_decoder_all_zero</span></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            hook_points_in


  
      pydantic-field
   (lm_saes.clt.CLTConfig.hook_points_in)" href="#lm_saes.CLTConfig.hook_points_in">hook_points_in</a></code>
                (<code><span title="list">list</span>[<span title="str">str</span>]</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            hook_points_out


  
      pydantic-field
   (lm_saes.clt.CLTConfig.hook_points_out)" href="#lm_saes.CLTConfig.hook_points_out">hook_points_out</a></code>
                (<code><span title="list">list</span>[<span title="str">str</span>]</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            decode_with_csr


  
      pydantic-field
   (lm_saes.clt.CLTConfig.decode_with_csr)" href="#lm_saes.CLTConfig.decode_with_csr">decode_with_csr</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_threshold_for_csr


  
      pydantic-field
   (lm_saes.clt.CLTConfig.sparsity_threshold_for_csr)" href="#lm_saes.CLTConfig.sparsity_threshold_for_csr">sparsity_threshold_for_csr</a></code>
                (<code><span title="float">float</span></code>)
            </li>
        </ul>




<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CLTConfig.hook_points_in" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">hook_points_in</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">hook_points_in</span><span class="p">:</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>List of hook points to capture input activations from, one for each layer.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CLTConfig.hook_points_out" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">hook_points_out</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">hook_points_out</span><span class="p">:</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>List of hook points to capture output activations from, one for each layer.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CLTConfig.decode_with_csr" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">decode_with_csr</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">decode_with_csr</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Whether to decode with CSR matrices. If <code>True</code>, will use CSR matrices for decoding. If <code>False</code>, will use dense matrices for decoding.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CLTConfig.sparsity_threshold_for_csr" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">sparsity_threshold_for_csr</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">sparsity_threshold_for_csr</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">0.05</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>The sparsity threshold for the CSR matrices. If the sparsity of the feature activations reaches this threshold, the CSR matrices will be used for decoding. The current conditioning for sparsity is dependent on usage of TopK family of activation functions, so this will not work with other activation functions like <code>relu</code> or <code>jumprelu</code>.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CLTConfig.n_layers" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">n_layers</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">n_layers</span><span class="p">:</span> <span class="n"><span title="int">int</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Number of layers in the CLT.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CLTConfig.n_decoders" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">n_decoders</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">n_decoders</span><span class="p">:</span> <span class="n"><span title="int">int</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Number of decoders in the CLT.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CLTConfig.associated_hook_points" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">associated_hook_points</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">associated_hook_points</span><span class="p">:</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>All hook points used by the CLT.</p>

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.CrossLayerTranscoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">CrossLayerTranscoder</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">CrossLayerTranscoder</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">cfg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            CLTConfig


  
      pydantic-model
   (lm_saes.clt.CLTConfig)" href="#lm_saes.CLTConfig">CLTConfig</a></span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n"><span title="torch.distributed.device_mesh.DeviceMesh">DeviceMesh</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="lm_saes.abstract_sae.AbstractSparseAutoEncoder">AbstractSparseAutoEncoder</span></code></p>



        <p>Cross Layer Transcoder (CLT) implementation.</p>
<p>A CLT has L encoders (one per layer) and L(L+1)/2 decoders arranged in an upper
triangular pattern. Each encoder at layer L reads from the residual stream at that
layer, and features can decode to layers L through L-1.</p>
<p>We store all parameters in the same object and shard
them across GPUs for efficient distributed training.</p>

        <p>Initialize the Cross Layer Transcoder.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>cfg</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="            CLTConfig


  
      pydantic-model
   (lm_saes.clt.CLTConfig)" href="#lm_saes.CLTConfig">CLTConfig</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Configuration for the CLT.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device_mesh</code>
            </td>
            <td>
                  <code><span title="torch.distributed.device_mesh.DeviceMesh">DeviceMesh</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device mesh for distributed training.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-129"><a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">CLTConfig</span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DeviceMesh</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="__span-0-130"><a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="w">    </span><span class="sd">"""Initialize the Cross Layer Transcoder.</span>
</span><span id="__span-0-131"><a id="__codelineno-0-131" name="__codelineno-0-131"></a>
</span><span id="__span-0-132"><a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">    Args:</span>
</span><span id="__span-0-133"><a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">        cfg: Configuration for the CLT.</span>
</span><span id="__span-0-134"><a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">        device_mesh: Device mesh for distributed training.</span>
</span><span id="__span-0-135"><a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">    """</span>
</span><span id="__span-0-136"><a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-137"><a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
</span><span id="__span-0-138"><a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="c1"># CLT requires specific configuration settings</span>
</span><span id="__span-0-139"><a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="c1"># assert not cfg.sparsity_include_decoder_norm, "CLT requires sparsity_include_decoder_norm=False"</span>
</span><span id="__span-0-140"><a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="c1"># assert cfg.use_decoder_bias, "CLT requires use_decoder_bias=True"</span>
</span><span id="__span-0-141"><a id="__codelineno-0-141" name="__codelineno-0-141"></a>
</span><span id="__span-0-142"><a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="c1"># Initialize weights and biases for cross-layer architecture</span>
</span><span id="__span-0-143"><a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-144"><a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="c1"># L encoders: one for each layer</span>
</span><span id="__span-0-145"><a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-146"><a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-147"><a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="p">)</span>
</span><span id="__span-0-148"><a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-149"><a id="__codelineno-0-149" name="__codelineno-0-149"></a>
</span><span id="__span-0-150"><a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="c1"># L decoder groups: W_D[i] contains decoders from layers 0..i to layer i</span>
</span><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="p">[</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a>                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)</span>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a>            <span class="p">]</span>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="p">)</span>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="c1"># L decoder biases: one bias per target layer</span>
</span><span id="__span-0-159"><a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span>
</span><span id="__span-0-160"><a id="__codelineno-0-160" name="__codelineno-0-160"></a>            <span class="p">[</span>
</span><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a>                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a>            <span class="p">]</span>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a>        <span class="p">)</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="c1"># Distributed initialization - shard along feature dimension</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a>            <span class="p">)</span>  <span class="c1"># shard along d_sae</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="p">)</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-183"><a id="__codelineno-0-183" name="__codelineno-0-183"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-184"><a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="p">)</span>  <span class="c1"># shard along d_sae</span>
</span><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="p">)</span>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="c1"># L decoder groups: W_D[i] contains decoders from layers 0..i to layer i</span>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span>
</span><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a>            <span class="p">[</span>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-192"><a id="__codelineno-0-192" name="__codelineno-0-192"></a>                        <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-193"><a id="__codelineno-0-193" name="__codelineno-0-193"></a>                        <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-194"><a id="__codelineno-0-194" name="__codelineno-0-194"></a>                        <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-195"><a id="__codelineno-0-195" name="__codelineno-0-195"></a>                        <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-196"><a id="__codelineno-0-196" name="__codelineno-0-196"></a>                        <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-197"><a id="__codelineno-0-197" name="__codelineno-0-197"></a>                        <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-198"><a id="__codelineno-0-198" name="__codelineno-0-198"></a>                    <span class="p">)</span>
</span><span id="__span-0-199"><a id="__codelineno-0-199" name="__codelineno-0-199"></a>                <span class="p">)</span>  <span class="c1"># shard along d_sae</span>
</span><span id="__span-0-200"><a id="__codelineno-0-200" name="__codelineno-0-200"></a>                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)</span>
</span><span id="__span-0-201"><a id="__codelineno-0-201" name="__codelineno-0-201"></a>            <span class="p">]</span>
</span><span id="__span-0-202"><a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="p">)</span>
</span><span id="__span-0-203"><a id="__codelineno-0-203" name="__codelineno-0-203"></a>
</span><span id="__span-0-204"><a id="__codelineno-0-204" name="__codelineno-0-204"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span>
</span><span id="__span-0-205"><a id="__codelineno-0-205" name="__codelineno-0-205"></a>            <span class="p">[</span>
</span><span id="__span-0-206"><a id="__codelineno-0-206" name="__codelineno-0-206"></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-207"><a id="__codelineno-0-207" name="__codelineno-0-207"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-208"><a id="__codelineno-0-208" name="__codelineno-0-208"></a>                        <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-209"><a id="__codelineno-0-209" name="__codelineno-0-209"></a>                        <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-210"><a id="__codelineno-0-210" name="__codelineno-0-210"></a>                        <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-211"><a id="__codelineno-0-211" name="__codelineno-0-211"></a>                        <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-212"><a id="__codelineno-0-212" name="__codelineno-0-212"></a>                    <span class="p">)</span>
</span><span id="__span-0-213"><a id="__codelineno-0-213" name="__codelineno-0-213"></a>                <span class="p">)</span>
</span><span id="__span-0-214"><a id="__codelineno-0-214" name="__codelineno-0-214"></a>                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)</span>
</span><span id="__span-0-215"><a id="__codelineno-0-215" name="__codelineno-0-215"></a>            <span class="p">]</span>
</span><span id="__span-0-216"><a id="__codelineno-0-216" name="__codelineno-0-216"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.CrossLayerTranscoder.specs" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">specs</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">specs</span><span class="p">:</span> <span class="n"><span title="type">type</span></span><span class="p">[</span><span class="n"><span title="lm_saes.utils.tensor_specs.TensorSpecs">TensorSpecs</span></span><span class="p">]</span> <span class="o">=</span> <span class="n"><span title="lm_saes.clt.CrossLayerTranscoderSpecs">CrossLayerTranscoderSpecs</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Tensor specs for CrossLayerTranscoder with layer dimension.</p>

    </div>

</div>




<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.init_parameters" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">init_parameters</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">init_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Initialize parameters.</p>
<p>Encoders: uniformly initialized in range (-1/sqrt(d_sae), 1/sqrt(d_sae))
Decoders at layer L: uniformly initialized in range (-1/sqrt(L<em>d_model), 1/sqrt(L</em>d_model))</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-375"><a id="__codelineno-0-375" name="__codelineno-0-375"></a><span class="nd">@override</span>
</span><span id="__span-0-376"><a id="__codelineno-0-376" name="__codelineno-0-376"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-377"><a id="__codelineno-0-377" name="__codelineno-0-377"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="__span-0-378"><a id="__codelineno-0-378" name="__codelineno-0-378"></a><span class="w">    </span><span class="sd">"""Initialize parameters.</span>
</span><span id="__span-0-379"><a id="__codelineno-0-379" name="__codelineno-0-379"></a>
</span><span id="__span-0-380"><a id="__codelineno-0-380" name="__codelineno-0-380"></a><span class="sd">    Encoders: uniformly initialized in range (-1/sqrt(d_sae), 1/sqrt(d_sae))</span>
</span><span id="__span-0-381"><a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="sd">    Decoders at layer L: uniformly initialized in range (-1/sqrt(L*d_model), 1/sqrt(L*d_model))</span>
</span><span id="__span-0-382"><a id="__codelineno-0-382" name="__codelineno-0-382"></a><span class="sd">    """</span>
</span><span id="__span-0-383"><a id="__codelineno-0-383" name="__codelineno-0-383"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">init_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># jump ReLU threshold is initialized in super()</span>
</span><span id="__span-0-384"><a id="__codelineno-0-384" name="__codelineno-0-384"></a>
</span><span id="__span-0-385"><a id="__codelineno-0-385" name="__codelineno-0-385"></a>    <span class="c1"># Initialize encoder weights and biases</span>
</span><span id="__span-0-386"><a id="__codelineno-0-386" name="__codelineno-0-386"></a>    <span class="n">encoder_bound</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">)</span>
</span><span id="__span-0-387"><a id="__codelineno-0-387" name="__codelineno-0-387"></a>
</span><span id="__span-0-388"><a id="__codelineno-0-388" name="__codelineno-0-388"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-389"><a id="__codelineno-0-389" name="__codelineno-0-389"></a>        <span class="c1"># Non-distributed initialization</span>
</span><span id="__span-0-390"><a id="__codelineno-0-390" name="__codelineno-0-390"></a>
</span><span id="__span-0-391"><a id="__codelineno-0-391" name="__codelineno-0-391"></a>        <span class="c1"># Initialize encoder weights: (n_layers, d_model, d_sae)</span>
</span><span id="__span-0-392"><a id="__codelineno-0-392" name="__codelineno-0-392"></a>        <span class="n">W_E</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-393"><a id="__codelineno-0-393" name="__codelineno-0-393"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-394"><a id="__codelineno-0-394" name="__codelineno-0-394"></a>        <span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">encoder_bound</span><span class="p">,</span> <span class="n">encoder_bound</span><span class="p">)</span>
</span><span id="__span-0-395"><a id="__codelineno-0-395" name="__codelineno-0-395"></a>
</span><span id="__span-0-396"><a id="__codelineno-0-396" name="__codelineno-0-396"></a>        <span class="c1"># Initialize encoder biases: (n_layers, d_sae) - set to zero</span>
</span><span id="__span-0-397"><a id="__codelineno-0-397" name="__codelineno-0-397"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_E</span><span class="p">)</span>
</span><span id="__span-0-398"><a id="__codelineno-0-398" name="__codelineno-0-398"></a>
</span><span id="__span-0-399"><a id="__codelineno-0-399" name="__codelineno-0-399"></a>        <span class="c1"># Initialize decoder weights</span>
</span><span id="__span-0-400"><a id="__codelineno-0-400" name="__codelineno-0-400"></a>        <span class="n">W_D_initialized</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-401"><a id="__codelineno-0-401" name="__codelineno-0-401"></a>        <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
</span><span id="__span-0-402"><a id="__codelineno-0-402" name="__codelineno-0-402"></a>        <span class="k">for</span> <span class="n">layer_to</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="__span-0-403"><a id="__codelineno-0-403" name="__codelineno-0-403"></a>            <span class="c1"># Initialize decoder weights for layer layer_to</span>
</span><span id="__span-0-404"><a id="__codelineno-0-404" name="__codelineno-0-404"></a>            <span class="c1"># W_D[layer_to] has shape (layer_to+1, d_sae, d_model)</span>
</span><span id="__span-0-405"><a id="__codelineno-0-405" name="__codelineno-0-405"></a>            <span class="c1"># Scale by 1/sqrt(L*d_model) where L is the number of contributing layers</span>
</span><span id="__span-0-406"><a id="__codelineno-0-406" name="__codelineno-0-406"></a>
</span><span id="__span-0-407"><a id="__codelineno-0-407" name="__codelineno-0-407"></a>            <span class="n">W_D_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-408"><a id="__codelineno-0-408" name="__codelineno-0-408"></a>                <span class="n">layer_to</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-409"><a id="__codelineno-0-409" name="__codelineno-0-409"></a>            <span class="p">)</span>
</span><span id="__span-0-410"><a id="__codelineno-0-410" name="__codelineno-0-410"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W_D_layer</span><span class="p">,</span> <span class="o">-</span><span class="n">scale</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
</span><span id="__span-0-411"><a id="__codelineno-0-411" name="__codelineno-0-411"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_cross_layer_decoder_all_zero</span><span class="p">:</span>
</span><span id="__span-0-412"><a id="__codelineno-0-412" name="__codelineno-0-412"></a>                <span class="n">W_D_layer</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-413"><a id="__codelineno-0-413" name="__codelineno-0-413"></a>            <span class="n">W_D_initialized</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">W_D_layer</span><span class="p">)</span>
</span><span id="__span-0-414"><a id="__codelineno-0-414" name="__codelineno-0-414"></a>
</span><span id="__span-0-415"><a id="__codelineno-0-415" name="__codelineno-0-415"></a>        <span class="c1"># Initialize decoder biases</span>
</span><span id="__span-0-416"><a id="__codelineno-0-416" name="__codelineno-0-416"></a>        <span class="k">for</span> <span class="n">layer_to</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="__span-0-417"><a id="__codelineno-0-417" name="__codelineno-0-417"></a>            <span class="c1"># Initialize decoder bias for layer layer_to to zero</span>
</span><span id="__span-0-418"><a id="__codelineno-0-418" name="__codelineno-0-418"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="p">[</span><span class="n">layer_to</span><span class="p">])</span>
</span><span id="__span-0-419"><a id="__codelineno-0-419" name="__codelineno-0-419"></a>
</span><span id="__span-0-420"><a id="__codelineno-0-420" name="__codelineno-0-420"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-421"><a id="__codelineno-0-421" name="__codelineno-0-421"></a>        <span class="c1"># Distributed initialization</span>
</span><span id="__span-0-422"><a id="__codelineno-0-422" name="__codelineno-0-422"></a>        <span class="c1"># Initialize encoder weights</span>
</span><span id="__span-0-423"><a id="__codelineno-0-423" name="__codelineno-0-423"></a>        <span class="n">W_E_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-424"><a id="__codelineno-0-424" name="__codelineno-0-424"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-425"><a id="__codelineno-0-425" name="__codelineno-0-425"></a>        <span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">encoder_bound</span><span class="p">,</span> <span class="n">encoder_bound</span><span class="p">)</span>
</span><span id="__span-0-426"><a id="__codelineno-0-426" name="__codelineno-0-426"></a>        <span class="n">W_E</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_E"</span><span class="p">]</span><span class="o">.</span><span class="n">distribute</span><span class="p">(</span><span class="n">W_E_local</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-427"><a id="__codelineno-0-427" name="__codelineno-0-427"></a>
</span><span id="__span-0-428"><a id="__codelineno-0-428" name="__codelineno-0-428"></a>        <span class="c1"># Initialize encoder biases</span>
</span><span id="__span-0-429"><a id="__codelineno-0-429" name="__codelineno-0-429"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_E</span><span class="p">)</span>
</span><span id="__span-0-430"><a id="__codelineno-0-430" name="__codelineno-0-430"></a>
</span><span id="__span-0-431"><a id="__codelineno-0-431" name="__codelineno-0-431"></a>        <span class="c1"># Initialize decoder weights for each layer</span>
</span><span id="__span-0-432"><a id="__codelineno-0-432" name="__codelineno-0-432"></a>        <span class="n">W_D_initialized</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-433"><a id="__codelineno-0-433" name="__codelineno-0-433"></a>        <span class="k">for</span> <span class="n">layer_to</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="__span-0-434"><a id="__codelineno-0-434" name="__codelineno-0-434"></a>            <span class="n">decoder_bound</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
</span><span id="__span-0-435"><a id="__codelineno-0-435" name="__codelineno-0-435"></a>            <span class="n">W_D_layer_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-436"><a id="__codelineno-0-436" name="__codelineno-0-436"></a>                <span class="n">layer_to</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-437"><a id="__codelineno-0-437" name="__codelineno-0-437"></a>            <span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">decoder_bound</span><span class="p">,</span> <span class="n">decoder_bound</span><span class="p">)</span>
</span><span id="__span-0-438"><a id="__codelineno-0-438" name="__codelineno-0-438"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">init_cross_layer_decoder_all_zero</span><span class="p">:</span>
</span><span id="__span-0-439"><a id="__codelineno-0-439" name="__codelineno-0-439"></a>                <span class="n">W_D_layer_local</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-440"><a id="__codelineno-0-440" name="__codelineno-0-440"></a>            <span class="n">W_D_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_D"</span><span class="p">]</span><span class="o">.</span><span class="n">distribute</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">W_D_layer_local</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-441"><a id="__codelineno-0-441" name="__codelineno-0-441"></a>            <span class="n">W_D_initialized</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">W_D_layer</span><span class="p">)</span>
</span><span id="__span-0-442"><a id="__codelineno-0-442" name="__codelineno-0-442"></a>
</span><span id="__span-0-443"><a id="__codelineno-0-443" name="__codelineno-0-443"></a>        <span class="c1"># Initialize decoder biases</span>
</span><span id="__span-0-444"><a id="__codelineno-0-444" name="__codelineno-0-444"></a>        <span class="k">for</span> <span class="n">layer_to</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="__span-0-445"><a id="__codelineno-0-445" name="__codelineno-0-445"></a>            <span class="c1"># Initialize decoder bias for layer layer_to to zero</span>
</span><span id="__span-0-446"><a id="__codelineno-0-446" name="__codelineno-0-446"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="p">[</span><span class="n">layer_to</span><span class="p">])</span>
</span><span id="__span-0-447"><a id="__codelineno-0-447" name="__codelineno-0-447"></a>
</span><span id="__span-0-448"><a id="__codelineno-0-448" name="__codelineno-0-448"></a>    <span class="c1"># Copy initialized values to parameters</span>
</span><span id="__span-0-449"><a id="__codelineno-0-449" name="__codelineno-0-449"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_E</span><span class="p">)</span>
</span><span id="__span-0-450"><a id="__codelineno-0-450" name="__codelineno-0-450"></a>
</span><span id="__span-0-451"><a id="__codelineno-0-451" name="__codelineno-0-451"></a>    <span class="k">for</span> <span class="n">layer_to</span><span class="p">,</span> <span class="n">W_D_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">W_D_initialized</span><span class="p">):</span>
</span><span id="__span-0-452"><a id="__codelineno-0-452" name="__codelineno-0-452"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">[</span><span class="n">layer_to</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_D_layer</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.get_decoder_weights" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_decoder_weights</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">get_decoder_weights</span><span class="p">(</span><span class="n">layer_to</span><span class="p">:</span> <span class="n"><span title="int">int</span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get decoder weights for all layers from 0..layer_to to layer_to.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>layer_to</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target layer (0 to n_layers-1)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Decoder weights for all source layers to the specified target layer</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-470"><a id="__codelineno-0-470" name="__codelineno-0-470"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_decoder_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_to</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-471"><a id="__codelineno-0-471" name="__codelineno-0-471"></a><span class="w">    </span><span class="sd">"""Get decoder weights for all layers from 0..layer_to to layer_to.</span>
</span><span id="__span-0-472"><a id="__codelineno-0-472" name="__codelineno-0-472"></a>
</span><span id="__span-0-473"><a id="__codelineno-0-473" name="__codelineno-0-473"></a><span class="sd">    Args:</span>
</span><span id="__span-0-474"><a id="__codelineno-0-474" name="__codelineno-0-474"></a><span class="sd">        layer_to: Target layer (0 to n_layers-1)</span>
</span><span id="__span-0-475"><a id="__codelineno-0-475" name="__codelineno-0-475"></a>
</span><span id="__span-0-476"><a id="__codelineno-0-476" name="__codelineno-0-476"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-477"><a id="__codelineno-0-477" name="__codelineno-0-477"></a><span class="sd">        Decoder weights for all source layers to the specified target layer</span>
</span><span id="__span-0-478"><a id="__codelineno-0-478" name="__codelineno-0-478"></a><span class="sd">    """</span>
</span><span id="__span-0-479"><a id="__codelineno-0-479" name="__codelineno-0-479"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">[</span><span class="n">layer_to</span><span class="p">]</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.encode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encode</span>


</h3>
          <div class="doc-overloads">
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="p">)</span>
</span></code></pre></div><div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">True</span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="p">]</span>
</span></code></pre></div>          </div>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="o">|</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="p">]</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode input activations to CLT features using L encoders.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_layers d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_layers d_model']</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input activations from all layers (..., n_layers, d_model)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_hidden_pre</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to return pre-activation values</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_layers d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_layers d_sae'] | <span title="tuple">tuple</span>[<span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_layers d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_layers d_sae'], <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_layers d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_layers d_sae']]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Feature activations for all layers (..., n_layers, d_sae)</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-512">512</a></span>
<span class="normal"><a href="#__codelineno-0-513">513</a></span>
<span class="normal"><a href="#__codelineno-0-514">514</a></span>
<span class="normal"><a href="#__codelineno-0-515">515</a></span>
<span class="normal"><a href="#__codelineno-0-516">516</a></span>
<span class="normal"><a href="#__codelineno-0-517">517</a></span>
<span class="normal"><a href="#__codelineno-0-518">518</a></span>
<span class="normal"><a href="#__codelineno-0-519">519</a></span>
<span class="normal"><a href="#__codelineno-0-520">520</a></span>
<span class="normal"><a href="#__codelineno-0-521">521</a></span>
<span class="normal"><a href="#__codelineno-0-522">522</a></span>
<span class="normal"><a href="#__codelineno-0-523">523</a></span>
<span class="normal"><a href="#__codelineno-0-524">524</a></span>
<span class="normal"><a href="#__codelineno-0-525">525</a></span>
<span class="normal"><a href="#__codelineno-0-526">526</a></span>
<span class="normal"><a href="#__codelineno-0-527">527</a></span>
<span class="normal"><a href="#__codelineno-0-528">528</a></span>
<span class="normal"><a href="#__codelineno-0-529">529</a></span>
<span class="normal"><a href="#__codelineno-0-530">530</a></span>
<span class="normal"><a href="#__codelineno-0-531">531</a></span>
<span class="normal"><a href="#__codelineno-0-532">532</a></span>
<span class="normal"><a href="#__codelineno-0-533">533</a></span>
<span class="normal"><a href="#__codelineno-0-534">534</a></span>
<span class="normal"><a href="#__codelineno-0-535">535</a></span>
<span class="normal"><a href="#__codelineno-0-536">536</a></span>
<span class="normal"><a href="#__codelineno-0-537">537</a></span>
<span class="normal"><a href="#__codelineno-0-538">538</a></span>
<span class="normal"><a href="#__codelineno-0-539">539</a></span>
<span class="normal"><a href="#__codelineno-0-540">540</a></span>
<span class="normal"><a href="#__codelineno-0-541">541</a></span>
<span class="normal"><a href="#__codelineno-0-542">542</a></span>
<span class="normal"><a href="#__codelineno-0-543">543</a></span>
<span class="normal"><a href="#__codelineno-0-544">544</a></span>
<span class="normal"><a href="#__codelineno-0-545">545</a></span>
<span class="normal"><a href="#__codelineno-0-546">546</a></span>
<span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span>
<span class="normal"><a href="#__codelineno-0-550">550</a></span>
<span class="normal"><a href="#__codelineno-0-551">551</a></span>
<span class="normal"><a href="#__codelineno-0-552">552</a></span>
<span class="normal"><a href="#__codelineno-0-553">553</a></span>
<span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span>
<span class="normal"><a href="#__codelineno-0-557">557</a></span>
<span class="normal"><a href="#__codelineno-0-558">558</a></span>
<span class="normal"><a href="#__codelineno-0-559">559</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-512"><a id="__codelineno-0-512" name="__codelineno-0-512"></a><span class="nd">@override</span>
</span><span id="__span-0-513"><a id="__codelineno-0-513" name="__codelineno-0-513"></a><span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-514"><a id="__codelineno-0-514" name="__codelineno-0-514"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-515"><a id="__codelineno-0-515" name="__codelineno-0-515"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-516"><a id="__codelineno-0-516" name="__codelineno-0-516"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_layers d_model"</span><span class="p">],</span>
</span><span id="__span-0-517"><a id="__codelineno-0-517" name="__codelineno-0-517"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_model"</span><span class="p">],</span>
</span><span id="__span-0-518"><a id="__codelineno-0-518" name="__codelineno-0-518"></a>    <span class="p">],</span>
</span><span id="__span-0-519"><a id="__codelineno-0-519" name="__codelineno-0-519"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-520"><a id="__codelineno-0-520" name="__codelineno-0-520"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-521"><a id="__codelineno-0-521" name="__codelineno-0-521"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-522"><a id="__codelineno-0-522" name="__codelineno-0-522"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-523"><a id="__codelineno-0-523" name="__codelineno-0-523"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-524"><a id="__codelineno-0-524" name="__codelineno-0-524"></a>    <span class="nb">tuple</span><span class="p">[</span>
</span><span id="__span-0-525"><a id="__codelineno-0-525" name="__codelineno-0-525"></a>        <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-526"><a id="__codelineno-0-526" name="__codelineno-0-526"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-527"><a id="__codelineno-0-527" name="__codelineno-0-527"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-528"><a id="__codelineno-0-528" name="__codelineno-0-528"></a>        <span class="p">],</span>
</span><span id="__span-0-529"><a id="__codelineno-0-529" name="__codelineno-0-529"></a>        <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-530"><a id="__codelineno-0-530" name="__codelineno-0-530"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-531"><a id="__codelineno-0-531" name="__codelineno-0-531"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-532"><a id="__codelineno-0-532" name="__codelineno-0-532"></a>        <span class="p">],</span>
</span><span id="__span-0-533"><a id="__codelineno-0-533" name="__codelineno-0-533"></a>    <span class="p">],</span>
</span><span id="__span-0-534"><a id="__codelineno-0-534" name="__codelineno-0-534"></a><span class="p">]:</span>
</span><span id="__span-0-535"><a id="__codelineno-0-535" name="__codelineno-0-535"></a><span class="w">    </span><span class="sd">"""Encode input activations to CLT features using L encoders.</span>
</span><span id="__span-0-536"><a id="__codelineno-0-536" name="__codelineno-0-536"></a>
</span><span id="__span-0-537"><a id="__codelineno-0-537" name="__codelineno-0-537"></a><span class="sd">    Args:</span>
</span><span id="__span-0-538"><a id="__codelineno-0-538" name="__codelineno-0-538"></a><span class="sd">        x: Input activations from all layers (..., n_layers, d_model)</span>
</span><span id="__span-0-539"><a id="__codelineno-0-539" name="__codelineno-0-539"></a><span class="sd">        return_hidden_pre: Whether to return pre-activation values</span>
</span><span id="__span-0-540"><a id="__codelineno-0-540" name="__codelineno-0-540"></a>
</span><span id="__span-0-541"><a id="__codelineno-0-541" name="__codelineno-0-541"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-542"><a id="__codelineno-0-542" name="__codelineno-0-542"></a><span class="sd">        Feature activations for all layers (..., n_layers, d_sae)</span>
</span><span id="__span-0-543"><a id="__codelineno-0-543" name="__codelineno-0-543"></a><span class="sd">    """</span>
</span><span id="__span-0-544"><a id="__codelineno-0-544" name="__codelineno-0-544"></a>    <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"encoder_matmul"</span><span class="p">):</span>
</span><span id="__span-0-545"><a id="__codelineno-0-545" name="__codelineno-0-545"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"...ld,lds-&gt;...ls"</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span>
</span><span id="__span-0-546"><a id="__codelineno-0-546" name="__codelineno-0-546"></a>
</span><span id="__span-0-547"><a id="__codelineno-0-547" name="__codelineno-0-547"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_include_decoder_norm</span><span class="p">:</span>
</span><span id="__span-0-548"><a id="__codelineno-0-548" name="__codelineno-0-548"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">hidden_pre</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm_per_feature</span><span class="p">()</span>
</span><span id="__span-0-549"><a id="__codelineno-0-549" name="__codelineno-0-549"></a>
</span><span id="__span-0-550"><a id="__codelineno-0-550" name="__codelineno-0-550"></a>    <span class="c1"># Apply activation function (ReLU, TopK, etc.)</span>
</span><span id="__span-0-551"><a id="__codelineno-0-551" name="__codelineno-0-551"></a>    <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"activation_function"</span><span class="p">):</span>
</span><span id="__span-0-552"><a id="__codelineno-0-552" name="__codelineno-0-552"></a>        <span class="n">feature_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">(</span><span class="n">hidden_pre</span><span class="p">)</span>
</span><span id="__span-0-553"><a id="__codelineno-0-553" name="__codelineno-0-553"></a>
</span><span id="__span-0-554"><a id="__codelineno-0-554" name="__codelineno-0-554"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_include_decoder_norm</span><span class="p">:</span>
</span><span id="__span-0-555"><a id="__codelineno-0-555" name="__codelineno-0-555"></a>        <span class="n">feature_acts</span> <span class="o">=</span> <span class="n">feature_acts</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm_per_feature</span><span class="p">()</span>
</span><span id="__span-0-556"><a id="__codelineno-0-556" name="__codelineno-0-556"></a>
</span><span id="__span-0-557"><a id="__codelineno-0-557" name="__codelineno-0-557"></a>    <span class="k">if</span> <span class="n">return_hidden_pre</span><span class="p">:</span>
</span><span id="__span-0-558"><a id="__codelineno-0-558" name="__codelineno-0-558"></a>        <span class="k">return</span> <span class="n">feature_acts</span><span class="p">,</span> <span class="n">hidden_pre</span>
</span><span id="__span-0-559"><a id="__codelineno-0-559" name="__codelineno-0-559"></a>    <span class="k">return</span> <span class="n">feature_acts</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.encode_single_layer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encode_single_layer</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode_single_layer</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">layer</span><span class="p">:</span> <span class="n"><span title="int">int</span></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="o">|</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="p">]</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode input activations to CLT features using L encoders.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_model']</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input activations from a given layer (..., d_model)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The layer to encode</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_hidden_pre</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to return pre-activation values</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae'] | <span title="tuple">tuple</span>[<span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae'], <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae']]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Feature activations for the given layer (..., d_sae)</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-561">561</a></span>
<span class="normal"><a href="#__codelineno-0-562">562</a></span>
<span class="normal"><a href="#__codelineno-0-563">563</a></span>
<span class="normal"><a href="#__codelineno-0-564">564</a></span>
<span class="normal"><a href="#__codelineno-0-565">565</a></span>
<span class="normal"><a href="#__codelineno-0-566">566</a></span>
<span class="normal"><a href="#__codelineno-0-567">567</a></span>
<span class="normal"><a href="#__codelineno-0-568">568</a></span>
<span class="normal"><a href="#__codelineno-0-569">569</a></span>
<span class="normal"><a href="#__codelineno-0-570">570</a></span>
<span class="normal"><a href="#__codelineno-0-571">571</a></span>
<span class="normal"><a href="#__codelineno-0-572">572</a></span>
<span class="normal"><a href="#__codelineno-0-573">573</a></span>
<span class="normal"><a href="#__codelineno-0-574">574</a></span>
<span class="normal"><a href="#__codelineno-0-575">575</a></span>
<span class="normal"><a href="#__codelineno-0-576">576</a></span>
<span class="normal"><a href="#__codelineno-0-577">577</a></span>
<span class="normal"><a href="#__codelineno-0-578">578</a></span>
<span class="normal"><a href="#__codelineno-0-579">579</a></span>
<span class="normal"><a href="#__codelineno-0-580">580</a></span>
<span class="normal"><a href="#__codelineno-0-581">581</a></span>
<span class="normal"><a href="#__codelineno-0-582">582</a></span>
<span class="normal"><a href="#__codelineno-0-583">583</a></span>
<span class="normal"><a href="#__codelineno-0-584">584</a></span>
<span class="normal"><a href="#__codelineno-0-585">585</a></span>
<span class="normal"><a href="#__codelineno-0-586">586</a></span>
<span class="normal"><a href="#__codelineno-0-587">587</a></span>
<span class="normal"><a href="#__codelineno-0-588">588</a></span>
<span class="normal"><a href="#__codelineno-0-589">589</a></span>
<span class="normal"><a href="#__codelineno-0-590">590</a></span>
<span class="normal"><a href="#__codelineno-0-591">591</a></span>
<span class="normal"><a href="#__codelineno-0-592">592</a></span>
<span class="normal"><a href="#__codelineno-0-593">593</a></span>
<span class="normal"><a href="#__codelineno-0-594">594</a></span>
<span class="normal"><a href="#__codelineno-0-595">595</a></span>
<span class="normal"><a href="#__codelineno-0-596">596</a></span>
<span class="normal"><a href="#__codelineno-0-597">597</a></span>
<span class="normal"><a href="#__codelineno-0-598">598</a></span>
<span class="normal"><a href="#__codelineno-0-599">599</a></span>
<span class="normal"><a href="#__codelineno-0-600">600</a></span>
<span class="normal"><a href="#__codelineno-0-601">601</a></span>
<span class="normal"><a href="#__codelineno-0-602">602</a></span>
<span class="normal"><a href="#__codelineno-0-603">603</a></span>
<span class="normal"><a href="#__codelineno-0-604">604</a></span>
<span class="normal"><a href="#__codelineno-0-605">605</a></span>
<span class="normal"><a href="#__codelineno-0-606">606</a></span>
<span class="normal"><a href="#__codelineno-0-607">607</a></span>
<span class="normal"><a href="#__codelineno-0-608">608</a></span>
<span class="normal"><a href="#__codelineno-0-609">609</a></span>
<span class="normal"><a href="#__codelineno-0-610">610</a></span>
<span class="normal"><a href="#__codelineno-0-611">611</a></span>
<span class="normal"><a href="#__codelineno-0-612">612</a></span>
<span class="normal"><a href="#__codelineno-0-613">613</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-561"><a id="__codelineno-0-561" name="__codelineno-0-561"></a><span class="k">def</span><span class="w"> </span><span class="nf">encode_single_layer</span><span class="p">(</span>
</span><span id="__span-0-562"><a id="__codelineno-0-562" name="__codelineno-0-562"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-563"><a id="__codelineno-0-563" name="__codelineno-0-563"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-564"><a id="__codelineno-0-564" name="__codelineno-0-564"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">],</span>
</span><span id="__span-0-565"><a id="__codelineno-0-565" name="__codelineno-0-565"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-566"><a id="__codelineno-0-566" name="__codelineno-0-566"></a>    <span class="p">],</span>
</span><span id="__span-0-567"><a id="__codelineno-0-567" name="__codelineno-0-567"></a>    <span class="n">layer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-568"><a id="__codelineno-0-568" name="__codelineno-0-568"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-569"><a id="__codelineno-0-569" name="__codelineno-0-569"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-570"><a id="__codelineno-0-570" name="__codelineno-0-570"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-571"><a id="__codelineno-0-571" name="__codelineno-0-571"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">],</span>
</span><span id="__span-0-572"><a id="__codelineno-0-572" name="__codelineno-0-572"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-573"><a id="__codelineno-0-573" name="__codelineno-0-573"></a>    <span class="nb">tuple</span><span class="p">[</span>
</span><span id="__span-0-574"><a id="__codelineno-0-574" name="__codelineno-0-574"></a>        <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-575"><a id="__codelineno-0-575" name="__codelineno-0-575"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">],</span>
</span><span id="__span-0-576"><a id="__codelineno-0-576" name="__codelineno-0-576"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-577"><a id="__codelineno-0-577" name="__codelineno-0-577"></a>        <span class="p">],</span>
</span><span id="__span-0-578"><a id="__codelineno-0-578" name="__codelineno-0-578"></a>        <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-579"><a id="__codelineno-0-579" name="__codelineno-0-579"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">],</span>
</span><span id="__span-0-580"><a id="__codelineno-0-580" name="__codelineno-0-580"></a>            <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-581"><a id="__codelineno-0-581" name="__codelineno-0-581"></a>        <span class="p">],</span>
</span><span id="__span-0-582"><a id="__codelineno-0-582" name="__codelineno-0-582"></a>    <span class="p">],</span>
</span><span id="__span-0-583"><a id="__codelineno-0-583" name="__codelineno-0-583"></a><span class="p">]:</span>
</span><span id="__span-0-584"><a id="__codelineno-0-584" name="__codelineno-0-584"></a><span class="w">    </span><span class="sd">"""Encode input activations to CLT features using L encoders.</span>
</span><span id="__span-0-585"><a id="__codelineno-0-585" name="__codelineno-0-585"></a>
</span><span id="__span-0-586"><a id="__codelineno-0-586" name="__codelineno-0-586"></a><span class="sd">    Args:</span>
</span><span id="__span-0-587"><a id="__codelineno-0-587" name="__codelineno-0-587"></a><span class="sd">        x: Input activations from a given layer (..., d_model)</span>
</span><span id="__span-0-588"><a id="__codelineno-0-588" name="__codelineno-0-588"></a><span class="sd">        layer: The layer to encode</span>
</span><span id="__span-0-589"><a id="__codelineno-0-589" name="__codelineno-0-589"></a><span class="sd">        return_hidden_pre: Whether to return pre-activation values</span>
</span><span id="__span-0-590"><a id="__codelineno-0-590" name="__codelineno-0-590"></a>
</span><span id="__span-0-591"><a id="__codelineno-0-591" name="__codelineno-0-591"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-592"><a id="__codelineno-0-592" name="__codelineno-0-592"></a><span class="sd">        Feature activations for the given layer (..., d_sae)</span>
</span><span id="__span-0-593"><a id="__codelineno-0-593" name="__codelineno-0-593"></a><span class="sd">    """</span>
</span><span id="__span-0-594"><a id="__codelineno-0-594" name="__codelineno-0-594"></a>    <span class="c1"># Apply each encoder to its corresponding layer: x[..., layer, :] @ W_E[layer] + b_E[layer]</span>
</span><span id="__span-0-595"><a id="__codelineno-0-595" name="__codelineno-0-595"></a>    <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"...d,ds-&gt;...s"</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span>
</span><span id="__span-0-596"><a id="__codelineno-0-596" name="__codelineno-0-596"></a>
</span><span id="__span-0-597"><a id="__codelineno-0-597" name="__codelineno-0-597"></a>    <span class="c1"># print(f'{x.shape=} {self.W_E[layer].shape=} {self.b_E[layer].shape=}')</span>
</span><span id="__span-0-598"><a id="__codelineno-0-598" name="__codelineno-0-598"></a>
</span><span id="__span-0-599"><a id="__codelineno-0-599" name="__codelineno-0-599"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_include_decoder_norm</span><span class="p">:</span>
</span><span id="__span-0-600"><a id="__codelineno-0-600" name="__codelineno-0-600"></a>        <span class="c1"># print(f'{hidden_pre.shape=} {self.decoder_norm_per_feature(layer=layer).shape=}')</span>
</span><span id="__span-0-601"><a id="__codelineno-0-601" name="__codelineno-0-601"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">hidden_pre</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm_per_feature</span><span class="p">(</span><span class="n">layer</span><span class="o">=</span><span class="n">layer</span><span class="p">)</span>
</span><span id="__span-0-602"><a id="__codelineno-0-602" name="__codelineno-0-602"></a>
</span><span id="__span-0-603"><a id="__codelineno-0-603" name="__codelineno-0-603"></a>    <span class="c1"># Apply activation function (ReLU, TopK, etc.)</span>
</span><span id="__span-0-604"><a id="__codelineno-0-604" name="__codelineno-0-604"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">act_fn</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">"jumprelu"</span><span class="p">:</span>
</span><span id="__span-0-605"><a id="__codelineno-0-605" name="__codelineno-0-605"></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">,</span> <span class="n">JumpReLU</span><span class="p">)</span>
</span><span id="__span-0-606"><a id="__codelineno-0-606" name="__codelineno-0-606"></a>        <span class="n">jumprelu_threshold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="o">.</span><span class="n">get_jumprelu_threshold</span><span class="p">()</span>
</span><span id="__span-0-607"><a id="__codelineno-0-607" name="__codelineno-0-607"></a>        <span class="n">feature_acts</span> <span class="o">=</span> <span class="n">hidden_pre</span> <span class="o">*</span> <span class="n">hidden_pre</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">jumprelu_threshold</span><span class="p">[</span><span class="n">layer</span><span class="p">])</span>
</span><span id="__span-0-608"><a id="__codelineno-0-608" name="__codelineno-0-608"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-609"><a id="__codelineno-0-609" name="__codelineno-0-609"></a>        <span class="n">feature_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">(</span><span class="n">hidden_pre</span><span class="p">)</span>
</span><span id="__span-0-610"><a id="__codelineno-0-610" name="__codelineno-0-610"></a>
</span><span id="__span-0-611"><a id="__codelineno-0-611" name="__codelineno-0-611"></a>    <span class="k">if</span> <span class="n">return_hidden_pre</span><span class="p">:</span>
</span><span id="__span-0-612"><a id="__codelineno-0-612" name="__codelineno-0-612"></a>        <span class="k">return</span> <span class="n">feature_acts</span><span class="p">,</span> <span class="n">hidden_pre</span>
</span><span id="__span-0-613"><a id="__codelineno-0-613" name="__codelineno-0-613"></a>    <span class="k">return</span> <span class="n">feature_acts</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.decode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decode</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">]</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">|</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.sparse.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"seq_len d_sae"</span><span class="p">]],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">batch_first</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"n_layers batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"n_layers batch seq_len d_model"</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_layers d_model"</span><span class="p">]</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_model"</span><span class="p">]</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Decode CLT features to output activations using the upper triangular pattern.</p>
<p>The output at layer L is the sum of contributions from all layers 0 through L:
y_L = _{i=0}^{L} W_D[iL] @ feature_acts[..., i, :] + b_D[L]</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feature_acts</code>
            </td>
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_layers d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_layers d_sae'] | <span title="list">list</span>[<span title="jaxtyping.Float">Float</span>[<span title="torch.sparse.Tensor">Tensor</span>, 'seq_len d_sae']]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>CLT feature activations (..., n_layers, d_sae)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'n_layers batch d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'n_layers batch seq_len d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch n_layers d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len n_layers d_model']</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Reconstructed activations for all layers (..., n_layers, d_model)</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span>
<span class="normal"><a href="#__codelineno-0-645">645</a></span>
<span class="normal"><a href="#__codelineno-0-646">646</a></span>
<span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span>
<span class="normal"><a href="#__codelineno-0-661">661</a></span>
<span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-615"><a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="nd">@override</span>
</span><span id="__span-0-616"><a id="__codelineno-0-616" name="__codelineno-0-616"></a><span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span>
</span><span id="__span-0-617"><a id="__codelineno-0-617" name="__codelineno-0-617"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-618"><a id="__codelineno-0-618" name="__codelineno-0-618"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-619"><a id="__codelineno-0-619" name="__codelineno-0-619"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-620"><a id="__codelineno-0-620" name="__codelineno-0-620"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_sae"</span><span class="p">],</span>
</span><span id="__span-0-621"><a id="__codelineno-0-621" name="__codelineno-0-621"></a>        <span class="n">List</span><span class="p">[</span><span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"seq_len d_sae"</span><span class="p">]],</span>
</span><span id="__span-0-622"><a id="__codelineno-0-622" name="__codelineno-0-622"></a>    <span class="p">],</span>
</span><span id="__span-0-623"><a id="__codelineno-0-623" name="__codelineno-0-623"></a>    <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-624"><a id="__codelineno-0-624" name="__codelineno-0-624"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-625"><a id="__codelineno-0-625" name="__codelineno-0-625"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-626"><a id="__codelineno-0-626" name="__codelineno-0-626"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"n_layers batch d_model"</span><span class="p">],</span>
</span><span id="__span-0-627"><a id="__codelineno-0-627" name="__codelineno-0-627"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"n_layers batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-628"><a id="__codelineno-0-628" name="__codelineno-0-628"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_layers d_model"</span><span class="p">],</span>
</span><span id="__span-0-629"><a id="__codelineno-0-629" name="__codelineno-0-629"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len n_layers d_model"</span><span class="p">],</span>
</span><span id="__span-0-630"><a id="__codelineno-0-630" name="__codelineno-0-630"></a><span class="p">]:</span>
</span><span id="__span-0-631"><a id="__codelineno-0-631" name="__codelineno-0-631"></a><span class="w">    </span><span class="sd">"""Decode CLT features to output activations using the upper triangular pattern.</span>
</span><span id="__span-0-632"><a id="__codelineno-0-632" name="__codelineno-0-632"></a>
</span><span id="__span-0-633"><a id="__codelineno-0-633" name="__codelineno-0-633"></a><span class="sd">    The output at layer L is the sum of contributions from all layers 0 through L:</span>
</span><span id="__span-0-634"><a id="__codelineno-0-634" name="__codelineno-0-634"></a><span class="sd">    y_L = _{i=0}^{L} W_D[iL] @ feature_acts[..., i, :] + b_D[L]</span>
</span><span id="__span-0-635"><a id="__codelineno-0-635" name="__codelineno-0-635"></a>
</span><span id="__span-0-636"><a id="__codelineno-0-636" name="__codelineno-0-636"></a><span class="sd">    Args:</span>
</span><span id="__span-0-637"><a id="__codelineno-0-637" name="__codelineno-0-637"></a><span class="sd">        feature_acts: CLT feature activations (..., n_layers, d_sae)</span>
</span><span id="__span-0-638"><a id="__codelineno-0-638" name="__codelineno-0-638"></a>
</span><span id="__span-0-639"><a id="__codelineno-0-639" name="__codelineno-0-639"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-640"><a id="__codelineno-0-640" name="__codelineno-0-640"></a><span class="sd">        Reconstructed activations for all layers (..., n_layers, d_model)</span>
</span><span id="__span-0-641"><a id="__codelineno-0-641" name="__codelineno-0-641"></a><span class="sd">    """</span>
</span><span id="__span-0-642"><a id="__codelineno-0-642" name="__codelineno-0-642"></a>    <span class="c1"># TODO: make this cleaner</span>
</span><span id="__span-0-643"><a id="__codelineno-0-643" name="__codelineno-0-643"></a>
</span><span id="__span-0-644"><a id="__codelineno-0-644" name="__codelineno-0-644"></a>    <span class="n">reconstructed</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-645"><a id="__codelineno-0-645" name="__codelineno-0-645"></a>    <span class="c1"># For each output layer L</span>
</span><span id="__span-0-646"><a id="__codelineno-0-646" name="__codelineno-0-646"></a>    <span class="k">if</span> <span class="p">(</span>
</span><span id="__span-0-647"><a id="__codelineno-0-647" name="__codelineno-0-647"></a>        <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
</span><span id="__span-0-648"><a id="__codelineno-0-648" name="__codelineno-0-648"></a>        <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="__span-0-649"><a id="__codelineno-0-649" name="__codelineno-0-649"></a>        <span class="ow">and</span> <span class="n">feature_acts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">layout</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span>
</span><span id="__span-0-650"><a id="__codelineno-0-650" name="__codelineno-0-650"></a>    <span class="p">):</span>
</span><span id="__span-0-651"><a id="__codelineno-0-651" name="__codelineno-0-651"></a>        <span class="n">decode_single_output_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decode_single_output_layer_coo</span>
</span><span id="__span-0-652"><a id="__codelineno-0-652" name="__codelineno-0-652"></a>    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">decode_with_csr</span><span class="p">:</span>
</span><span id="__span-0-653"><a id="__codelineno-0-653" name="__codelineno-0-653"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_k</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_threshold_for_csr</span><span class="p">:</span>
</span><span id="__span-0-654"><a id="__codelineno-0-654" name="__codelineno-0-654"></a>            <span class="n">decode_single_output_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decode_single_output_layer_csr</span>
</span><span id="__span-0-655"><a id="__codelineno-0-655" name="__codelineno-0-655"></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="nb">list</span><span class="p">),</span> <span class="p">(</span>
</span><span id="__span-0-656"><a id="__codelineno-0-656" name="__codelineno-0-656"></a>                <span class="s2">"feature_acts must not be a list when decode_with_csr is True"</span>
</span><span id="__span-0-657"><a id="__codelineno-0-657" name="__codelineno-0-657"></a>            <span class="p">)</span>
</span><span id="__span-0-658"><a id="__codelineno-0-658" name="__codelineno-0-658"></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-659"><a id="__codelineno-0-659" name="__codelineno-0-659"></a>                <span class="n">feature_acts</span> <span class="o">=</span> <span class="n">feature_acts</span><span class="o">.</span><span class="n">to_local</span><span class="p">()</span>
</span><span id="__span-0-660"><a id="__codelineno-0-660" name="__codelineno-0-660"></a>            <span class="k">if</span> <span class="n">feature_acts</span><span class="o">.</span><span class="n">layout</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csr</span><span class="p">:</span>
</span><span id="__span-0-661"><a id="__codelineno-0-661" name="__codelineno-0-661"></a>                <span class="n">feature_acts</span> <span class="o">=</span> <span class="p">[</span><span class="n">fa</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">()</span> <span class="k">for</span> <span class="n">fa</span> <span class="ow">in</span> <span class="n">feature_acts</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="__span-0-662"><a id="__codelineno-0-662" name="__codelineno-0-662"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-663"><a id="__codelineno-0-663" name="__codelineno-0-663"></a>            <span class="n">decode_single_output_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decode_single_output_layer_dense</span>
</span><span id="__span-0-664"><a id="__codelineno-0-664" name="__codelineno-0-664"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-665"><a id="__codelineno-0-665" name="__codelineno-0-665"></a>        <span class="n">decode_single_output_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decode_single_output_layer_dense</span>
</span><span id="__span-0-666"><a id="__codelineno-0-666" name="__codelineno-0-666"></a>
</span><span id="__span-0-667"><a id="__codelineno-0-667" name="__codelineno-0-667"></a>    <span class="k">for</span> <span class="n">layer_to</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="__span-0-668"><a id="__codelineno-0-668" name="__codelineno-0-668"></a>        <span class="c1"># we only compute W_D @ feature_acts here, without b_D</span>
</span><span id="__span-0-669"><a id="__codelineno-0-669" name="__codelineno-0-669"></a>        <span class="n">contribution</span> <span class="o">=</span> <span class="n">decode_single_output_layer</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="n">layer_to</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
</span><span id="__span-0-670"><a id="__codelineno-0-670" name="__codelineno-0-670"></a>
</span><span id="__span-0-671"><a id="__codelineno-0-671" name="__codelineno-0-671"></a>        <span class="c1"># Add bias contribution (single bias vector for this target layer)</span>
</span><span id="__span-0-672"><a id="__codelineno-0-672" name="__codelineno-0-672"></a>        <span class="n">contribution</span> <span class="o">=</span> <span class="n">contribution</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="p">[</span><span class="n">layer_to</span><span class="p">]</span>  <span class="c1"># (d_model,)</span>
</span><span id="__span-0-673"><a id="__codelineno-0-673" name="__codelineno-0-673"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">contribution</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-674"><a id="__codelineno-0-674" name="__codelineno-0-674"></a>            <span class="n">contribution</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"data"</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span><span class="o">.</span><span class="n">redistribute</span><span class="p">(</span><span class="n">contribution</span><span class="p">)</span>
</span><span id="__span-0-675"><a id="__codelineno-0-675" name="__codelineno-0-675"></a>
</span><span id="__span-0-676"><a id="__codelineno-0-676" name="__codelineno-0-676"></a>        <span class="n">reconstructed</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">contribution</span><span class="p">)</span>
</span><span id="__span-0-677"><a id="__codelineno-0-677" name="__codelineno-0-677"></a>
</span><span id="__span-0-678"><a id="__codelineno-0-678" name="__codelineno-0-678"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">reconstructed</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">batch_first</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.decoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the effective norm of decoder weights for each feature.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-786">786</a></span>
<span class="normal"><a href="#__codelineno-0-787">787</a></span>
<span class="normal"><a href="#__codelineno-0-788">788</a></span>
<span class="normal"><a href="#__codelineno-0-789">789</a></span>
<span class="normal"><a href="#__codelineno-0-790">790</a></span>
<span class="normal"><a href="#__codelineno-0-791">791</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-786"><a id="__codelineno-0-786" name="__codelineno-0-786"></a><span class="nd">@override</span>
</span><span id="__span-0-787"><a id="__codelineno-0-787" name="__codelineno-0-787"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="__span-0-788"><a id="__codelineno-0-788" name="__codelineno-0-788"></a><span class="w">    </span><span class="sd">"""Compute the effective norm of decoder weights for each feature."""</span>
</span><span id="__span-0-789"><a id="__codelineno-0-789" name="__codelineno-0-789"></a>    <span class="c1"># Collect norms from all decoder groups</span>
</span><span id="__span-0-790"><a id="__codelineno-0-790" name="__codelineno-0-790"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_decoders</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-791"><a id="__codelineno-0-791" name="__codelineno-0-791"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_decoders</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.encoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the norm of encoder weights averaged across layers.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-793">793</a></span>
<span class="normal"><a href="#__codelineno-0-794">794</a></span>
<span class="normal"><a href="#__codelineno-0-795">795</a></span>
<span class="normal"><a href="#__codelineno-0-796">796</a></span>
<span class="normal"><a href="#__codelineno-0-797">797</a></span>
<span class="normal"><a href="#__codelineno-0-798">798</a></span>
<span class="normal"><a href="#__codelineno-0-799">799</a></span>
<span class="normal"><a href="#__codelineno-0-800">800</a></span>
<span class="normal"><a href="#__codelineno-0-801">801</a></span>
<span class="normal"><a href="#__codelineno-0-802">802</a></span>
<span class="normal"><a href="#__codelineno-0-803">803</a></span>
<span class="normal"><a href="#__codelineno-0-804">804</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-793"><a id="__codelineno-0-793" name="__codelineno-0-793"></a><span class="nd">@override</span>
</span><span id="__span-0-794"><a id="__codelineno-0-794" name="__codelineno-0-794"></a><span class="k">def</span><span class="w"> </span><span class="nf">encoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="__span-0-795"><a id="__codelineno-0-795" name="__codelineno-0-795"></a><span class="w">    </span><span class="sd">"""Compute the norm of encoder weights averaged across layers."""</span>
</span><span id="__span-0-796"><a id="__codelineno-0-796" name="__codelineno-0-796"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-797"><a id="__codelineno-0-797" name="__codelineno-0-797"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-798"><a id="__codelineno-0-798" name="__codelineno-0-798"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-799"><a id="__codelineno-0-799" name="__codelineno-0-799"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-800"><a id="__codelineno-0-800" name="__codelineno-0-800"></a>        <span class="k">return</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-801"><a id="__codelineno-0-801" name="__codelineno-0-801"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="o">.</span><span class="n">to_local</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">),</span>
</span><span id="__span-0-802"><a id="__codelineno-0-802" name="__codelineno-0-802"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-803"><a id="__codelineno-0-803" name="__codelineno-0-803"></a>            <span class="n">placements</span><span class="o">=</span><span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">keepdim</span> <span class="k">else</span> <span class="mi">0</span><span class="p">})</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-804"><a id="__codelineno-0-804" name="__codelineno-0-804"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.decoder_bias_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_bias_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_bias_norm</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the norm of decoder bias for each target layer.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-806">806</a></span>
<span class="normal"><a href="#__codelineno-0-807">807</a></span>
<span class="normal"><a href="#__codelineno-0-808">808</a></span>
<span class="normal"><a href="#__codelineno-0-809">809</a></span>
<span class="normal"><a href="#__codelineno-0-810">810</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-806"><a id="__codelineno-0-806" name="__codelineno-0-806"></a><span class="nd">@override</span>
</span><span id="__span-0-807"><a id="__codelineno-0-807" name="__codelineno-0-807"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_bias_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-0-808"><a id="__codelineno-0-808" name="__codelineno-0-808"></a><span class="w">    </span><span class="sd">"""Compute the norm of decoder bias for each target layer."""</span>
</span><span id="__span-0-809"><a id="__codelineno-0-809" name="__codelineno-0-809"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-810"><a id="__codelineno-0-810" name="__codelineno-0-810"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.set_encoder_to_fixed_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">set_encoder_to_fixed_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">set_encoder_to_fixed_norm</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n"><span title="float">float</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Set encoder weights to fixed norm.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-816">816</a></span>
<span class="normal"><a href="#__codelineno-0-817">817</a></span>
<span class="normal"><a href="#__codelineno-0-818">818</a></span>
<span class="normal"><a href="#__codelineno-0-819">819</a></span>
<span class="normal"><a href="#__codelineno-0-820">820</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-816"><a id="__codelineno-0-816" name="__codelineno-0-816"></a><span class="nd">@override</span>
</span><span id="__span-0-817"><a id="__codelineno-0-817" name="__codelineno-0-817"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-818"><a id="__codelineno-0-818" name="__codelineno-0-818"></a><span class="k">def</span><span class="w"> </span><span class="nf">set_encoder_to_fixed_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="__span-0-819"><a id="__codelineno-0-819" name="__codelineno-0-819"></a><span class="w">    </span><span class="sd">"""Set encoder weights to fixed norm."""</span>
</span><span id="__span-0-820"><a id="__codelineno-0-820" name="__codelineno-0-820"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"set_encoder_to_fixed_norm does not make sense for CLT"</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.keep_only_decoders_for_layer_from" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">keep_only_decoders_for_layer_from</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">keep_only_decoders_for_layer_from</span><span class="p">(</span><span class="n">layer_from</span><span class="p">:</span> <span class="n"><span title="int">int</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Keep only the decoder norm for the given layer.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-822">822</a></span>
<span class="normal"><a href="#__codelineno-0-823">823</a></span>
<span class="normal"><a href="#__codelineno-0-824">824</a></span>
<span class="normal"><a href="#__codelineno-0-825">825</a></span>
<span class="normal"><a href="#__codelineno-0-826">826</a></span>
<span class="normal"><a href="#__codelineno-0-827">827</a></span>
<span class="normal"><a href="#__codelineno-0-828">828</a></span>
<span class="normal"><a href="#__codelineno-0-829">829</a></span>
<span class="normal"><a href="#__codelineno-0-830">830</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-822"><a id="__codelineno-0-822" name="__codelineno-0-822"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-823"><a id="__codelineno-0-823" name="__codelineno-0-823"></a><span class="k">def</span><span class="w"> </span><span class="nf">keep_only_decoders_for_layer_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_from</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="__span-0-824"><a id="__codelineno-0-824" name="__codelineno-0-824"></a><span class="w">    </span><span class="sd">"""Keep only the decoder norm for the given layer."""</span>
</span><span id="__span-0-825"><a id="__codelineno-0-825" name="__codelineno-0-825"></a>    <span class="n">new_W_D</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-826"><a id="__codelineno-0-826" name="__codelineno-0-826"></a>    <span class="k">for</span> <span class="n">layer_to</span><span class="p">,</span> <span class="n">decoder_weights</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">):</span>
</span><span id="__span-0-827"><a id="__codelineno-0-827" name="__codelineno-0-827"></a>        <span class="k">if</span> <span class="n">layer_to</span> <span class="o">&gt;=</span> <span class="n">layer_from</span><span class="p">:</span>
</span><span id="__span-0-828"><a id="__codelineno-0-828" name="__codelineno-0-828"></a>            <span class="n">new_W_D</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_weights</span><span class="p">[</span><span class="n">layer_from</span><span class="p">])</span>
</span><span id="__span-0-829"><a id="__codelineno-0-829" name="__codelineno-0-829"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">decoders_for_layer_from</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer_from</span><span class="p">,</span> <span class="n">new_W_D</span><span class="p">)</span>
</span><span id="__span-0-830"><a id="__codelineno-0-830" name="__codelineno-0-830"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.decoder_norm_per_feature" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_norm_per_feature</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_norm_per_feature</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">layer</span><span class="p">:</span> <span class="n"><span title="int">int</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"n_layers d_sae"</span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the norm of decoder weights for each feature.
If layer is not None, only compute the norm for the decoder weights from layer to subsequent layers.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-832">832</a></span>
<span class="normal"><a href="#__codelineno-0-833">833</a></span>
<span class="normal"><a href="#__codelineno-0-834">834</a></span>
<span class="normal"><a href="#__codelineno-0-835">835</a></span>
<span class="normal"><a href="#__codelineno-0-836">836</a></span>
<span class="normal"><a href="#__codelineno-0-837">837</a></span>
<span class="normal"><a href="#__codelineno-0-838">838</a></span>
<span class="normal"><a href="#__codelineno-0-839">839</a></span>
<span class="normal"><a href="#__codelineno-0-840">840</a></span>
<span class="normal"><a href="#__codelineno-0-841">841</a></span>
<span class="normal"><a href="#__codelineno-0-842">842</a></span>
<span class="normal"><a href="#__codelineno-0-843">843</a></span>
<span class="normal"><a href="#__codelineno-0-844">844</a></span>
<span class="normal"><a href="#__codelineno-0-845">845</a></span>
<span class="normal"><a href="#__codelineno-0-846">846</a></span>
<span class="normal"><a href="#__codelineno-0-847">847</a></span>
<span class="normal"><a href="#__codelineno-0-848">848</a></span>
<span class="normal"><a href="#__codelineno-0-849">849</a></span>
<span class="normal"><a href="#__codelineno-0-850">850</a></span>
<span class="normal"><a href="#__codelineno-0-851">851</a></span>
<span class="normal"><a href="#__codelineno-0-852">852</a></span>
<span class="normal"><a href="#__codelineno-0-853">853</a></span>
<span class="normal"><a href="#__codelineno-0-854">854</a></span>
<span class="normal"><a href="#__codelineno-0-855">855</a></span>
<span class="normal"><a href="#__codelineno-0-856">856</a></span>
<span class="normal"><a href="#__codelineno-0-857">857</a></span>
<span class="normal"><a href="#__codelineno-0-858">858</a></span>
<span class="normal"><a href="#__codelineno-0-859">859</a></span>
<span class="normal"><a href="#__codelineno-0-860">860</a></span>
<span class="normal"><a href="#__codelineno-0-861">861</a></span>
<span class="normal"><a href="#__codelineno-0-862">862</a></span>
<span class="normal"><a href="#__codelineno-0-863">863</a></span>
<span class="normal"><a href="#__codelineno-0-864">864</a></span>
<span class="normal"><a href="#__codelineno-0-865">865</a></span>
<span class="normal"><a href="#__codelineno-0-866">866</a></span>
<span class="normal"><a href="#__codelineno-0-867">867</a></span>
<span class="normal"><a href="#__codelineno-0-868">868</a></span>
<span class="normal"><a href="#__codelineno-0-869">869</a></span>
<span class="normal"><a href="#__codelineno-0-870">870</a></span>
<span class="normal"><a href="#__codelineno-0-871">871</a></span>
<span class="normal"><a href="#__codelineno-0-872">872</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-832"><a id="__codelineno-0-832" name="__codelineno-0-832"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-833"><a id="__codelineno-0-833" name="__codelineno-0-833"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_norm_per_feature</span><span class="p">(</span>
</span><span id="__span-0-834"><a id="__codelineno-0-834" name="__codelineno-0-834"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-835"><a id="__codelineno-0-835" name="__codelineno-0-835"></a>    <span class="n">layer</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-836"><a id="__codelineno-0-836" name="__codelineno-0-836"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"n_layers d_sae"</span><span class="p">]:</span>
</span><span id="__span-0-837"><a id="__codelineno-0-837" name="__codelineno-0-837"></a><span class="w">    </span><span class="sd">"""</span>
</span><span id="__span-0-838"><a id="__codelineno-0-838" name="__codelineno-0-838"></a><span class="sd">    Compute the norm of decoder weights for each feature.</span>
</span><span id="__span-0-839"><a id="__codelineno-0-839" name="__codelineno-0-839"></a><span class="sd">    If layer is not None, only compute the norm for the decoder weights from layer to subsequent layers.</span>
</span><span id="__span-0-840"><a id="__codelineno-0-840" name="__codelineno-0-840"></a><span class="sd">    """</span>
</span><span id="__span-0-841"><a id="__codelineno-0-841" name="__codelineno-0-841"></a>
</span><span id="__span-0-842"><a id="__codelineno-0-842" name="__codelineno-0-842"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-843"><a id="__codelineno-0-843" name="__codelineno-0-843"></a>        <span class="n">decoder_norms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="__span-0-844"><a id="__codelineno-0-844" name="__codelineno-0-844"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
</span><span id="__span-0-845"><a id="__codelineno-0-845" name="__codelineno-0-845"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-846"><a id="__codelineno-0-846" name="__codelineno-0-846"></a>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-847"><a id="__codelineno-0-847" name="__codelineno-0-847"></a>            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-0-848"><a id="__codelineno-0-848" name="__codelineno-0-848"></a>        <span class="p">)</span>
</span><span id="__span-0-849"><a id="__codelineno-0-849" name="__codelineno-0-849"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-850"><a id="__codelineno-0-850" name="__codelineno-0-850"></a>        <span class="n">decoder_norms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="__span-0-851"><a id="__codelineno-0-851" name="__codelineno-0-851"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
</span><span id="__span-0-852"><a id="__codelineno-0-852" name="__codelineno-0-852"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-853"><a id="__codelineno-0-853" name="__codelineno-0-853"></a>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-854"><a id="__codelineno-0-854" name="__codelineno-0-854"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-855"><a id="__codelineno-0-855" name="__codelineno-0-855"></a>            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"decoder_norms"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-856"><a id="__codelineno-0-856" name="__codelineno-0-856"></a>        <span class="p">)</span>
</span><span id="__span-0-857"><a id="__codelineno-0-857" name="__codelineno-0-857"></a>    <span class="k">if</span> <span class="n">layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-858"><a id="__codelineno-0-858" name="__codelineno-0-858"></a>        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"decoders_for_layer_from"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-859"><a id="__codelineno-0-859" name="__codelineno-0-859"></a>            <span class="n">kept_layer_from</span><span class="p">,</span> <span class="n">kept_decoders</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"decoders_for_layer_from"</span><span class="p">)</span>
</span><span id="__span-0-860"><a id="__codelineno-0-860" name="__codelineno-0-860"></a>            <span class="k">assert</span> <span class="n">kept_layer_from</span> <span class="o">==</span> <span class="n">layer</span>
</span><span id="__span-0-861"><a id="__codelineno-0-861" name="__codelineno-0-861"></a>            <span class="k">for</span> <span class="n">layer_to</span><span class="p">,</span> <span class="n">decoder_weights</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kept_decoders</span><span class="p">):</span>
</span><span id="__span-0-862"><a id="__codelineno-0-862" name="__codelineno-0-862"></a>                <span class="n">layer_to</span> <span class="o">+=</span> <span class="n">layer</span>
</span><span id="__span-0-863"><a id="__codelineno-0-863" name="__codelineno-0-863"></a>                <span class="n">decoder_norms</span><span class="p">[</span><span class="n">layer_to</span><span class="p">]</span> <span class="o">=</span> <span class="n">decoder_weights</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
</span><span id="__span-0-864"><a id="__codelineno-0-864" name="__codelineno-0-864"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-865"><a id="__codelineno-0-865" name="__codelineno-0-865"></a>            <span class="k">for</span> <span class="n">layer_to</span><span class="p">,</span> <span class="n">decoder_weights</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">[</span><span class="n">layer</span><span class="p">:]):</span>
</span><span id="__span-0-866"><a id="__codelineno-0-866" name="__codelineno-0-866"></a>                <span class="n">layer_to</span> <span class="o">+=</span> <span class="n">layer</span>
</span><span id="__span-0-867"><a id="__codelineno-0-867" name="__codelineno-0-867"></a>                <span class="n">decoder_norms</span><span class="p">[</span><span class="n">layer_to</span><span class="p">]</span> <span class="o">=</span> <span class="n">decoder_weights</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
</span><span id="__span-0-868"><a id="__codelineno-0-868" name="__codelineno-0-868"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-869"><a id="__codelineno-0-869" name="__codelineno-0-869"></a>        <span class="k">for</span> <span class="n">layer_to</span><span class="p">,</span> <span class="n">decoder_weights</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">):</span>
</span><span id="__span-0-870"><a id="__codelineno-0-870" name="__codelineno-0-870"></a>            <span class="n">decoder_norms</span><span class="p">[:</span> <span class="n">layer_to</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">decoder_norms</span><span class="p">[:</span> <span class="n">layer_to</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">decoder_weights</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-871"><a id="__codelineno-0-871" name="__codelineno-0-871"></a>        <span class="n">decoder_norms</span> <span class="o">=</span> <span class="n">decoder_norms</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
</span><span id="__span-0-872"><a id="__codelineno-0-872" name="__codelineno-0-872"></a>    <span class="k">return</span> <span class="n">decoder_norms</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.decoder_norm_per_decoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_norm_per_decoder</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_norm_per_decoder</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="n_decoders">n_decoders</span></span><span class="p">]</span> <span class="o">|</span> <span class="n"><span title="torch.distributed.tensor.DTensor">DTensor</span></span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the L2 norm of decoder weights for each decoder (layer_from -&gt; layer_to).
Returns:
    norms: torch.Tensor or DTensor of shape (n_decoders,), where n_decoders = n_layers * (n_layers + 1) // 2</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-874">874</a></span>
<span class="normal"><a href="#__codelineno-0-875">875</a></span>
<span class="normal"><a href="#__codelineno-0-876">876</a></span>
<span class="normal"><a href="#__codelineno-0-877">877</a></span>
<span class="normal"><a href="#__codelineno-0-878">878</a></span>
<span class="normal"><a href="#__codelineno-0-879">879</a></span>
<span class="normal"><a href="#__codelineno-0-880">880</a></span>
<span class="normal"><a href="#__codelineno-0-881">881</a></span>
<span class="normal"><a href="#__codelineno-0-882">882</a></span>
<span class="normal"><a href="#__codelineno-0-883">883</a></span>
<span class="normal"><a href="#__codelineno-0-884">884</a></span>
<span class="normal"><a href="#__codelineno-0-885">885</a></span>
<span class="normal"><a href="#__codelineno-0-886">886</a></span>
<span class="normal"><a href="#__codelineno-0-887">887</a></span>
<span class="normal"><a href="#__codelineno-0-888">888</a></span>
<span class="normal"><a href="#__codelineno-0-889">889</a></span>
<span class="normal"><a href="#__codelineno-0-890">890</a></span>
<span class="normal"><a href="#__codelineno-0-891">891</a></span>
<span class="normal"><a href="#__codelineno-0-892">892</a></span>
<span class="normal"><a href="#__codelineno-0-893">893</a></span>
<span class="normal"><a href="#__codelineno-0-894">894</a></span>
<span class="normal"><a href="#__codelineno-0-895">895</a></span>
<span class="normal"><a href="#__codelineno-0-896">896</a></span>
<span class="normal"><a href="#__codelineno-0-897">897</a></span>
<span class="normal"><a href="#__codelineno-0-898">898</a></span>
<span class="normal"><a href="#__codelineno-0-899">899</a></span>
<span class="normal"><a href="#__codelineno-0-900">900</a></span>
<span class="normal"><a href="#__codelineno-0-901">901</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-874"><a id="__codelineno-0-874" name="__codelineno-0-874"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_norm_per_decoder</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"n_decoders"</span><span class="p">],</span> <span class="n">DTensor</span><span class="p">]:</span>  <span class="c1"># noqa: F821</span>
</span><span id="__span-0-875"><a id="__codelineno-0-875" name="__codelineno-0-875"></a><span class="w">    </span><span class="sd">"""Compute the L2 norm of decoder weights for each decoder (layer_from -&gt; layer_to).</span>
</span><span id="__span-0-876"><a id="__codelineno-0-876" name="__codelineno-0-876"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-877"><a id="__codelineno-0-877" name="__codelineno-0-877"></a><span class="sd">        norms: torch.Tensor or DTensor of shape (n_decoders,), where n_decoders = n_layers * (n_layers + 1) // 2</span>
</span><span id="__span-0-878"><a id="__codelineno-0-878" name="__codelineno-0-878"></a><span class="sd">    """</span>
</span><span id="__span-0-879"><a id="__codelineno-0-879" name="__codelineno-0-879"></a>    <span class="n">n_decoders</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
</span><span id="__span-0-880"><a id="__codelineno-0-880" name="__codelineno-0-880"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-881"><a id="__codelineno-0-881" name="__codelineno-0-881"></a>        <span class="n">decoder_norms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="__span-0-882"><a id="__codelineno-0-882" name="__codelineno-0-882"></a>            <span class="n">n_decoders</span><span class="p">,</span>
</span><span id="__span-0-883"><a id="__codelineno-0-883" name="__codelineno-0-883"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-884"><a id="__codelineno-0-884" name="__codelineno-0-884"></a>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-885"><a id="__codelineno-0-885" name="__codelineno-0-885"></a>            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-0-886"><a id="__codelineno-0-886" name="__codelineno-0-886"></a>        <span class="p">)</span>
</span><span id="__span-0-887"><a id="__codelineno-0-887" name="__codelineno-0-887"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-888"><a id="__codelineno-0-888" name="__codelineno-0-888"></a>        <span class="n">decoder_norms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="__span-0-889"><a id="__codelineno-0-889" name="__codelineno-0-889"></a>            <span class="n">n_decoders</span><span class="p">,</span>
</span><span id="__span-0-890"><a id="__codelineno-0-890" name="__codelineno-0-890"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-891"><a id="__codelineno-0-891" name="__codelineno-0-891"></a>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-892"><a id="__codelineno-0-892" name="__codelineno-0-892"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-893"><a id="__codelineno-0-893" name="__codelineno-0-893"></a>            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"decoder_norms"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-894"><a id="__codelineno-0-894" name="__codelineno-0-894"></a>        <span class="p">)</span>
</span><span id="__span-0-895"><a id="__codelineno-0-895" name="__codelineno-0-895"></a>    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-896"><a id="__codelineno-0-896" name="__codelineno-0-896"></a>    <span class="k">for</span> <span class="n">layer_to</span><span class="p">,</span> <span class="n">decoder_weights</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">):</span>
</span><span id="__span-0-897"><a id="__codelineno-0-897" name="__codelineno-0-897"></a>        <span class="k">for</span> <span class="n">layer_from</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer_to</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-898"><a id="__codelineno-0-898" name="__codelineno-0-898"></a>            <span class="n">decoder_norms</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">decoder_weights</span><span class="p">[</span><span class="n">layer_from</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-899"><a id="__codelineno-0-899" name="__codelineno-0-899"></a>            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="__span-0-900"><a id="__codelineno-0-900" name="__codelineno-0-900"></a>    <span class="n">decoder_norms</span> <span class="o">=</span> <span class="n">decoder_norms</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-901"><a id="__codelineno-0-901" name="__codelineno-0-901"></a>    <span class="k">return</span> <span class="n">decoder_norms</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.standardize_parameters_of_dataset_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">standardize_parameters_of_dataset_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">standardize_parameters_of_dataset_norm</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Standardize parameters for dataset-wise normalization during inference.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-903">903</a></span>
<span class="normal"><a href="#__codelineno-0-904">904</a></span>
<span class="normal"><a href="#__codelineno-0-905">905</a></span>
<span class="normal"><a href="#__codelineno-0-906">906</a></span>
<span class="normal"><a href="#__codelineno-0-907">907</a></span>
<span class="normal"><a href="#__codelineno-0-908">908</a></span>
<span class="normal"><a href="#__codelineno-0-909">909</a></span>
<span class="normal"><a href="#__codelineno-0-910">910</a></span>
<span class="normal"><a href="#__codelineno-0-911">911</a></span>
<span class="normal"><a href="#__codelineno-0-912">912</a></span>
<span class="normal"><a href="#__codelineno-0-913">913</a></span>
<span class="normal"><a href="#__codelineno-0-914">914</a></span>
<span class="normal"><a href="#__codelineno-0-915">915</a></span>
<span class="normal"><a href="#__codelineno-0-916">916</a></span>
<span class="normal"><a href="#__codelineno-0-917">917</a></span>
<span class="normal"><a href="#__codelineno-0-918">918</a></span>
<span class="normal"><a href="#__codelineno-0-919">919</a></span>
<span class="normal"><a href="#__codelineno-0-920">920</a></span>
<span class="normal"><a href="#__codelineno-0-921">921</a></span>
<span class="normal"><a href="#__codelineno-0-922">922</a></span>
<span class="normal"><a href="#__codelineno-0-923">923</a></span>
<span class="normal"><a href="#__codelineno-0-924">924</a></span>
<span class="normal"><a href="#__codelineno-0-925">925</a></span>
<span class="normal"><a href="#__codelineno-0-926">926</a></span>
<span class="normal"><a href="#__codelineno-0-927">927</a></span>
<span class="normal"><a href="#__codelineno-0-928">928</a></span>
<span class="normal"><a href="#__codelineno-0-929">929</a></span>
<span class="normal"><a href="#__codelineno-0-930">930</a></span>
<span class="normal"><a href="#__codelineno-0-931">931</a></span>
<span class="normal"><a href="#__codelineno-0-932">932</a></span>
<span class="normal"><a href="#__codelineno-0-933">933</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-903"><a id="__codelineno-0-903" name="__codelineno-0-903"></a><span class="nd">@override</span>
</span><span id="__span-0-904"><a id="__codelineno-0-904" name="__codelineno-0-904"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-905"><a id="__codelineno-0-905" name="__codelineno-0-905"></a><span class="k">def</span><span class="w"> </span><span class="nf">standardize_parameters_of_dataset_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-0-906"><a id="__codelineno-0-906" name="__codelineno-0-906"></a><span class="w">    </span><span class="sd">"""Standardize parameters for dataset-wise normalization during inference."""</span>
</span><span id="__span-0-907"><a id="__codelineno-0-907" name="__codelineno-0-907"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">norm_activation</span> <span class="o">==</span> <span class="s2">"dataset-wise"</span>
</span><span id="__span-0-908"><a id="__codelineno-0-908" name="__codelineno-0-908"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-909"><a id="__codelineno-0-909" name="__codelineno-0-909"></a>    <span class="n">dataset_average_activation_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span>
</span><span id="__span-0-910"><a id="__codelineno-0-910" name="__codelineno-0-910"></a>
</span><span id="__span-0-911"><a id="__codelineno-0-911" name="__codelineno-0-911"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">input_norm_factor</span><span class="p">(</span><span class="n">layer</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="__span-0-912"><a id="__codelineno-0-912" name="__codelineno-0-912"></a>        <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">/</span> <span class="n">dataset_average_activation_norm</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_points_in</span><span class="p">[</span><span class="n">layer</span><span class="p">]]</span>
</span><span id="__span-0-913"><a id="__codelineno-0-913" name="__codelineno-0-913"></a>
</span><span id="__span-0-914"><a id="__codelineno-0-914" name="__codelineno-0-914"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">output_norm_factor</span><span class="p">(</span><span class="n">layer</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="__span-0-915"><a id="__codelineno-0-915" name="__codelineno-0-915"></a>        <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">/</span> <span class="n">dataset_average_activation_norm</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_points_out</span><span class="p">[</span><span class="n">layer</span><span class="p">]]</span>
</span><span id="__span-0-916"><a id="__codelineno-0-916" name="__codelineno-0-916"></a>
</span><span id="__span-0-917"><a id="__codelineno-0-917" name="__codelineno-0-917"></a>    <span class="c1"># For CLT, we need to handle multiple input and output layers</span>
</span><span id="__span-0-918"><a id="__codelineno-0-918" name="__codelineno-0-918"></a>    <span class="k">for</span> <span class="n">layer_from</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="__span-0-919"><a id="__codelineno-0-919" name="__codelineno-0-919"></a>        <span class="c1"># Adjust encoder bias for this layer</span>
</span><span id="__span-0-920"><a id="__codelineno-0-920" name="__codelineno-0-920"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">layer_from</span><span class="p">]</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">input_norm_factor</span><span class="p">(</span><span class="n">layer_from</span><span class="p">))</span>
</span><span id="__span-0-921"><a id="__codelineno-0-921" name="__codelineno-0-921"></a>
</span><span id="__span-0-922"><a id="__codelineno-0-922" name="__codelineno-0-922"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">act_fn</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">"jumprelu"</span><span class="p">:</span>
</span><span id="__span-0-923"><a id="__codelineno-0-923" name="__codelineno-0-923"></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">,</span> <span class="n">JumpReLU</span><span class="p">)</span>
</span><span id="__span-0-924"><a id="__codelineno-0-924" name="__codelineno-0-924"></a>            <span class="n">threshold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="o">.</span><span class="n">log_jumprelu_threshold</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">layer_from</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
</span><span id="__span-0-925"><a id="__codelineno-0-925" name="__codelineno-0-925"></a>            <span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span> <span class="o">/</span> <span class="n">input_norm_factor</span><span class="p">(</span><span class="n">layer_from</span><span class="p">)</span>
</span><span id="__span-0-926"><a id="__codelineno-0-926" name="__codelineno-0-926"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="o">.</span><span class="n">log_jumprelu_threshold</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">layer_from</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
</span><span id="__span-0-927"><a id="__codelineno-0-927" name="__codelineno-0-927"></a>
</span><span id="__span-0-928"><a id="__codelineno-0-928" name="__codelineno-0-928"></a>    <span class="k">for</span> <span class="n">layer_to</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="__span-0-929"><a id="__codelineno-0-929" name="__codelineno-0-929"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="p">[</span><span class="n">layer_to</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">output_norm_factor</span><span class="p">(</span><span class="n">layer_to</span><span class="p">))</span>
</span><span id="__span-0-930"><a id="__codelineno-0-930" name="__codelineno-0-930"></a>        <span class="k">for</span> <span class="n">layer_from</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer_to</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-931"><a id="__codelineno-0-931" name="__codelineno-0-931"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">W_D</span><span class="p">[</span><span class="n">layer_to</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">layer_from</span><span class="p">]</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">input_norm_factor</span><span class="p">(</span><span class="n">layer_from</span><span class="p">)</span> <span class="o">/</span> <span class="n">output_norm_factor</span><span class="p">(</span><span class="n">layer_to</span><span class="p">))</span>
</span><span id="__span-0-932"><a id="__codelineno-0-932" name="__codelineno-0-932"></a>
</span><span id="__span-0-933"><a id="__codelineno-0-933" name="__codelineno-0-933"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">norm_activation</span> <span class="o">=</span> <span class="s2">"inference"</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.prepare_input" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_input</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">prepare_input</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">],</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare input tensor from batch by stacking all layer activations from hook_points_in.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-940">940</a></span>
<span class="normal"><a href="#__codelineno-0-941">941</a></span>
<span class="normal"><a href="#__codelineno-0-942">942</a></span>
<span class="normal"><a href="#__codelineno-0-943">943</a></span>
<span class="normal"><a href="#__codelineno-0-944">944</a></span>
<span class="normal"><a href="#__codelineno-0-945">945</a></span>
<span class="normal"><a href="#__codelineno-0-946">946</a></span>
<span class="normal"><a href="#__codelineno-0-947">947</a></span>
<span class="normal"><a href="#__codelineno-0-948">948</a></span>
<span class="normal"><a href="#__codelineno-0-949">949</a></span>
<span class="normal"><a href="#__codelineno-0-950">950</a></span>
<span class="normal"><a href="#__codelineno-0-951">951</a></span>
<span class="normal"><a href="#__codelineno-0-952">952</a></span>
<span class="normal"><a href="#__codelineno-0-953">953</a></span>
<span class="normal"><a href="#__codelineno-0-954">954</a></span>
<span class="normal"><a href="#__codelineno-0-955">955</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-940"><a id="__codelineno-0-940" name="__codelineno-0-940"></a><span class="nd">@override</span>
</span><span id="__span-0-941"><a id="__codelineno-0-941" name="__codelineno-0-941"></a><span class="k">def</span><span class="w"> </span><span class="nf">prepare_input</span><span class="p">(</span>
</span><span id="__span-0-942"><a id="__codelineno-0-942" name="__codelineno-0-942"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="s2">"dict[str, torch.Tensor]"</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="__span-0-943"><a id="__codelineno-0-943" name="__codelineno-0-943"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"tuple[torch.Tensor, dict[str, Any], dict[str, Any]]"</span><span class="p">:</span>
</span><span id="__span-0-944"><a id="__codelineno-0-944" name="__codelineno-0-944"></a><span class="w">    </span><span class="sd">"""Prepare input tensor from batch by stacking all layer activations from hook_points_in."""</span>
</span><span id="__span-0-945"><a id="__codelineno-0-945" name="__codelineno-0-945"></a>    <span class="n">x_layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-946"><a id="__codelineno-0-946" name="__codelineno-0-946"></a>    <span class="k">for</span> <span class="n">hook_point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_points_in</span><span class="p">:</span>
</span><span id="__span-0-947"><a id="__codelineno-0-947" name="__codelineno-0-947"></a>        <span class="k">if</span> <span class="n">hook_point</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
</span><span id="__span-0-948"><a id="__codelineno-0-948" name="__codelineno-0-948"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Missing hook point </span><span class="si">{</span><span class="n">hook_point</span><span class="si">}</span><span class="s2"> in batch"</span><span class="p">)</span>
</span><span id="__span-0-949"><a id="__codelineno-0-949" name="__codelineno-0-949"></a>        <span class="n">x_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">hook_point</span><span class="p">])</span>
</span><span id="__span-0-950"><a id="__codelineno-0-950" name="__codelineno-0-950"></a>    <span class="c1"># it is a bug of DTensor, ideally, we should stack along dim=-2,but it will cause an error on shard dim.</span>
</span><span id="__span-0-951"><a id="__codelineno-0-951" name="__codelineno-0-951"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_layers</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">x_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (..., n_layers, d_model)</span>
</span><span id="__span-0-952"><a id="__codelineno-0-952" name="__codelineno-0-952"></a>
</span><span id="__span-0-953"><a id="__codelineno-0-953" name="__codelineno-0-953"></a>    <span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="__span-0-954"><a id="__codelineno-0-954" name="__codelineno-0-954"></a>    <span class="n">decoder_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="__span-0-955"><a id="__codelineno-0-955" name="__codelineno-0-955"></a>    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">encoder_kwargs</span><span class="p">,</span> <span class="n">decoder_kwargs</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.prepare_input_single_layer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_input_single_layer</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">prepare_input_single_layer</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span> <span class="n">layer</span><span class="p">:</span> <span class="n"><span title="int">int</span></span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">],</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare input tensor from batch by stacking all layer activations from hook_points_in.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-957">957</a></span>
<span class="normal"><a href="#__codelineno-0-958">958</a></span>
<span class="normal"><a href="#__codelineno-0-959">959</a></span>
<span class="normal"><a href="#__codelineno-0-960">960</a></span>
<span class="normal"><a href="#__codelineno-0-961">961</a></span>
<span class="normal"><a href="#__codelineno-0-962">962</a></span>
<span class="normal"><a href="#__codelineno-0-963">963</a></span>
<span class="normal"><a href="#__codelineno-0-964">964</a></span>
<span class="normal"><a href="#__codelineno-0-965">965</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-957"><a id="__codelineno-0-957" name="__codelineno-0-957"></a><span class="k">def</span><span class="w"> </span><span class="nf">prepare_input_single_layer</span><span class="p">(</span>
</span><span id="__span-0-958"><a id="__codelineno-0-958" name="__codelineno-0-958"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="s2">"dict[str, torch.Tensor]"</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="__span-0-959"><a id="__codelineno-0-959" name="__codelineno-0-959"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"tuple[torch.Tensor, dict[str, Any], dict[str, Any]]"</span><span class="p">:</span>
</span><span id="__span-0-960"><a id="__codelineno-0-960" name="__codelineno-0-960"></a><span class="w">    </span><span class="sd">"""Prepare input tensor from batch by stacking all layer activations from hook_points_in."""</span>
</span><span id="__span-0-961"><a id="__codelineno-0-961" name="__codelineno-0-961"></a>    <span class="n">hook_point_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_points_in</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span>
</span><span id="__span-0-962"><a id="__codelineno-0-962" name="__codelineno-0-962"></a>    <span class="k">if</span> <span class="n">hook_point_in</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
</span><span id="__span-0-963"><a id="__codelineno-0-963" name="__codelineno-0-963"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Missing hook point </span><span class="si">{</span><span class="n">hook_point_in</span><span class="si">}</span><span class="s2"> in batch"</span><span class="p">)</span>
</span><span id="__span-0-964"><a id="__codelineno-0-964" name="__codelineno-0-964"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">hook_point_in</span><span class="p">]</span>
</span><span id="__span-0-965"><a id="__codelineno-0-965" name="__codelineno-0-965"></a>    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="p">{},</span> <span class="p">{}</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.prepare_label" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_label</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">prepare_label</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare label tensor from batch using hook_points_out.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-967">967</a></span>
<span class="normal"><a href="#__codelineno-0-968">968</a></span>
<span class="normal"><a href="#__codelineno-0-969">969</a></span>
<span class="normal"><a href="#__codelineno-0-970">970</a></span>
<span class="normal"><a href="#__codelineno-0-971">971</a></span>
<span class="normal"><a href="#__codelineno-0-972">972</a></span>
<span class="normal"><a href="#__codelineno-0-973">973</a></span>
<span class="normal"><a href="#__codelineno-0-974">974</a></span>
<span class="normal"><a href="#__codelineno-0-975">975</a></span>
<span class="normal"><a href="#__codelineno-0-976">976</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-967"><a id="__codelineno-0-967" name="__codelineno-0-967"></a><span class="nd">@override</span>
</span><span id="__span-0-968"><a id="__codelineno-0-968" name="__codelineno-0-968"></a><span class="k">def</span><span class="w"> </span><span class="nf">prepare_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="s2">"dict[str, torch.Tensor]"</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-969"><a id="__codelineno-0-969" name="__codelineno-0-969"></a><span class="w">    </span><span class="sd">"""Prepare label tensor from batch using hook_points_out."""</span>
</span><span id="__span-0-970"><a id="__codelineno-0-970" name="__codelineno-0-970"></a>    <span class="n">x_layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-971"><a id="__codelineno-0-971" name="__codelineno-0-971"></a>    <span class="k">for</span> <span class="n">hook_point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_points_out</span><span class="p">:</span>
</span><span id="__span-0-972"><a id="__codelineno-0-972" name="__codelineno-0-972"></a>        <span class="k">if</span> <span class="n">hook_point</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
</span><span id="__span-0-973"><a id="__codelineno-0-973" name="__codelineno-0-973"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Missing hook point </span><span class="si">{</span><span class="n">hook_point</span><span class="si">}</span><span class="s2"> in batch"</span><span class="p">)</span>
</span><span id="__span-0-974"><a id="__codelineno-0-974" name="__codelineno-0-974"></a>        <span class="n">x_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">hook_point</span><span class="p">])</span>
</span><span id="__span-0-975"><a id="__codelineno-0-975" name="__codelineno-0-975"></a>    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_layers</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (n_layers, ..., d_model)</span>
</span><span id="__span-0-976"><a id="__codelineno-0-976" name="__codelineno-0-976"></a>    <span class="k">return</span> <span class="n">labels</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.compute_training_metrics" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">compute_training_metrics</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_training_metrics</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">l0</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">explained_variance_legacy</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="float">float</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute per-layer training metrics for CLT.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-978">978</a></span>
<span class="normal"><a href="#__codelineno-0-979">979</a></span>
<span class="normal"><a href="#__codelineno-0-980">980</a></span>
<span class="normal"><a href="#__codelineno-0-981">981</a></span>
<span class="normal"><a href="#__codelineno-0-982">982</a></span>
<span class="normal"><a href="#__codelineno-0-983">983</a></span>
<span class="normal"><a href="#__codelineno-0-984">984</a></span>
<span class="normal"><a href="#__codelineno-0-985">985</a></span>
<span class="normal"><a href="#__codelineno-0-986">986</a></span>
<span class="normal"><a href="#__codelineno-0-987">987</a></span>
<span class="normal"><a href="#__codelineno-0-988">988</a></span>
<span class="normal"><a href="#__codelineno-0-989">989</a></span>
<span class="normal"><a href="#__codelineno-0-990">990</a></span>
<span class="normal"><a href="#__codelineno-0-991">991</a></span>
<span class="normal"><a href="#__codelineno-0-992">992</a></span>
<span class="normal"><a href="#__codelineno-0-993">993</a></span>
<span class="normal"><a href="#__codelineno-0-994">994</a></span>
<span class="normal"><a href="#__codelineno-0-995">995</a></span>
<span class="normal"><a href="#__codelineno-0-996">996</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-978"><a id="__codelineno-0-978" name="__codelineno-0-978"></a><span class="nd">@override</span>
</span><span id="__span-0-979"><a id="__codelineno-0-979" name="__codelineno-0-979"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-980"><a id="__codelineno-0-980" name="__codelineno-0-980"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_training_metrics</span><span class="p">(</span>
</span><span id="__span-0-981"><a id="__codelineno-0-981" name="__codelineno-0-981"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-982"><a id="__codelineno-0-982" name="__codelineno-0-982"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-983"><a id="__codelineno-0-983" name="__codelineno-0-983"></a>    <span class="n">l0</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-984"><a id="__codelineno-0-984" name="__codelineno-0-984"></a>    <span class="n">explained_variance_legacy</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-985"><a id="__codelineno-0-985" name="__codelineno-0-985"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-986"><a id="__codelineno-0-986" name="__codelineno-0-986"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-987"><a id="__codelineno-0-987" name="__codelineno-0-987"></a><span class="w">    </span><span class="sd">"""Compute per-layer training metrics for CLT."""</span>
</span><span id="__span-0-988"><a id="__codelineno-0-988" name="__codelineno-0-988"></a>    <span class="k">assert</span> <span class="n">explained_variance_legacy</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">explained_variance_legacy</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="p">(</span>
</span><span id="__span-0-989"><a id="__codelineno-0-989" name="__codelineno-0-989"></a>        <span class="sa">f</span><span class="s2">"explained_variance_legacy should be of shape (n_layers,), but got </span><span class="si">{</span><span class="n">explained_variance_legacy</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span>
</span><span id="__span-0-990"><a id="__codelineno-0-990" name="__codelineno-0-990"></a>    <span class="p">)</span>
</span><span id="__span-0-991"><a id="__codelineno-0-991" name="__codelineno-0-991"></a>    <span class="n">clt_per_layer_ev_dict</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-992"><a id="__codelineno-0-992" name="__codelineno-0-992"></a>        <span class="sa">f</span><span class="s2">"metrics/explained_variance_L</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2">"</span><span class="p">:</span> <span class="n">item</span><span class="p">(</span><span class="n">explained_variance_legacy</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span><span id="__span-0-993"><a id="__codelineno-0-993" name="__codelineno-0-993"></a>        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">explained_variance_legacy</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</span><span id="__span-0-994"><a id="__codelineno-0-994" name="__codelineno-0-994"></a>    <span class="p">}</span>
</span><span id="__span-0-995"><a id="__codelineno-0-995" name="__codelineno-0-995"></a>    <span class="n">clt_per_layer_l0_dict</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">"metrics/l0_layer</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2">"</span><span class="p">:</span> <span class="n">item</span><span class="p">(</span><span class="n">l0</span><span class="p">[:,</span> <span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">l0</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))}</span>
</span><span id="__span-0-996"><a id="__codelineno-0-996" name="__codelineno-0-996"></a>    <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">clt_per_layer_ev_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">clt_per_layer_l0_dict</span><span class="p">}</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.compute_loss" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">compute_loss</span>


</h3>
          <div class="doc-overloads">
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_loss</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">sparsity_loss_type</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>        <span class="s2">"power"</span><span class="p">,</span> <span class="s2">"tanh"</span><span class="p">,</span> <span class="s2">"tanh-quad"</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">tanh_stretch_coefficient</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">p</span><span class="p">:</span> <span class="n"><span title="int">int</span></span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">l1_coefficient</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">return_aux_data</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">]</span>
</span></code></pre></div><div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_loss</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">sparsity_loss_type</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>        <span class="s2">"power"</span><span class="p">,</span> <span class="s2">"tanh"</span><span class="p">,</span> <span class="s2">"tanh-quad"</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">tanh_stretch_coefficient</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">p</span><span class="p">:</span> <span class="n"><span title="int">int</span></span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">l1_coefficient</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">return_aux_data</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">False</span><span class="p">],</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">" batch"</span><span class="p">]</span>
</span></code></pre></div>          </div>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_loss</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">label</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">]</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">sparsity_loss_type</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        <span class="s2">"power"</span><span class="p">,</span> <span class="s2">"tanh"</span><span class="p">,</span> <span class="s2">"tanh-quad"</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">tanh_stretch_coefficient</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">frequency_scale</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">p</span><span class="p">:</span> <span class="n"><span title="int">int</span></span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">l1_coefficient</span><span class="p">:</span> <span class="n"><span title="float">float</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">return_aux_data</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">" batch"</span><span class="p">]</span> <span class="o">|</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the loss for the autoencoder.
Ensure that the input activations are normalized by calling <code>normalize_activations</code> before calling this method.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span>
<span class="normal"><a href="#__codelineno-0-1042">1042</a></span>
<span class="normal"><a href="#__codelineno-0-1043">1043</a></span>
<span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span>
<span class="normal"><a href="#__codelineno-0-1054">1054</a></span>
<span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span>
<span class="normal"><a href="#__codelineno-0-1085">1085</a></span>
<span class="normal"><a href="#__codelineno-0-1086">1086</a></span>
<span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1024"><a id="__codelineno-0-1024" name="__codelineno-0-1024"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"compute_loss"</span><span class="p">)</span>
</span><span id="__span-0-1025"><a id="__codelineno-0-1025" name="__codelineno-0-1025"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span>
</span><span id="__span-0-1026"><a id="__codelineno-0-1026" name="__codelineno-0-1026"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-1027"><a id="__codelineno-0-1027" name="__codelineno-0-1027"></a>    <span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-1028"><a id="__codelineno-0-1028" name="__codelineno-0-1028"></a>    <span class="n">label</span><span class="p">:</span> <span class="p">(</span>
</span><span id="__span-0-1029"><a id="__codelineno-0-1029" name="__codelineno-0-1029"></a>        <span class="n">Optional</span><span class="p">[</span>
</span><span id="__span-0-1030"><a id="__codelineno-0-1030" name="__codelineno-0-1030"></a>            <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-1031"><a id="__codelineno-0-1031" name="__codelineno-0-1031"></a>                <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">],</span>
</span><span id="__span-0-1032"><a id="__codelineno-0-1032" name="__codelineno-0-1032"></a>                <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-1033"><a id="__codelineno-0-1033" name="__codelineno-0-1033"></a>            <span class="p">]</span>
</span><span id="__span-0-1034"><a id="__codelineno-0-1034" name="__codelineno-0-1034"></a>        <span class="p">]</span>
</span><span id="__span-0-1035"><a id="__codelineno-0-1035" name="__codelineno-0-1035"></a>    <span class="p">)</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1036"><a id="__codelineno-0-1036" name="__codelineno-0-1036"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-1037"><a id="__codelineno-0-1037" name="__codelineno-0-1037"></a>    <span class="n">sparsity_loss_type</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">"power"</span><span class="p">,</span> <span class="s2">"tanh"</span><span class="p">,</span> <span class="s2">"tanh-quad"</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1038"><a id="__codelineno-0-1038" name="__codelineno-0-1038"></a>    <span class="n">tanh_stretch_coefficient</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
</span><span id="__span-0-1039"><a id="__codelineno-0-1039" name="__codelineno-0-1039"></a>    <span class="n">frequency_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
</span><span id="__span-0-1040"><a id="__codelineno-0-1040" name="__codelineno-0-1040"></a>    <span class="n">p</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-1041"><a id="__codelineno-0-1041" name="__codelineno-0-1041"></a>    <span class="n">l1_coefficient</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-1042"><a id="__codelineno-0-1042" name="__codelineno-0-1042"></a>    <span class="n">return_aux_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-1043"><a id="__codelineno-0-1043" name="__codelineno-0-1043"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-1044"><a id="__codelineno-0-1044" name="__codelineno-0-1044"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-1045"><a id="__codelineno-0-1045" name="__codelineno-0-1045"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">" batch"</span><span class="p">],</span>
</span><span id="__span-0-1046"><a id="__codelineno-0-1046" name="__codelineno-0-1046"></a>    <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
</span><span id="__span-0-1047"><a id="__codelineno-0-1047" name="__codelineno-0-1047"></a><span class="p">]:</span>
</span><span id="__span-0-1048"><a id="__codelineno-0-1048" name="__codelineno-0-1048"></a><span class="w">    </span><span class="sd">"""Compute the loss for the autoencoder.</span>
</span><span id="__span-0-1049"><a id="__codelineno-0-1049" name="__codelineno-0-1049"></a><span class="sd">    Ensure that the input activations are normalized by calling `normalize_activations` before calling this method.</span>
</span><span id="__span-0-1050"><a id="__codelineno-0-1050" name="__codelineno-0-1050"></a><span class="sd">    """</span>
</span><span id="__span-0-1051"><a id="__codelineno-0-1051" name="__codelineno-0-1051"></a>    <span class="n">x</span><span class="p">,</span> <span class="n">encoder_kwargs</span><span class="p">,</span> <span class="n">decoder_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_input</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="__span-0-1052"><a id="__codelineno-0-1052" name="__codelineno-0-1052"></a>    <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_label</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="__span-0-1053"><a id="__codelineno-0-1053" name="__codelineno-0-1053"></a>
</span><span id="__span-0-1054"><a id="__codelineno-0-1054" name="__codelineno-0-1054"></a>    <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"encode"</span><span class="p">):</span>
</span><span id="__span-0-1055"><a id="__codelineno-0-1055" name="__codelineno-0-1055"></a>        <span class="n">feature_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_kwargs</span><span class="p">)</span>
</span><span id="__span-0-1056"><a id="__codelineno-0-1056" name="__codelineno-0-1056"></a>
</span><span id="__span-0-1057"><a id="__codelineno-0-1057" name="__codelineno-0-1057"></a>    <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"decode"</span><span class="p">):</span>
</span><span id="__span-0-1058"><a id="__codelineno-0-1058" name="__codelineno-0-1058"></a>        <span class="n">reconstructed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="o">**</span><span class="n">decoder_kwargs</span><span class="p">)</span>
</span><span id="__span-0-1059"><a id="__codelineno-0-1059" name="__codelineno-0-1059"></a>
</span><span id="__span-0-1060"><a id="__codelineno-0-1060" name="__codelineno-0-1060"></a>    <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"loss_calculation"</span><span class="p">):</span>
</span><span id="__span-0-1061"><a id="__codelineno-0-1061" name="__codelineno-0-1061"></a>        <span class="n">l_rec</span> <span class="o">=</span> <span class="p">(</span><span class="n">reconstructed</span> <span class="o">-</span> <span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-1062"><a id="__codelineno-0-1062" name="__codelineno-0-1062"></a>        <span class="n">l_rec</span> <span class="o">=</span> <span class="n">l_rec</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="__span-0-1063"><a id="__codelineno-0-1063" name="__codelineno-0-1063"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">l_rec</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-1064"><a id="__codelineno-0-1064" name="__codelineno-0-1064"></a>            <span class="n">l_rec</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">l_rec</span><span class="o">.</span><span class="n">full_tensor</span><span class="p">()</span>
</span><span id="__span-0-1065"><a id="__codelineno-0-1065" name="__codelineno-0-1065"></a>        <span class="n">loss_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-1066"><a id="__codelineno-0-1066" name="__codelineno-0-1066"></a>            <span class="s2">"l_rec"</span><span class="p">:</span> <span class="n">l_rec</span><span class="p">,</span>
</span><span id="__span-0-1067"><a id="__codelineno-0-1067" name="__codelineno-0-1067"></a>        <span class="p">}</span>
</span><span id="__span-0-1068"><a id="__codelineno-0-1068" name="__codelineno-0-1068"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="n">l_rec</span>
</span><span id="__span-0-1069"><a id="__codelineno-0-1069" name="__codelineno-0-1069"></a>
</span><span id="__span-0-1070"><a id="__codelineno-0-1070" name="__codelineno-0-1070"></a>        <span class="k">if</span> <span class="n">sparsity_loss_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-1071"><a id="__codelineno-0-1071" name="__codelineno-0-1071"></a>            <span class="n">decoder_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"n_layers d_sae"</span><span class="p">],</span> <span class="n">DTensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm_per_feature</span><span class="p">()</span>
</span><span id="__span-0-1072"><a id="__codelineno-0-1072" name="__codelineno-0-1072"></a>            <span class="k">with</span> <span class="n">timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"sparsity_loss_calculation"</span><span class="p">):</span>
</span><span id="__span-0-1073"><a id="__codelineno-0-1073" name="__codelineno-0-1073"></a>                <span class="k">if</span> <span class="n">sparsity_loss_type</span> <span class="o">==</span> <span class="s2">"power"</span><span class="p">:</span>
</span><span id="__span-0-1074"><a id="__codelineno-0-1074" name="__codelineno-0-1074"></a>                    <span class="n">l_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">feature_acts</span> <span class="o">*</span> <span class="n">decoder_norm</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-1075"><a id="__codelineno-0-1075" name="__codelineno-0-1075"></a>                <span class="k">elif</span> <span class="n">sparsity_loss_type</span> <span class="o">==</span> <span class="s2">"tanh"</span><span class="p">:</span>
</span><span id="__span-0-1076"><a id="__codelineno-0-1076" name="__codelineno-0-1076"></a>                    <span class="n">l_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tanh_stretch_coefficient</span> <span class="o">*</span> <span class="n">feature_acts</span> <span class="o">*</span> <span class="n">decoder_norm</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-1077"><a id="__codelineno-0-1077" name="__codelineno-0-1077"></a>                <span class="k">elif</span> <span class="n">sparsity_loss_type</span> <span class="o">==</span> <span class="s2">"tanh-quad"</span><span class="p">:</span>
</span><span id="__span-0-1078"><a id="__codelineno-0-1078" name="__codelineno-0-1078"></a>                    <span class="n">approx_frequency</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
</span><span id="__span-0-1079"><a id="__codelineno-0-1079" name="__codelineno-0-1079"></a>                        <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tanh_stretch_coefficient</span> <span class="o">*</span> <span class="n">feature_acts</span> <span class="o">*</span> <span class="n">decoder_norm</span><span class="p">),</span>
</span><span id="__span-0-1080"><a id="__codelineno-0-1080" name="__codelineno-0-1080"></a>                        <span class="s2">"... d_sae -&gt; d_sae"</span><span class="p">,</span>
</span><span id="__span-0-1081"><a id="__codelineno-0-1081" name="__codelineno-0-1081"></a>                        <span class="s2">"mean"</span><span class="p">,</span>
</span><span id="__span-0-1082"><a id="__codelineno-0-1082" name="__codelineno-0-1082"></a>                    <span class="p">)</span>
</span><span id="__span-0-1083"><a id="__codelineno-0-1083" name="__codelineno-0-1083"></a>                    <span class="n">l_s</span> <span class="o">=</span> <span class="p">(</span><span class="n">approx_frequency</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">approx_frequency</span> <span class="o">/</span> <span class="n">frequency_scale</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-1084"><a id="__codelineno-0-1084" name="__codelineno-0-1084"></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1085"><a id="__codelineno-0-1085" name="__codelineno-0-1085"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"sparsity_loss_type f</span><span class="si">{</span><span class="n">sparsity_loss_type</span><span class="si">}</span><span class="s2"> not supported."</span><span class="p">)</span>
</span><span id="__span-0-1086"><a id="__codelineno-0-1086" name="__codelineno-0-1086"></a>                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">l_s</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-1087"><a id="__codelineno-0-1087" name="__codelineno-0-1087"></a>                    <span class="n">l_s</span> <span class="o">=</span> <span class="n">l_s</span><span class="o">.</span><span class="n">full_tensor</span><span class="p">()</span>
</span><span id="__span-0-1088"><a id="__codelineno-0-1088" name="__codelineno-0-1088"></a>                <span class="n">l_s</span> <span class="o">=</span> <span class="n">l1_coefficient</span> <span class="o">*</span> <span class="n">l_s</span>
</span><span id="__span-0-1089"><a id="__codelineno-0-1089" name="__codelineno-0-1089"></a>                <span class="c1"># WARNING: Some DTensor bugs make if l1_coefficient * l_s goes before full_tensor, the l1_coefficient value will be internally cached. Furthermore, it will cause the backward pass to fail with redistribution error. See https://github.com/pytorch/pytorch/issues/153603 and https://github.com/pytorch/pytorch/issues/153615 .</span>
</span><span id="__span-0-1090"><a id="__codelineno-0-1090" name="__codelineno-0-1090"></a>                <span class="n">loss_dict</span><span class="p">[</span><span class="s2">"l_s"</span><span class="p">]</span> <span class="o">=</span> <span class="n">l_s</span>
</span><span id="__span-0-1091"><a id="__codelineno-0-1091" name="__codelineno-0-1091"></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">l_s</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="__span-0-1092"><a id="__codelineno-0-1092" name="__codelineno-0-1092"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1093"><a id="__codelineno-0-1093" name="__codelineno-0-1093"></a>            <span class="n">loss_dict</span><span class="p">[</span><span class="s2">"l_s"</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-1094"><a id="__codelineno-0-1094" name="__codelineno-0-1094"></a>
</span><span id="__span-0-1095"><a id="__codelineno-0-1095" name="__codelineno-0-1095"></a>    <span class="k">if</span> <span class="n">return_aux_data</span><span class="p">:</span>
</span><span id="__span-0-1096"><a id="__codelineno-0-1096" name="__codelineno-0-1096"></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="__span-0-1097"><a id="__codelineno-0-1097" name="__codelineno-0-1097"></a>            <span class="s2">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
</span><span id="__span-0-1098"><a id="__codelineno-0-1098" name="__codelineno-0-1098"></a>            <span class="o">**</span><span class="n">loss_dict</span><span class="p">,</span>
</span><span id="__span-0-1099"><a id="__codelineno-0-1099" name="__codelineno-0-1099"></a>            <span class="s2">"label"</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span>
</span><span id="__span-0-1100"><a id="__codelineno-0-1100" name="__codelineno-0-1100"></a>            <span class="s2">"mask"</span><span class="p">:</span> <span class="n">batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"mask"</span><span class="p">),</span>
</span><span id="__span-0-1101"><a id="__codelineno-0-1101" name="__codelineno-0-1101"></a>            <span class="s2">"n_tokens"</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"tokens"</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">if</span> <span class="n">batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"mask"</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">item</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">"mask"</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">())),</span>
</span><span id="__span-0-1102"><a id="__codelineno-0-1102" name="__codelineno-0-1102"></a>            <span class="s2">"feature_acts"</span><span class="p">:</span> <span class="n">feature_acts</span><span class="p">,</span>
</span><span id="__span-0-1103"><a id="__codelineno-0-1103" name="__codelineno-0-1103"></a>            <span class="s2">"reconstructed"</span><span class="p">:</span> <span class="n">reconstructed</span><span class="p">,</span>
</span><span id="__span-0-1104"><a id="__codelineno-0-1104" name="__codelineno-0-1104"></a>        <span class="p">}</span>
</span><span id="__span-0-1105"><a id="__codelineno-0-1105" name="__codelineno-0-1105"></a>    <span class="k">return</span> <span class="n">loss</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.CrossLayerTranscoder.dim_maps" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">dim_maps</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">dim_maps</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="lm_saes.utils.distributed.DimMap">DimMap</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return dimension maps for distributed training along feature dimension.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/clt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1112"><a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="k">def</span><span class="w"> </span><span class="nf">dim_maps</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"dict[str, DimMap]"</span><span class="p">:</span>
</span><span id="__span-0-1113"><a id="__codelineno-0-1113" name="__codelineno-0-1113"></a><span class="w">    </span><span class="sd">"""Return dimension maps for distributed training along feature dimension."""</span>
</span><span id="__span-0-1114"><a id="__codelineno-0-1114" name="__codelineno-0-1114"></a>    <span class="n">base_maps</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()</span>
</span><span id="__span-0-1115"><a id="__codelineno-0-1115" name="__codelineno-0-1115"></a>
</span><span id="__span-0-1116"><a id="__codelineno-0-1116" name="__codelineno-0-1116"></a>    <span class="n">clt_maps</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-1117"><a id="__codelineno-0-1117" name="__codelineno-0-1117"></a>        <span class="s2">"W_E"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">2</span><span class="p">}),</span>  <span class="c1"># Shard along d_sae dimension</span>
</span><span id="__span-0-1118"><a id="__codelineno-0-1118" name="__codelineno-0-1118"></a>        <span class="s2">"b_E"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>  <span class="c1"># Shard along d_sae dimension</span>
</span><span id="__span-0-1119"><a id="__codelineno-0-1119" name="__codelineno-0-1119"></a>        <span class="s2">"W_D"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>  <span class="c1"># Shard along d_sae dimension</span>
</span><span id="__span-0-1120"><a id="__codelineno-0-1120" name="__codelineno-0-1120"></a>        <span class="s2">"b_D"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({}),</span>  <span class="c1"># Replicate decoder biases</span>
</span><span id="__span-0-1121"><a id="__codelineno-0-1121" name="__codelineno-0-1121"></a>        <span class="s2">"decoder_norms"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>  <span class="c1"># Shard along d_sae dimension</span>
</span><span id="__span-0-1122"><a id="__codelineno-0-1122" name="__codelineno-0-1122"></a>    <span class="p">}</span>
</span><span id="__span-0-1123"><a id="__codelineno-0-1123" name="__codelineno-0-1123"></a>
</span><span id="__span-0-1124"><a id="__codelineno-0-1124" name="__codelineno-0-1124"></a>    <span class="k">return</span> <span class="n">base_maps</span> <span class="o">|</span> <span class="n">clt_maps</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.LorsaConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">LorsaConfig</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            BaseSAEConfig


  
      pydantic-model
   (lm_saes.abstract_sae.BaseSAEConfig)" href="#lm_saes.BaseSAEConfig">BaseSAEConfig</a></code></p>

        <p>Configuration for Low Rank Sparse Attention.</p>

    

        <p>Fields:</p>
        <ul>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.device">device</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.dtype">dtype</span></code>
                (<code><span title="torch.dtype">dtype</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            d_model


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.d_model)" href="#lm_saes.BaseSAEConfig.d_model">d_model</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            expansion_factor


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.expansion_factor)" href="#lm_saes.BaseSAEConfig.expansion_factor">expansion_factor</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_decoder_bias


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.use_decoder_bias)" href="#lm_saes.BaseSAEConfig.use_decoder_bias">use_decoder_bias</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            act_fn


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.act_fn)" href="#lm_saes.BaseSAEConfig.act_fn">act_fn</a></code>
                (<code><span title="typing.Literal">Literal</span>['relu', 'jumprelu', 'topk', 'batchtopk', 'batchlayertopk', 'layertopk']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            norm_activation


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.norm_activation)" href="#lm_saes.BaseSAEConfig.norm_activation">norm_activation</a></code>
                (<code><span title="typing.Literal">Literal</span>['token-wise', 'batch-wise', 'dataset-wise', 'inference']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_include_decoder_norm


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.sparsity_include_decoder_norm)" href="#lm_saes.BaseSAEConfig.sparsity_include_decoder_norm">sparsity_include_decoder_norm</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            top_k


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.top_k)" href="#lm_saes.BaseSAEConfig.top_k">top_k</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_triton_kernel


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.use_triton_kernel)" href="#lm_saes.BaseSAEConfig.use_triton_kernel">use_triton_kernel</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_threshold_for_triton_spmm_kernel


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.sparsity_threshold_for_triton_spmm_kernel)" href="#lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel">sparsity_threshold_for_triton_spmm_kernel</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            jumprelu_threshold_window


  
      pydantic-field
   (lm_saes.lorsa.LorsaConfig.jumprelu_threshold_window)" href="#lm_saes.BaseSAEConfig.jumprelu_threshold_window">jumprelu_threshold_window</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.sae_type">sae_type</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.hook_point_in">hook_point_in</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.hook_point_out">hook_point_out</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.n_qk_heads">n_qk_heads</span></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.d_qk_head">d_qk_head</span></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.positional_embedding_type">positional_embedding_type</span></code>
                (<code><span title="typing.Literal">Literal</span>['rotary', 'none']</code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.rotary_dim">rotary_dim</span></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.rotary_base">rotary_base</span></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.rotary_adjacent_pairs">rotary_adjacent_pairs</span></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.rotary_scale">rotary_scale</span></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.use_NTK_by_parts_rope">use_NTK_by_parts_rope</span></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.NTK_by_parts_factor">NTK_by_parts_factor</span></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.NTK_by_parts_low_freq_factor">NTK_by_parts_low_freq_factor</span></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.NTK_by_parts_high_freq_factor">NTK_by_parts_high_freq_factor</span></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.old_context_len">old_context_len</span></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.n_ctx">n_ctx</span></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.attn_scale">attn_scale</span></code>
                (<code><span title="float">float</span> | None</code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.use_post_qk_ln">use_post_qk_ln</span></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.normalization_type">normalization_type</span></code>
                (<code><span title="typing.Literal">Literal</span>['LN', 'RMS'] | None</code>)
            </li>
            <li>
              <code><span title="lm_saes.lorsa.LorsaConfig.eps">eps</span></code>
                (<code><span title="float">float</span></code>)
            </li>
        </ul>




<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.LorsaConfig.associated_hook_points" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">associated_hook_points</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">associated_hook_points</span><span class="p">:</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>All hook points used by Lorsa.</p>

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.LowRankSparseAttention" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">LowRankSparseAttention</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">LowRankSparseAttention</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">cfg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            LorsaConfig


  
      pydantic-model
   (lm_saes.lorsa.LorsaConfig)" href="#lm_saes.LorsaConfig">LorsaConfig</a></span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n"><span title="torch.distributed.DeviceMesh">DeviceMesh</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="lm_saes.abstract_sae.AbstractSparseAutoEncoder">AbstractSparseAutoEncoder</span></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-96"><a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">LorsaConfig</span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DeviceMesh</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="__span-0-97"><a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-98"><a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
</span><span id="__span-0-99"><a id="__codelineno-0-99" name="__codelineno-0-99"></a>
</span><span id="__span-0-100"><a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-101"><a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="c1"># Local parameters</span>
</span><span id="__span-0-102"><a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="k">def</span><span class="w"> </span><span class="nf">_get_param_with_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
</span><span id="__span-0-103"><a id="__codelineno-0-103" name="__codelineno-0-103"></a>            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-104"><a id="__codelineno-0-104" name="__codelineno-0-104"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-105"><a id="__codelineno-0-105" name="__codelineno-0-105"></a>                    <span class="n">shape</span><span class="p">,</span>
</span><span id="__span-0-106"><a id="__codelineno-0-106" name="__codelineno-0-106"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-107"><a id="__codelineno-0-107" name="__codelineno-0-107"></a>                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-0-108"><a id="__codelineno-0-108" name="__codelineno-0-108"></a>                <span class="p">)</span>
</span><span id="__span-0-109"><a id="__codelineno-0-109" name="__codelineno-0-109"></a>            <span class="p">)</span>
</span><span id="__span-0-110"><a id="__codelineno-0-110" name="__codelineno-0-110"></a>
</span><span id="__span-0-111"><a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_Q</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">))</span>
</span><span id="__span-0-112"><a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_K</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">))</span>
</span><span id="__span-0-113"><a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ov_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>
</span><span id="__span-0-114"><a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ov_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>
</span><span id="__span-0-115"><a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_Q</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">))</span>
</span><span id="__span-0-116"><a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_K</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">))</span>
</span><span id="__span-0-117"><a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_V</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ov_heads</span><span class="p">,))</span>
</span><span id="__span-0-118"><a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-119"><a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,))</span>
</span><span id="__span-0-120"><a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-121"><a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="c1"># Distributed parameters with head sharding</span>
</span><span id="__span-0-122"><a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="n">dim_maps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()</span>
</span><span id="__span-0-123"><a id="__codelineno-0-123" name="__codelineno-0-123"></a>
</span><span id="__span-0-124"><a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="k">def</span><span class="w"> </span><span class="nf">_get_param_with_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">placements</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
</span><span id="__span-0-125"><a id="__codelineno-0-125" name="__codelineno-0-125"></a>            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-126"><a id="__codelineno-0-126" name="__codelineno-0-126"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-127"><a id="__codelineno-0-127" name="__codelineno-0-127"></a>                    <span class="n">shape</span><span class="p">,</span>
</span><span id="__span-0-128"><a id="__codelineno-0-128" name="__codelineno-0-128"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-129"><a id="__codelineno-0-129" name="__codelineno-0-129"></a>                    <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-130"><a id="__codelineno-0-130" name="__codelineno-0-130"></a>                    <span class="n">placements</span><span class="o">=</span><span class="n">placements</span><span class="p">,</span>
</span><span id="__span-0-131"><a id="__codelineno-0-131" name="__codelineno-0-131"></a>                <span class="p">)</span>
</span><span id="__span-0-132"><a id="__codelineno-0-132" name="__codelineno-0-132"></a>            <span class="p">)</span>
</span><span id="__span-0-133"><a id="__codelineno-0-133" name="__codelineno-0-133"></a>
</span><span id="__span-0-134"><a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_Q</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">(</span>
</span><span id="__span-0-135"><a id="__codelineno-0-135" name="__codelineno-0-135"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">),</span>
</span><span id="__span-0-136"><a id="__codelineno-0-136" name="__codelineno-0-136"></a>            <span class="n">placements</span><span class="o">=</span><span class="n">dim_maps</span><span class="p">[</span><span class="s2">"W_Q"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-137"><a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="p">)</span>
</span><span id="__span-0-138"><a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_K</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">(</span>
</span><span id="__span-0-139"><a id="__codelineno-0-139" name="__codelineno-0-139"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">),</span>
</span><span id="__span-0-140"><a id="__codelineno-0-140" name="__codelineno-0-140"></a>            <span class="n">placements</span><span class="o">=</span><span class="n">dim_maps</span><span class="p">[</span><span class="s2">"W_K"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-141"><a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="p">)</span>
</span><span id="__span-0-142"><a id="__codelineno-0-142" name="__codelineno-0-142"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">(</span>
</span><span id="__span-0-143"><a id="__codelineno-0-143" name="__codelineno-0-143"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ov_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">),</span> <span class="n">placements</span><span class="o">=</span><span class="n">dim_maps</span><span class="p">[</span><span class="s2">"W_V"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-144"><a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="p">)</span>
</span><span id="__span-0-145"><a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">(</span>
</span><span id="__span-0-146"><a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ov_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">),</span> <span class="n">placements</span><span class="o">=</span><span class="n">dim_maps</span><span class="p">[</span><span class="s2">"W_O"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-147"><a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="p">)</span>
</span><span id="__span-0-148"><a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_Q</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">(</span>
</span><span id="__span-0-149"><a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">),</span> <span class="n">placements</span><span class="o">=</span><span class="n">dim_maps</span><span class="p">[</span><span class="s2">"b_Q"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-150"><a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="p">)</span>
</span><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_K</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">(</span>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">),</span> <span class="n">placements</span><span class="o">=</span><span class="n">dim_maps</span><span class="p">[</span><span class="s2">"b_K"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="p">)</span>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_V</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ov_heads</span><span class="p">,),</span> <span class="n">placements</span><span class="o">=</span><span class="n">dim_maps</span><span class="p">[</span><span class="s2">"b_V"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">))</span>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">_get_param_with_shape</span><span class="p">(</span>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a>                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,),</span> <span class="n">placements</span><span class="o">=</span><span class="n">dim_maps</span><span class="p">[</span><span class="s2">"b_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a>            <span class="p">)</span>
</span><span id="__span-0-159"><a id="__codelineno-0-159" name="__codelineno-0-159"></a>
</span><span id="__span-0-160"><a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="c1"># Attention mask</span>
</span><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">),</span>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a>            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="p">)</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="n">mask</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({})</span><span class="o">.</span><span class="n">distribute</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"mask"</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="n">IGNORE</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({})</span><span class="o">.</span><span class="n">distribute</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="n">IGNORE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"IGNORE"</span><span class="p">,</span> <span class="n">IGNORE</span><span class="p">)</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_post_qk_ln</span><span class="p">:</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="c1"># if self.cfg.normalization_type == "LN":</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="c1">#     # TODO: fix this</span>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a>        <span class="c1">#     pass</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">normalization_type</span> <span class="o">==</span> <span class="s2">"RMS"</span><span class="p">:</span>
</span><span id="__span-0-183"><a id="__codelineno-0-183" name="__codelineno-0-183"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">qk_ln_type</span> <span class="o">=</span> <span class="n">RMSNormPerHead</span>
</span><span id="__span-0-184"><a id="__codelineno-0-184" name="__codelineno-0-184"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Invalid normalization type for QK-norm: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">normalization_type</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">qk_ln_type</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a>
</span><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_post_qk_ln</span><span class="p">:</span>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">qk_ln_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ln_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qk_ln_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-192"><a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ln_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qk_ln_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-193"><a id="__codelineno-0-193" name="__codelineno-0-193"></a>
</span><span id="__span-0-194"><a id="__codelineno-0-194" name="__codelineno-0-194"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">positional_embedding_type</span> <span class="o">==</span> <span class="s2">"rotary"</span><span class="p">:</span>
</span><span id="__span-0-195"><a id="__codelineno-0-195" name="__codelineno-0-195"></a>        <span class="c1"># Applies a rotation to each two-element chunk of keys and queries pre dot producting to bake in relative position.</span>
</span><span id="__span-0-196"><a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">rotary_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># keep mypy happy</span>
</span><span id="__span-0-197"><a id="__codelineno-0-197" name="__codelineno-0-197"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Rotary dim must be provided for rotary positional embeddings"</span><span class="p">)</span>
</span><span id="__span-0-198"><a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="n">sin</span><span class="p">,</span> <span class="n">cos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_sin_cos_rotary</span><span class="p">(</span>
</span><span id="__span-0-199"><a id="__codelineno-0-199" name="__codelineno-0-199"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">rotary_dim</span><span class="p">,</span>
</span><span id="__span-0-200"><a id="__codelineno-0-200" name="__codelineno-0-200"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">,</span>
</span><span id="__span-0-201"><a id="__codelineno-0-201" name="__codelineno-0-201"></a>            <span class="n">base</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">rotary_base</span><span class="p">,</span>
</span><span id="__span-0-202"><a id="__codelineno-0-202" name="__codelineno-0-202"></a>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-203"><a id="__codelineno-0-203" name="__codelineno-0-203"></a>            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-0-204"><a id="__codelineno-0-204" name="__codelineno-0-204"></a>        <span class="p">)</span>
</span><span id="__span-0-205"><a id="__codelineno-0-205" name="__codelineno-0-205"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-206"><a id="__codelineno-0-206" name="__codelineno-0-206"></a>            <span class="n">sin</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({})</span><span class="o">.</span><span class="n">distribute</span><span class="p">(</span><span class="n">sin</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-207"><a id="__codelineno-0-207" name="__codelineno-0-207"></a>            <span class="n">cos</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({})</span><span class="o">.</span><span class="n">distribute</span><span class="p">(</span><span class="n">cos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-208"><a id="__codelineno-0-208" name="__codelineno-0-208"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"rotary_sin"</span><span class="p">,</span> <span class="n">sin</span><span class="p">)</span>
</span><span id="__span-0-209"><a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"rotary_cos"</span><span class="p">,</span> <span class="n">cos</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.init_parameters" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">init_parameters</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">init_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Initialize parameters.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-228"><a id="__codelineno-0-228" name="__codelineno-0-228"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="__span-0-229"><a id="__codelineno-0-229" name="__codelineno-0-229"></a><span class="w">    </span><span class="sd">"""Initialize parameters."""</span>
</span><span id="__span-0-230"><a id="__codelineno-0-230" name="__codelineno-0-230"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">init_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="__span-0-231"><a id="__codelineno-0-231" name="__codelineno-0-231"></a>
</span><span id="__span-0-232"><a id="__codelineno-0-232" name="__codelineno-0-232"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_Q</span><span class="p">)</span>
</span><span id="__span-0-233"><a id="__codelineno-0-233" name="__codelineno-0-233"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_K</span><span class="p">)</span>
</span><span id="__span-0-234"><a id="__codelineno-0-234" name="__codelineno-0-234"></a>
</span><span id="__span-0-235"><a id="__codelineno-0-235" name="__codelineno-0-235"></a>    <span class="n">W_V_bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">)</span>
</span><span id="__span-0-236"><a id="__codelineno-0-236" name="__codelineno-0-236"></a>    <span class="c1"># torch.nn.init.uniform_(self.W_V, -W_V_bound, W_V_bound)</span>
</span><span id="__span-0-237"><a id="__codelineno-0-237" name="__codelineno-0-237"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">W_V_bound</span><span class="p">)</span>
</span><span id="__span-0-238"><a id="__codelineno-0-238" name="__codelineno-0-238"></a>
</span><span id="__span-0-239"><a id="__codelineno-0-239" name="__codelineno-0-239"></a>    <span class="n">W_O_bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
</span><span id="__span-0-240"><a id="__codelineno-0-240" name="__codelineno-0-240"></a>    <span class="c1"># torch.nn.init.uniform_(self.W_O, -W_O_bound, W_O_bound)</span>
</span><span id="__span-0-241"><a id="__codelineno-0-241" name="__codelineno-0-241"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">W_O_bound</span><span class="p">)</span>
</span><span id="__span-0-242"><a id="__codelineno-0-242" name="__codelineno-0-242"></a>
</span><span id="__span-0-243"><a id="__codelineno-0-243" name="__codelineno-0-243"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_Q</span><span class="p">)</span>
</span><span id="__span-0-244"><a id="__codelineno-0-244" name="__codelineno-0-244"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_K</span><span class="p">)</span>
</span><span id="__span-0-245"><a id="__codelineno-0-245" name="__codelineno-0-245"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_V</span><span class="p">)</span>
</span><span id="__span-0-246"><a id="__codelineno-0-246" name="__codelineno-0-246"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-247"><a id="__codelineno-0-247" name="__codelineno-0-247"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.init_lorsa_with_mhsa" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">init_lorsa_with_mhsa</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">init_lorsa_with_mhsa</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">mhsa</span><span class="p">:</span> <span class="n"><span title="transformer_lens.components.Attention">Attention</span></span> <span class="o">|</span> <span class="n"><span title="transformer_lens.components.GroupedQueryAttention">GroupedQueryAttention</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Initialize Lorsa with Original Multi Head Sparse Attention</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-249"><a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-250"><a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_lorsa_with_mhsa</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mhsa</span><span class="p">:</span> <span class="n">Attention</span> <span class="o">|</span> <span class="n">GroupedQueryAttention</span><span class="p">):</span>
</span><span id="__span-0-251"><a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="w">    </span><span class="sd">"""Initialize Lorsa with Original Multi Head Sparse Attention"""</span>
</span><span id="__span-0-252"><a id="__codelineno-0-252" name="__codelineno-0-252"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span> <span class="o">%</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_Q</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="__span-0-253"><a id="__codelineno-0-253" name="__codelineno-0-253"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span> <span class="o">==</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_Q</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-254"><a id="__codelineno-0-254" name="__codelineno-0-254"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-255"><a id="__codelineno-0-255" name="__codelineno-0-255"></a>    <span class="n">input_norm_factor</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_point_in</span><span class="p">]</span>
</span><span id="__span-0-256"><a id="__codelineno-0-256" name="__codelineno-0-256"></a>    <span class="n">qk_exp_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span> <span class="o">//</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_Q</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-257"><a id="__codelineno-0-257" name="__codelineno-0-257"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-258"><a id="__codelineno-0-258" name="__codelineno-0-258"></a>        <span class="n">model_parallel_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">(</span><span class="n">mesh_dim</span><span class="o">=</span><span class="s2">"model"</span><span class="p">)</span>
</span><span id="__span-0-259"><a id="__codelineno-0-259" name="__codelineno-0-259"></a>        <span class="n">model_parallel_size</span> <span class="o">=</span> <span class="n">mesh_dim_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">)</span>
</span><span id="__span-0-260"><a id="__codelineno-0-260" name="__codelineno-0-260"></a>        <span class="n">lorsa_qk_start_idx</span> <span class="o">=</span> <span class="n">model_parallel_rank</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span> <span class="o">//</span> <span class="n">model_parallel_size</span>
</span><span id="__span-0-261"><a id="__codelineno-0-261" name="__codelineno-0-261"></a>        <span class="n">lorsa_qk_end_idx</span> <span class="o">=</span> <span class="n">lorsa_qk_start_idx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_qk_heads</span> <span class="o">//</span> <span class="n">model_parallel_size</span>
</span><span id="__span-0-262"><a id="__codelineno-0-262" name="__codelineno-0-262"></a>        <span class="n">lorsa_qk_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">lorsa_qk_start_idx</span><span class="p">,</span> <span class="n">lorsa_qk_end_idx</span><span class="p">)</span>
</span><span id="__span-0-263"><a id="__codelineno-0-263" name="__codelineno-0-263"></a>        <span class="n">W_Q_local</span> <span class="o">=</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_Q</span><span class="p">[</span><span class="n">lorsa_qk_indices</span> <span class="o">//</span> <span class="n">qk_exp_factor</span><span class="p">]</span> <span class="o">/</span> <span class="n">input_norm_factor</span>
</span><span id="__span-0-264"><a id="__codelineno-0-264" name="__codelineno-0-264"></a>        <span class="n">W_K_local</span> <span class="o">=</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_K</span><span class="p">[</span><span class="n">lorsa_qk_indices</span> <span class="o">//</span> <span class="n">qk_exp_factor</span><span class="p">]</span> <span class="o">/</span> <span class="n">input_norm_factor</span>
</span><span id="__span-0-265"><a id="__codelineno-0-265" name="__codelineno-0-265"></a>        <span class="n">W_Q</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-266"><a id="__codelineno-0-266" name="__codelineno-0-266"></a>            <span class="n">W_Q_local</span><span class="p">,</span>
</span><span id="__span-0-267"><a id="__codelineno-0-267" name="__codelineno-0-267"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-268"><a id="__codelineno-0-268" name="__codelineno-0-268"></a>            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_Q"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-269"><a id="__codelineno-0-269" name="__codelineno-0-269"></a>        <span class="p">)</span>
</span><span id="__span-0-270"><a id="__codelineno-0-270" name="__codelineno-0-270"></a>        <span class="n">W_K</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-271"><a id="__codelineno-0-271" name="__codelineno-0-271"></a>            <span class="n">W_K_local</span><span class="p">,</span>
</span><span id="__span-0-272"><a id="__codelineno-0-272" name="__codelineno-0-272"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-273"><a id="__codelineno-0-273" name="__codelineno-0-273"></a>            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_K"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-274"><a id="__codelineno-0-274" name="__codelineno-0-274"></a>        <span class="p">)</span>
</span><span id="__span-0-275"><a id="__codelineno-0-275" name="__codelineno-0-275"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_Q</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_Q</span><span class="p">)</span>
</span><span id="__span-0-276"><a id="__codelineno-0-276" name="__codelineno-0-276"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_K</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_K</span><span class="p">)</span>
</span><span id="__span-0-277"><a id="__codelineno-0-277" name="__codelineno-0-277"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_post_qk_ln</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">normalization_type</span> <span class="o">==</span> <span class="s2">"RMS"</span><span class="p">:</span>
</span><span id="__span-0-278"><a id="__codelineno-0-278" name="__codelineno-0-278"></a>            <span class="k">assert</span> <span class="n">FORKED_TL</span><span class="p">,</span> <span class="s2">"Post-QK layer normalization requires the forked TransformerLens (lmsaes)."</span>
</span><span id="__span-0-279"><a id="__codelineno-0-279" name="__codelineno-0-279"></a>            <span class="n">ln_q_w_local</span> <span class="o">=</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">ln_q</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">lorsa_qk_indices</span> <span class="o">//</span> <span class="n">qk_exp_factor</span><span class="p">]</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="__span-0-280"><a id="__codelineno-0-280" name="__codelineno-0-280"></a>            <span class="k">if</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_key_value_heads</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-281"><a id="__codelineno-0-281" name="__codelineno-0-281"></a>                <span class="n">ln_k_w_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
</span><span id="__span-0-282"><a id="__codelineno-0-282" name="__codelineno-0-282"></a>                    <span class="n">mhsa</span><span class="o">.</span><span class="n">ln_k</span><span class="o">.</span><span class="n">w</span><span class="p">,</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="__span-0-283"><a id="__codelineno-0-283" name="__codelineno-0-283"></a>                    <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">//</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_key_value_heads</span><span class="p">,</span>
</span><span id="__span-0-284"><a id="__codelineno-0-284" name="__codelineno-0-284"></a>                    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-285"><a id="__codelineno-0-285" name="__codelineno-0-285"></a>                <span class="p">)[</span><span class="n">lorsa_qk_indices</span> <span class="o">//</span> <span class="n">qk_exp_factor</span><span class="p">]</span>
</span><span id="__span-0-286"><a id="__codelineno-0-286" name="__codelineno-0-286"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-287"><a id="__codelineno-0-287" name="__codelineno-0-287"></a>                <span class="n">ln_k_w_local</span> <span class="o">=</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">ln_k</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">lorsa_qk_indices</span> <span class="o">//</span> <span class="n">qk_exp_factor</span><span class="p">]</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="__span-0-288"><a id="__codelineno-0-288" name="__codelineno-0-288"></a>            <span class="n">ln_q_w</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-289"><a id="__codelineno-0-289" name="__codelineno-0-289"></a>                <span class="n">ln_q_w_local</span><span class="p">,</span>
</span><span id="__span-0-290"><a id="__codelineno-0-290" name="__codelineno-0-290"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-291"><a id="__codelineno-0-291" name="__codelineno-0-291"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ln_q</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"w"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-292"><a id="__codelineno-0-292" name="__codelineno-0-292"></a>            <span class="p">)</span>
</span><span id="__span-0-293"><a id="__codelineno-0-293" name="__codelineno-0-293"></a>            <span class="n">ln_k_w</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-294"><a id="__codelineno-0-294" name="__codelineno-0-294"></a>                <span class="n">ln_k_w_local</span><span class="p">,</span>
</span><span id="__span-0-295"><a id="__codelineno-0-295" name="__codelineno-0-295"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-296"><a id="__codelineno-0-296" name="__codelineno-0-296"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ln_k</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"w"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-297"><a id="__codelineno-0-297" name="__codelineno-0-297"></a>            <span class="p">)</span>
</span><span id="__span-0-298"><a id="__codelineno-0-298" name="__codelineno-0-298"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ln_q</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">ln_q_w</span><span class="p">)</span>
</span><span id="__span-0-299"><a id="__codelineno-0-299" name="__codelineno-0-299"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ln_k</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">ln_k_w</span><span class="p">)</span>
</span><span id="__span-0-300"><a id="__codelineno-0-300" name="__codelineno-0-300"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-301"><a id="__codelineno-0-301" name="__codelineno-0-301"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_Q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-302"><a id="__codelineno-0-302" name="__codelineno-0-302"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">W_Q</span><span class="p">,</span> <span class="n">qk_exp_factor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">/</span> <span class="n">input_norm_factor</span>
</span><span id="__span-0-303"><a id="__codelineno-0-303" name="__codelineno-0-303"></a>        <span class="p">)</span>
</span><span id="__span-0-304"><a id="__codelineno-0-304" name="__codelineno-0-304"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_K</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-305"><a id="__codelineno-0-305" name="__codelineno-0-305"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">W_K</span><span class="p">,</span> <span class="n">qk_exp_factor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">/</span> <span class="n">input_norm_factor</span>
</span><span id="__span-0-306"><a id="__codelineno-0-306" name="__codelineno-0-306"></a>        <span class="p">)</span>
</span><span id="__span-0-307"><a id="__codelineno-0-307" name="__codelineno-0-307"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_post_qk_ln</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">normalization_type</span> <span class="o">==</span> <span class="s2">"RMS"</span><span class="p">:</span>
</span><span id="__span-0-308"><a id="__codelineno-0-308" name="__codelineno-0-308"></a>            <span class="k">assert</span> <span class="n">FORKED_TL</span><span class="p">,</span> <span class="s2">"Post-QK layer normalization requires the forked TransformerLens (lmsaes)."</span>
</span><span id="__span-0-309"><a id="__codelineno-0-309" name="__codelineno-0-309"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ln_q</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-310"><a id="__codelineno-0-310" name="__codelineno-0-310"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">ln_q</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="n">qk_exp_factor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="__span-0-311"><a id="__codelineno-0-311" name="__codelineno-0-311"></a>            <span class="p">)</span>
</span><span id="__span-0-312"><a id="__codelineno-0-312" name="__codelineno-0-312"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ln_k</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-313"><a id="__codelineno-0-313" name="__codelineno-0-313"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">ln_k</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_k</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">//</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">ln_k</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="__span-0-314"><a id="__codelineno-0-314" name="__codelineno-0-314"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-315"><a id="__codelineno-0-315" name="__codelineno-0-315"></a>                <span class="p">)</span>
</span><span id="__span-0-316"><a id="__codelineno-0-316" name="__codelineno-0-316"></a>            <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.init_W_D_with_active_subspace_per_head" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">init_W_D_with_active_subspace_per_head</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">init_W_D_with_active_subspace_per_head</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">mhsa</span><span class="p">:</span> <span class="n"><span title="transformer_lens.components.Attention">Attention</span></span> <span class="o">|</span> <span class="n"><span title="transformer_lens.components.GroupedQueryAttention">GroupedQueryAttention</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Initialize W_D with the active subspace for each head.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-318"><a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-319"><a id="__codelineno-0-319" name="__codelineno-0-319"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>
</span><span id="__span-0-320"><a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_W_D_with_active_subspace_per_head</span><span class="p">(</span>
</span><span id="__span-0-321"><a id="__codelineno-0-321" name="__codelineno-0-321"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">mhsa</span><span class="p">:</span> <span class="n">Attention</span> <span class="o">|</span> <span class="n">GroupedQueryAttention</span>
</span><span id="__span-0-322"><a id="__codelineno-0-322" name="__codelineno-0-322"></a><span class="p">):</span>
</span><span id="__span-0-323"><a id="__codelineno-0-323" name="__codelineno-0-323"></a><span class="w">    </span><span class="sd">"""</span>
</span><span id="__span-0-324"><a id="__codelineno-0-324" name="__codelineno-0-324"></a><span class="sd">    Initialize W_D with the active subspace for each head.</span>
</span><span id="__span-0-325"><a id="__codelineno-0-325" name="__codelineno-0-325"></a><span class="sd">    """</span>
</span><span id="__span-0-326"><a id="__codelineno-0-326" name="__codelineno-0-326"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_input</span><span class="p">(</span><span class="n">batch</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-0-327"><a id="__codelineno-0-327" name="__codelineno-0-327"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-328"><a id="__codelineno-0-328" name="__codelineno-0-328"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_local</span><span class="p">()</span>
</span><span id="__span-0-329"><a id="__codelineno-0-329" name="__codelineno-0-329"></a>
</span><span id="__span-0-330"><a id="__codelineno-0-330" name="__codelineno-0-330"></a>    <span class="n">captured_z</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-331"><a id="__codelineno-0-331" name="__codelineno-0-331"></a>
</span><span id="__span-0-332"><a id="__codelineno-0-332" name="__codelineno-0-332"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">capture_hook</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
</span><span id="__span-0-333"><a id="__codelineno-0-333" name="__codelineno-0-333"></a>        <span class="k">nonlocal</span> <span class="n">captured_z</span>
</span><span id="__span-0-334"><a id="__codelineno-0-334" name="__codelineno-0-334"></a>        <span class="n">captured_z</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span><span id="__span-0-335"><a id="__codelineno-0-335" name="__codelineno-0-335"></a>        <span class="k">return</span> <span class="n">tensor</span>
</span><span id="__span-0-336"><a id="__codelineno-0-336" name="__codelineno-0-336"></a>
</span><span id="__span-0-337"><a id="__codelineno-0-337" name="__codelineno-0-337"></a>    <span class="n">mhsa</span><span class="o">.</span><span class="n">hook_z</span><span class="o">.</span><span class="n">add_hook</span><span class="p">(</span><span class="n">capture_hook</span><span class="p">)</span>
</span><span id="__span-0-338"><a id="__codelineno-0-338" name="__codelineno-0-338"></a>    <span class="n">_</span> <span class="o">=</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
</span><span id="__span-0-339"><a id="__codelineno-0-339" name="__codelineno-0-339"></a>        <span class="n">query_input</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-340"><a id="__codelineno-0-340" name="__codelineno-0-340"></a>        <span class="n">key_input</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-341"><a id="__codelineno-0-341" name="__codelineno-0-341"></a>        <span class="n">value_input</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-342"><a id="__codelineno-0-342" name="__codelineno-0-342"></a>    <span class="p">)</span>
</span><span id="__span-0-343"><a id="__codelineno-0-343" name="__codelineno-0-343"></a>    <span class="n">output_per_head</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"b s n h, n h d -&gt; b s n d"</span><span class="p">,</span> <span class="n">captured_z</span><span class="p">,</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_O</span><span class="p">)</span>
</span><span id="__span-0-344"><a id="__codelineno-0-344" name="__codelineno-0-344"></a>    <span class="n">n_ov_per_orig_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ov_heads</span> <span class="o">//</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span>
</span><span id="__span-0-345"><a id="__codelineno-0-345" name="__codelineno-0-345"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-346"><a id="__codelineno-0-346" name="__codelineno-0-346"></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">)</span>
</span><span id="__span-0-347"><a id="__codelineno-0-347" name="__codelineno-0-347"></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">)</span>
</span><span id="__span-0-348"><a id="__codelineno-0-348" name="__codelineno-0-348"></a>        <span class="n">model_parallel_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">(</span><span class="n">mesh_dim</span><span class="o">=</span><span class="s2">"model"</span><span class="p">)</span>
</span><span id="__span-0-349"><a id="__codelineno-0-349" name="__codelineno-0-349"></a>        <span class="n">model_parallel_size</span> <span class="o">=</span> <span class="n">mesh_dim_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">)</span>
</span><span id="__span-0-350"><a id="__codelineno-0-350" name="__codelineno-0-350"></a>        <span class="n">orig_start_idx</span> <span class="o">=</span> <span class="n">model_parallel_rank</span> <span class="o">*</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">//</span> <span class="n">model_parallel_size</span>
</span><span id="__span-0-351"><a id="__codelineno-0-351" name="__codelineno-0-351"></a>        <span class="n">orig_end_idx</span> <span class="o">=</span> <span class="n">orig_start_idx</span> <span class="o">+</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">//</span> <span class="n">model_parallel_size</span>
</span><span id="__span-0-352"><a id="__codelineno-0-352" name="__codelineno-0-352"></a>        <span class="n">W_O_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">to_local</span><span class="p">())</span>
</span><span id="__span-0-353"><a id="__codelineno-0-353" name="__codelineno-0-353"></a>        <span class="n">W_V_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">to_local</span><span class="p">())</span>
</span><span id="__span-0-354"><a id="__codelineno-0-354" name="__codelineno-0-354"></a>        <span class="k">for</span> <span class="n">orig_head_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">orig_start_idx</span><span class="p">,</span> <span class="n">orig_end_idx</span><span class="p">):</span>
</span><span id="__span-0-355"><a id="__codelineno-0-355" name="__codelineno-0-355"></a>            <span class="n">output</span> <span class="o">=</span> <span class="n">output_per_head</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">orig_head_index</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="__span-0-356"><a id="__codelineno-0-356" name="__codelineno-0-356"></a>            <span class="n">output_flattened</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-357"><a id="__codelineno-0-357" name="__codelineno-0-357"></a>            <span class="n">demeaned_output</span> <span class="o">=</span> <span class="n">output_flattened</span> <span class="o">-</span> <span class="n">output_flattened</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-358"><a id="__codelineno-0-358" name="__codelineno-0-358"></a>            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">demeaned_output</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span><span id="__span-0-359"><a id="__codelineno-0-359" name="__codelineno-0-359"></a>            <span class="n">proj_weight</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">]</span>
</span><span id="__span-0-360"><a id="__codelineno-0-360" name="__codelineno-0-360"></a>            <span class="n">start_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">-</span> <span class="n">orig_start_idx</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span>
</span><span id="__span-0-361"><a id="__codelineno-0-361" name="__codelineno-0-361"></a>            <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">n_ov_per_orig_head</span><span class="p">,</span> <span class="n">W_O_local</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span><span id="__span-0-362"><a id="__codelineno-0-362" name="__codelineno-0-362"></a>            <span class="n">W_O_local</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-363"><a id="__codelineno-0-363" name="__codelineno-0-363"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">to_local</span><span class="p">()[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">]</span> <span class="o">@</span> <span class="n">proj_weight</span><span class="o">.</span><span class="n">T</span>
</span><span id="__span-0-364"><a id="__codelineno-0-364" name="__codelineno-0-364"></a>            <span class="p">)</span>
</span><span id="__span-0-365"><a id="__codelineno-0-365" name="__codelineno-0-365"></a>            <span class="n">W_V_local</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-366"><a id="__codelineno-0-366" name="__codelineno-0-366"></a>                <span class="n">W_O_local</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">@</span> <span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">W_V</span><span class="p">[</span><span class="n">orig_head_index</span><span class="p">]</span> <span class="o">@</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_O</span><span class="p">[</span><span class="n">orig_head_index</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
</span><span id="__span-0-367"><a id="__codelineno-0-367" name="__codelineno-0-367"></a>            <span class="p">)</span>
</span><span id="__span-0-368"><a id="__codelineno-0-368" name="__codelineno-0-368"></a>        <span class="n">W_V_local</span> <span class="o">=</span> <span class="n">W_V_local</span> <span class="o">/</span> <span class="n">W_V_local</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-369"><a id="__codelineno-0-369" name="__codelineno-0-369"></a>        <span class="n">W_O_local</span> <span class="o">=</span> <span class="n">W_O_local</span> <span class="o">/</span> <span class="n">W_O_local</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-370"><a id="__codelineno-0-370" name="__codelineno-0-370"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">W_O_local</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">"data"</span><span class="p">),</span> <span class="n">group_src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-371"><a id="__codelineno-0-371" name="__codelineno-0-371"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">W_V_local</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">"data"</span><span class="p">),</span> <span class="n">group_src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-372"><a id="__codelineno-0-372" name="__codelineno-0-372"></a>        <span class="n">W_O_global</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-373"><a id="__codelineno-0-373" name="__codelineno-0-373"></a>            <span class="n">W_O_local</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_O"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-374"><a id="__codelineno-0-374" name="__codelineno-0-374"></a>        <span class="p">)</span>
</span><span id="__span-0-375"><a id="__codelineno-0-375" name="__codelineno-0-375"></a>        <span class="n">W_V_global</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-376"><a id="__codelineno-0-376" name="__codelineno-0-376"></a>            <span class="n">W_V_local</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_V"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-377"><a id="__codelineno-0-377" name="__codelineno-0-377"></a>        <span class="p">)</span>
</span><span id="__span-0-378"><a id="__codelineno-0-378" name="__codelineno-0-378"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_O_global</span><span class="p">)</span>
</span><span id="__span-0-379"><a id="__codelineno-0-379" name="__codelineno-0-379"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_V_global</span><span class="p">)</span>
</span><span id="__span-0-380"><a id="__codelineno-0-380" name="__codelineno-0-380"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-381"><a id="__codelineno-0-381" name="__codelineno-0-381"></a>        <span class="k">for</span> <span class="n">orig_head_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">):</span>
</span><span id="__span-0-382"><a id="__codelineno-0-382" name="__codelineno-0-382"></a>            <span class="n">output</span> <span class="o">=</span> <span class="n">output_per_head</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">orig_head_index</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="__span-0-383"><a id="__codelineno-0-383" name="__codelineno-0-383"></a>            <span class="n">output_flattened</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-384"><a id="__codelineno-0-384" name="__codelineno-0-384"></a>            <span class="n">demeaned_output</span> <span class="o">=</span> <span class="n">output_flattened</span> <span class="o">-</span> <span class="n">output_flattened</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-385"><a id="__codelineno-0-385" name="__codelineno-0-385"></a>            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">demeaned_output</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span><span id="__span-0-386"><a id="__codelineno-0-386" name="__codelineno-0-386"></a>            <span class="n">proj_weight</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">]</span>
</span><span id="__span-0-387"><a id="__codelineno-0-387" name="__codelineno-0-387"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">[</span><span class="n">orig_head_index</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span> <span class="p">:</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-388"><a id="__codelineno-0-388" name="__codelineno-0-388"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">[</span>
</span><span id="__span-0-389"><a id="__codelineno-0-389" name="__codelineno-0-389"></a>                    <span class="n">orig_head_index</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span> <span class="p">:</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span><span class="p">,</span>
</span><span id="__span-0-390"><a id="__codelineno-0-390" name="__codelineno-0-390"></a>                    <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">,</span>
</span><span id="__span-0-391"><a id="__codelineno-0-391" name="__codelineno-0-391"></a>                <span class="p">]</span>
</span><span id="__span-0-392"><a id="__codelineno-0-392" name="__codelineno-0-392"></a>                <span class="o">@</span> <span class="n">proj_weight</span><span class="o">.</span><span class="n">T</span>
</span><span id="__span-0-393"><a id="__codelineno-0-393" name="__codelineno-0-393"></a>            <span class="p">)</span>
</span><span id="__span-0-394"><a id="__codelineno-0-394" name="__codelineno-0-394"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">[</span><span class="n">orig_head_index</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span> <span class="p">:</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-395"><a id="__codelineno-0-395" name="__codelineno-0-395"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">[</span><span class="n">orig_head_index</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span> <span class="p">:</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span><span class="p">]</span>
</span><span id="__span-0-396"><a id="__codelineno-0-396" name="__codelineno-0-396"></a>                <span class="o">@</span> <span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">W_V</span><span class="p">[</span><span class="n">orig_head_index</span><span class="p">]</span> <span class="o">@</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_O</span><span class="p">[</span><span class="n">orig_head_index</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
</span><span id="__span-0-397"><a id="__codelineno-0-397" name="__codelineno-0-397"></a>            <span class="p">)</span>
</span><span id="__span-0-398"><a id="__codelineno-0-398" name="__codelineno-0-398"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="__span-0-399"><a id="__codelineno-0-399" name="__codelineno-0-399"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.init_W_V_with_active_subspace_per_head" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">init_W_V_with_active_subspace_per_head</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">init_W_V_with_active_subspace_per_head</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">mhsa</span><span class="p">:</span> <span class="n"><span title="transformer_lens.components.Attention">Attention</span></span> <span class="o">|</span> <span class="n"><span title="transformer_lens.components.GroupedQueryAttention">GroupedQueryAttention</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Initialize W_D with the active subspace for each head.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-401"><a id="__codelineno-0-401" name="__codelineno-0-401"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-402"><a id="__codelineno-0-402" name="__codelineno-0-402"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>
</span><span id="__span-0-403"><a id="__codelineno-0-403" name="__codelineno-0-403"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_W_V_with_active_subspace_per_head</span><span class="p">(</span>
</span><span id="__span-0-404"><a id="__codelineno-0-404" name="__codelineno-0-404"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">mhsa</span><span class="p">:</span> <span class="n">Attention</span> <span class="o">|</span> <span class="n">GroupedQueryAttention</span>
</span><span id="__span-0-405"><a id="__codelineno-0-405" name="__codelineno-0-405"></a><span class="p">):</span>
</span><span id="__span-0-406"><a id="__codelineno-0-406" name="__codelineno-0-406"></a><span class="w">    </span><span class="sd">"""</span>
</span><span id="__span-0-407"><a id="__codelineno-0-407" name="__codelineno-0-407"></a><span class="sd">    Initialize W_D with the active subspace for each head.</span>
</span><span id="__span-0-408"><a id="__codelineno-0-408" name="__codelineno-0-408"></a><span class="sd">    """</span>
</span><span id="__span-0-409"><a id="__codelineno-0-409" name="__codelineno-0-409"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_input</span><span class="p">(</span><span class="n">batch</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-0-410"><a id="__codelineno-0-410" name="__codelineno-0-410"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-411"><a id="__codelineno-0-411" name="__codelineno-0-411"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_local</span><span class="p">()</span>
</span><span id="__span-0-412"><a id="__codelineno-0-412" name="__codelineno-0-412"></a>
</span><span id="__span-0-413"><a id="__codelineno-0-413" name="__codelineno-0-413"></a>    <span class="n">v_per_head</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-414"><a id="__codelineno-0-414" name="__codelineno-0-414"></a>        <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">@</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
</span><span id="__span-0-415"><a id="__codelineno-0-415" name="__codelineno-0-415"></a>    <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_head</span><span class="p">)</span>
</span><span id="__span-0-416"><a id="__codelineno-0-416" name="__codelineno-0-416"></a>    <span class="n">captured_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"bnh,nhd-&gt;bnd"</span><span class="p">,</span> <span class="n">v_per_head</span><span class="p">,</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-0-417"><a id="__codelineno-0-417" name="__codelineno-0-417"></a>
</span><span id="__span-0-418"><a id="__codelineno-0-418" name="__codelineno-0-418"></a>    <span class="n">n_ov_per_orig_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_ov_heads</span> <span class="o">//</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span>
</span><span id="__span-0-419"><a id="__codelineno-0-419" name="__codelineno-0-419"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-420"><a id="__codelineno-0-420" name="__codelineno-0-420"></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">)</span>
</span><span id="__span-0-421"><a id="__codelineno-0-421" name="__codelineno-0-421"></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">)</span>
</span><span id="__span-0-422"><a id="__codelineno-0-422" name="__codelineno-0-422"></a>        <span class="n">model_parallel_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">(</span><span class="n">mesh_dim</span><span class="o">=</span><span class="s2">"model"</span><span class="p">)</span>
</span><span id="__span-0-423"><a id="__codelineno-0-423" name="__codelineno-0-423"></a>        <span class="n">model_parallel_size</span> <span class="o">=</span> <span class="n">mesh_dim_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="s2">"model"</span><span class="p">)</span>
</span><span id="__span-0-424"><a id="__codelineno-0-424" name="__codelineno-0-424"></a>        <span class="n">orig_start_idx</span> <span class="o">=</span> <span class="n">model_parallel_rank</span> <span class="o">*</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">//</span> <span class="n">model_parallel_size</span>
</span><span id="__span-0-425"><a id="__codelineno-0-425" name="__codelineno-0-425"></a>        <span class="n">orig_end_idx</span> <span class="o">=</span> <span class="n">orig_start_idx</span> <span class="o">+</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">//</span> <span class="n">model_parallel_size</span>
</span><span id="__span-0-426"><a id="__codelineno-0-426" name="__codelineno-0-426"></a>        <span class="n">W_O_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">to_local</span><span class="p">())</span>
</span><span id="__span-0-427"><a id="__codelineno-0-427" name="__codelineno-0-427"></a>        <span class="n">W_V_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">to_local</span><span class="p">())</span>
</span><span id="__span-0-428"><a id="__codelineno-0-428" name="__codelineno-0-428"></a>        <span class="k">for</span> <span class="n">orig_head_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">orig_start_idx</span><span class="p">,</span> <span class="n">orig_end_idx</span><span class="p">):</span>
</span><span id="__span-0-429"><a id="__codelineno-0-429" name="__codelineno-0-429"></a>            <span class="n">v</span> <span class="o">=</span> <span class="n">captured_v</span><span class="p">[:,</span> <span class="n">orig_head_index</span><span class="p">]</span>
</span><span id="__span-0-430"><a id="__codelineno-0-430" name="__codelineno-0-430"></a>            <span class="n">demeaned_v</span> <span class="o">=</span> <span class="n">v</span> <span class="o">-</span> <span class="n">v</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-431"><a id="__codelineno-0-431" name="__codelineno-0-431"></a>            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">demeaned_v</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span><span id="__span-0-432"><a id="__codelineno-0-432" name="__codelineno-0-432"></a>            <span class="n">proj_weight</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">]</span>
</span><span id="__span-0-433"><a id="__codelineno-0-433" name="__codelineno-0-433"></a>            <span class="n">start_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">-</span> <span class="n">orig_start_idx</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span>
</span><span id="__span-0-434"><a id="__codelineno-0-434" name="__codelineno-0-434"></a>            <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">n_ov_per_orig_head</span><span class="p">,</span> <span class="n">W_O_local</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span><span id="__span-0-435"><a id="__codelineno-0-435" name="__codelineno-0-435"></a>            <span class="n">W_V_local</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-436"><a id="__codelineno-0-436" name="__codelineno-0-436"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">to_local</span><span class="p">()[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">]</span> <span class="o">@</span> <span class="n">proj_weight</span><span class="o">.</span><span class="n">T</span>
</span><span id="__span-0-437"><a id="__codelineno-0-437" name="__codelineno-0-437"></a>            <span class="p">)</span>
</span><span id="__span-0-438"><a id="__codelineno-0-438" name="__codelineno-0-438"></a>            <span class="n">W_O_local</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-439"><a id="__codelineno-0-439" name="__codelineno-0-439"></a>                <span class="n">W_V_local</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">@</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_V</span><span class="p">[</span><span class="n">orig_head_index</span><span class="p">]</span> <span class="o">@</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_O</span><span class="p">[</span><span class="n">orig_head_index</span><span class="p">]</span>
</span><span id="__span-0-440"><a id="__codelineno-0-440" name="__codelineno-0-440"></a>            <span class="p">)</span>
</span><span id="__span-0-441"><a id="__codelineno-0-441" name="__codelineno-0-441"></a>        <span class="n">W_V_local</span> <span class="o">=</span> <span class="n">W_V_local</span> <span class="o">/</span> <span class="n">W_V_local</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-442"><a id="__codelineno-0-442" name="__codelineno-0-442"></a>        <span class="n">W_O_local</span> <span class="o">=</span> <span class="n">W_O_local</span> <span class="o">/</span> <span class="n">W_O_local</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-443"><a id="__codelineno-0-443" name="__codelineno-0-443"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">W_O_local</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">"data"</span><span class="p">),</span> <span class="n">group_src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-444"><a id="__codelineno-0-444" name="__codelineno-0-444"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">W_V_local</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">"data"</span><span class="p">),</span> <span class="n">group_src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-445"><a id="__codelineno-0-445" name="__codelineno-0-445"></a>        <span class="n">W_O_global</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-446"><a id="__codelineno-0-446" name="__codelineno-0-446"></a>            <span class="n">W_O_local</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_O"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-447"><a id="__codelineno-0-447" name="__codelineno-0-447"></a>        <span class="p">)</span>
</span><span id="__span-0-448"><a id="__codelineno-0-448" name="__codelineno-0-448"></a>        <span class="n">W_V_global</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-449"><a id="__codelineno-0-449" name="__codelineno-0-449"></a>            <span class="n">W_V_local</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_V"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-450"><a id="__codelineno-0-450" name="__codelineno-0-450"></a>        <span class="p">)</span>
</span><span id="__span-0-451"><a id="__codelineno-0-451" name="__codelineno-0-451"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_O_global</span><span class="p">)</span>
</span><span id="__span-0-452"><a id="__codelineno-0-452" name="__codelineno-0-452"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">W_V_global</span><span class="p">)</span>
</span><span id="__span-0-453"><a id="__codelineno-0-453" name="__codelineno-0-453"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-454"><a id="__codelineno-0-454" name="__codelineno-0-454"></a>        <span class="k">for</span> <span class="n">orig_head_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mhsa</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">):</span>
</span><span id="__span-0-455"><a id="__codelineno-0-455" name="__codelineno-0-455"></a>            <span class="n">v</span> <span class="o">=</span> <span class="n">captured_v</span><span class="p">[:,</span> <span class="n">orig_head_index</span><span class="p">]</span>
</span><span id="__span-0-456"><a id="__codelineno-0-456" name="__codelineno-0-456"></a>            <span class="n">demeaned_v</span> <span class="o">=</span> <span class="n">v</span> <span class="o">-</span> <span class="n">v</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-457"><a id="__codelineno-0-457" name="__codelineno-0-457"></a>            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">demeaned_v</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span><span id="__span-0-458"><a id="__codelineno-0-458" name="__codelineno-0-458"></a>            <span class="n">proj_weight</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">]</span>
</span><span id="__span-0-459"><a id="__codelineno-0-459" name="__codelineno-0-459"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">[</span><span class="n">orig_head_index</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span> <span class="p">:</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-460"><a id="__codelineno-0-460" name="__codelineno-0-460"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">[</span>
</span><span id="__span-0-461"><a id="__codelineno-0-461" name="__codelineno-0-461"></a>                    <span class="n">orig_head_index</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span> <span class="p">:</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span><span class="p">,</span>
</span><span id="__span-0-462"><a id="__codelineno-0-462" name="__codelineno-0-462"></a>                    <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_qk_head</span><span class="p">,</span>
</span><span id="__span-0-463"><a id="__codelineno-0-463" name="__codelineno-0-463"></a>                <span class="p">]</span>
</span><span id="__span-0-464"><a id="__codelineno-0-464" name="__codelineno-0-464"></a>                <span class="o">@</span> <span class="n">proj_weight</span><span class="o">.</span><span class="n">T</span>
</span><span id="__span-0-465"><a id="__codelineno-0-465" name="__codelineno-0-465"></a>            <span class="p">)</span>
</span><span id="__span-0-466"><a id="__codelineno-0-466" name="__codelineno-0-466"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">[</span><span class="n">orig_head_index</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span> <span class="p">:</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-467"><a id="__codelineno-0-467" name="__codelineno-0-467"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">[</span><span class="n">orig_head_index</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span> <span class="p">:</span> <span class="p">(</span><span class="n">orig_head_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_ov_per_orig_head</span><span class="p">]</span>
</span><span id="__span-0-468"><a id="__codelineno-0-468" name="__codelineno-0-468"></a>                <span class="o">@</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_V</span><span class="p">[</span><span class="n">orig_head_index</span><span class="p">]</span>
</span><span id="__span-0-469"><a id="__codelineno-0-469" name="__codelineno-0-469"></a>                <span class="o">@</span> <span class="n">mhsa</span><span class="o">.</span><span class="n">W_O</span><span class="p">[</span><span class="n">orig_head_index</span><span class="p">]</span>
</span><span id="__span-0-470"><a id="__codelineno-0-470" name="__codelineno-0-470"></a>            <span class="p">)</span>
</span><span id="__span-0-471"><a id="__codelineno-0-471" name="__codelineno-0-471"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="__span-0-472"><a id="__codelineno-0-472" name="__codelineno-0-472"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.encoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Norm of encoder (Q/K weights).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-546">546</a></span>
<span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span>
<span class="normal"><a href="#__codelineno-0-550">550</a></span>
<span class="normal"><a href="#__codelineno-0-551">551</a></span>
<span class="normal"><a href="#__codelineno-0-552">552</a></span>
<span class="normal"><a href="#__codelineno-0-553">553</a></span>
<span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span>
<span class="normal"><a href="#__codelineno-0-557">557</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-546"><a id="__codelineno-0-546" name="__codelineno-0-546"></a><span class="nd">@override</span>
</span><span id="__span-0-547"><a id="__codelineno-0-547" name="__codelineno-0-547"></a><span class="k">def</span><span class="w"> </span><span class="nf">encoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-548"><a id="__codelineno-0-548" name="__codelineno-0-548"></a><span class="w">    </span><span class="sd">"""Norm of encoder (Q/K weights)."""</span>
</span><span id="__span-0-549"><a id="__codelineno-0-549" name="__codelineno-0-549"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-550"><a id="__codelineno-0-550" name="__codelineno-0-550"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-551"><a id="__codelineno-0-551" name="__codelineno-0-551"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-552"><a id="__codelineno-0-552" name="__codelineno-0-552"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-553"><a id="__codelineno-0-553" name="__codelineno-0-553"></a>        <span class="k">return</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-554"><a id="__codelineno-0-554" name="__codelineno-0-554"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">to_local</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">),</span>
</span><span id="__span-0-555"><a id="__codelineno-0-555" name="__codelineno-0-555"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-556"><a id="__codelineno-0-556" name="__codelineno-0-556"></a>            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_V"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-557"><a id="__codelineno-0-557" name="__codelineno-0-557"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.decoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Norm of decoder (O weights).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-559">559</a></span>
<span class="normal"><a href="#__codelineno-0-560">560</a></span>
<span class="normal"><a href="#__codelineno-0-561">561</a></span>
<span class="normal"><a href="#__codelineno-0-562">562</a></span>
<span class="normal"><a href="#__codelineno-0-563">563</a></span>
<span class="normal"><a href="#__codelineno-0-564">564</a></span>
<span class="normal"><a href="#__codelineno-0-565">565</a></span>
<span class="normal"><a href="#__codelineno-0-566">566</a></span>
<span class="normal"><a href="#__codelineno-0-567">567</a></span>
<span class="normal"><a href="#__codelineno-0-568">568</a></span>
<span class="normal"><a href="#__codelineno-0-569">569</a></span>
<span class="normal"><a href="#__codelineno-0-570">570</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-559"><a id="__codelineno-0-559" name="__codelineno-0-559"></a><span class="nd">@override</span>
</span><span id="__span-0-560"><a id="__codelineno-0-560" name="__codelineno-0-560"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-561"><a id="__codelineno-0-561" name="__codelineno-0-561"></a><span class="w">    </span><span class="sd">"""Norm of decoder (O weights)."""</span>
</span><span id="__span-0-562"><a id="__codelineno-0-562" name="__codelineno-0-562"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-563"><a id="__codelineno-0-563" name="__codelineno-0-563"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-564"><a id="__codelineno-0-564" name="__codelineno-0-564"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-565"><a id="__codelineno-0-565" name="__codelineno-0-565"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-566"><a id="__codelineno-0-566" name="__codelineno-0-566"></a>        <span class="k">return</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-567"><a id="__codelineno-0-567" name="__codelineno-0-567"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">to_local</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">),</span>
</span><span id="__span-0-568"><a id="__codelineno-0-568" name="__codelineno-0-568"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-569"><a id="__codelineno-0-569" name="__codelineno-0-569"></a>            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_O"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-570"><a id="__codelineno-0-570" name="__codelineno-0-570"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.decoder_bias_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_bias_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_bias_norm</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Norm of decoder bias.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-572">572</a></span>
<span class="normal"><a href="#__codelineno-0-573">573</a></span>
<span class="normal"><a href="#__codelineno-0-574">574</a></span>
<span class="normal"><a href="#__codelineno-0-575">575</a></span>
<span class="normal"><a href="#__codelineno-0-576">576</a></span>
<span class="normal"><a href="#__codelineno-0-577">577</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-572"><a id="__codelineno-0-572" name="__codelineno-0-572"></a><span class="nd">@override</span>
</span><span id="__span-0-573"><a id="__codelineno-0-573" name="__codelineno-0-573"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_bias_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-574"><a id="__codelineno-0-574" name="__codelineno-0-574"></a><span class="w">    </span><span class="sd">"""Norm of decoder bias."""</span>
</span><span id="__span-0-575"><a id="__codelineno-0-575" name="__codelineno-0-575"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-576"><a id="__codelineno-0-576" name="__codelineno-0-576"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Decoder bias not used"</span><span class="p">)</span>
</span><span id="__span-0-577"><a id="__codelineno-0-577" name="__codelineno-0-577"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.transform_to_unit_decoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">transform_to_unit_decoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">transform_to_unit_decoder_norm</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Transform to unit decoder norm.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-579">579</a></span>
<span class="normal"><a href="#__codelineno-0-580">580</a></span>
<span class="normal"><a href="#__codelineno-0-581">581</a></span>
<span class="normal"><a href="#__codelineno-0-582">582</a></span>
<span class="normal"><a href="#__codelineno-0-583">583</a></span>
<span class="normal"><a href="#__codelineno-0-584">584</a></span>
<span class="normal"><a href="#__codelineno-0-585">585</a></span>
<span class="normal"><a href="#__codelineno-0-586">586</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-579"><a id="__codelineno-0-579" name="__codelineno-0-579"></a><span class="nd">@override</span>
</span><span id="__span-0-580"><a id="__codelineno-0-580" name="__codelineno-0-580"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-581"><a id="__codelineno-0-581" name="__codelineno-0-581"></a><span class="k">def</span><span class="w"> </span><span class="nf">transform_to_unit_decoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-0-582"><a id="__codelineno-0-582" name="__codelineno-0-582"></a><span class="w">    </span><span class="sd">"""Transform to unit decoder norm."""</span>
</span><span id="__span-0-583"><a id="__codelineno-0-583" name="__codelineno-0-583"></a>    <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-584"><a id="__codelineno-0-584" name="__codelineno-0-584"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span> <span class="o">/=</span> <span class="n">norm</span>
</span><span id="__span-0-585"><a id="__codelineno-0-585" name="__codelineno-0-585"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span> <span class="o">*=</span> <span class="n">norm</span>
</span><span id="__span-0-586"><a id="__codelineno-0-586" name="__codelineno-0-586"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">b_V</span> <span class="o">*=</span> <span class="n">norm</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.standardize_parameters_of_dataset_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">standardize_parameters_of_dataset_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">standardize_parameters_of_dataset_norm</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Standardize parameters for dataset norm.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-588">588</a></span>
<span class="normal"><a href="#__codelineno-0-589">589</a></span>
<span class="normal"><a href="#__codelineno-0-590">590</a></span>
<span class="normal"><a href="#__codelineno-0-591">591</a></span>
<span class="normal"><a href="#__codelineno-0-592">592</a></span>
<span class="normal"><a href="#__codelineno-0-593">593</a></span>
<span class="normal"><a href="#__codelineno-0-594">594</a></span>
<span class="normal"><a href="#__codelineno-0-595">595</a></span>
<span class="normal"><a href="#__codelineno-0-596">596</a></span>
<span class="normal"><a href="#__codelineno-0-597">597</a></span>
<span class="normal"><a href="#__codelineno-0-598">598</a></span>
<span class="normal"><a href="#__codelineno-0-599">599</a></span>
<span class="normal"><a href="#__codelineno-0-600">600</a></span>
<span class="normal"><a href="#__codelineno-0-601">601</a></span>
<span class="normal"><a href="#__codelineno-0-602">602</a></span>
<span class="normal"><a href="#__codelineno-0-603">603</a></span>
<span class="normal"><a href="#__codelineno-0-604">604</a></span>
<span class="normal"><a href="#__codelineno-0-605">605</a></span>
<span class="normal"><a href="#__codelineno-0-606">606</a></span>
<span class="normal"><a href="#__codelineno-0-607">607</a></span>
<span class="normal"><a href="#__codelineno-0-608">608</a></span>
<span class="normal"><a href="#__codelineno-0-609">609</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-588"><a id="__codelineno-0-588" name="__codelineno-0-588"></a><span class="nd">@override</span>
</span><span id="__span-0-589"><a id="__codelineno-0-589" name="__codelineno-0-589"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-590"><a id="__codelineno-0-590" name="__codelineno-0-590"></a><span class="k">def</span><span class="w"> </span><span class="nf">standardize_parameters_of_dataset_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-0-591"><a id="__codelineno-0-591" name="__codelineno-0-591"></a><span class="w">    </span><span class="sd">"""Standardize parameters for dataset norm."""</span>
</span><span id="__span-0-592"><a id="__codelineno-0-592" name="__codelineno-0-592"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">norm_activation</span> <span class="o">==</span> <span class="s2">"dataset-wise"</span>
</span><span id="__span-0-593"><a id="__codelineno-0-593" name="__codelineno-0-593"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-594"><a id="__codelineno-0-594" name="__codelineno-0-594"></a>
</span><span id="__span-0-595"><a id="__codelineno-0-595" name="__codelineno-0-595"></a>    <span class="n">hook_point_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_point_in</span>
</span><span id="__span-0-596"><a id="__codelineno-0-596" name="__codelineno-0-596"></a>    <span class="n">hook_point_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_point_out</span>
</span><span id="__span-0-597"><a id="__codelineno-0-597" name="__codelineno-0-597"></a>
</span><span id="__span-0-598"><a id="__codelineno-0-598" name="__codelineno-0-598"></a>    <span class="n">input_norm_factor</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span><span class="p">[</span><span class="n">hook_point_in</span><span class="p">]</span>
</span><span id="__span-0-599"><a id="__codelineno-0-599" name="__codelineno-0-599"></a>    <span class="n">output_norm_factor</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_average_activation_norm</span><span class="p">[</span><span class="n">hook_point_out</span><span class="p">]</span>
</span><span id="__span-0-600"><a id="__codelineno-0-600" name="__codelineno-0-600"></a>
</span><span id="__span-0-601"><a id="__codelineno-0-601" name="__codelineno-0-601"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_Q</span><span class="o">.</span><span class="n">data</span> <span class="o">*=</span> <span class="n">input_norm_factor</span>
</span><span id="__span-0-602"><a id="__codelineno-0-602" name="__codelineno-0-602"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_K</span><span class="o">.</span><span class="n">data</span> <span class="o">*=</span> <span class="n">input_norm_factor</span>
</span><span id="__span-0-603"><a id="__codelineno-0-603" name="__codelineno-0-603"></a>
</span><span id="__span-0-604"><a id="__codelineno-0-604" name="__codelineno-0-604"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="o">.</span><span class="n">data</span> <span class="o">*=</span> <span class="n">input_norm_factor</span>
</span><span id="__span-0-605"><a id="__codelineno-0-605" name="__codelineno-0-605"></a>
</span><span id="__span-0-606"><a id="__codelineno-0-606" name="__codelineno-0-606"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">data</span> <span class="o">/</span> <span class="n">output_norm_factor</span>
</span><span id="__span-0-607"><a id="__codelineno-0-607" name="__codelineno-0-607"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span><span class="o">.</span><span class="n">data</span> <span class="o">/</span> <span class="n">output_norm_factor</span>
</span><span id="__span-0-608"><a id="__codelineno-0-608" name="__codelineno-0-608"></a>
</span><span id="__span-0-609"><a id="__codelineno-0-609" name="__codelineno-0-609"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">norm_activation</span> <span class="o">=</span> <span class="s2">"inference"</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.compute_hidden_pre" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">compute_hidden_pre</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_hidden_pre</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the hidden pre-activations.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-611">611</a></span>
<span class="normal"><a href="#__codelineno-0-612">612</a></span>
<span class="normal"><a href="#__codelineno-0-613">613</a></span>
<span class="normal"><a href="#__codelineno-0-614">614</a></span>
<span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-611"><a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_hidden_pre</span><span class="p">(</span>
</span><span id="__span-0-612"><a id="__codelineno-0-612" name="__codelineno-0-612"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">]</span>
</span><span id="__span-0-613"><a id="__codelineno-0-613" name="__codelineno-0-613"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">]:</span>
</span><span id="__span-0-614"><a id="__codelineno-0-614" name="__codelineno-0-614"></a><span class="w">    </span><span class="sd">"""Compute the hidden pre-activations."""</span>
</span><span id="__span-0-615"><a id="__codelineno-0-615" name="__codelineno-0-615"></a>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-616"><a id="__codelineno-0-616" name="__codelineno-0-616"></a>    <span class="n">query</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-617"><a id="__codelineno-0-617" name="__codelineno-0-617"></a>    <span class="n">key</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-618"><a id="__codelineno-0-618" name="__codelineno-0-618"></a>    <span class="n">value</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-619"><a id="__codelineno-0-619" name="__codelineno-0-619"></a>    <span class="k">with</span> <span class="n">sdpa_kernel</span><span class="p">(</span>
</span><span id="__span-0-620"><a id="__codelineno-0-620" name="__codelineno-0-620"></a>        <span class="n">backends</span><span class="o">=</span><span class="p">[</span>
</span><span id="__span-0-621"><a id="__codelineno-0-621" name="__codelineno-0-621"></a>            <span class="n">SDPBackend</span><span class="o">.</span><span class="n">FLASH_ATTENTION</span><span class="p">,</span>
</span><span id="__span-0-622"><a id="__codelineno-0-622" name="__codelineno-0-622"></a>            <span class="n">SDPBackend</span><span class="o">.</span><span class="n">CUDNN_ATTENTION</span><span class="p">,</span>
</span><span id="__span-0-623"><a id="__codelineno-0-623" name="__codelineno-0-623"></a>            <span class="n">SDPBackend</span><span class="o">.</span><span class="n">EFFICIENT_ATTENTION</span><span class="p">,</span>
</span><span id="__span-0-624"><a id="__codelineno-0-624" name="__codelineno-0-624"></a>            <span class="n">SDPBackend</span><span class="o">.</span><span class="n">MATH</span><span class="p">,</span>
</span><span id="__span-0-625"><a id="__codelineno-0-625" name="__codelineno-0-625"></a>        <span class="p">]</span>
</span><span id="__span-0-626"><a id="__codelineno-0-626" name="__codelineno-0-626"></a>    <span class="p">):</span>
</span><span id="__span-0-627"><a id="__codelineno-0-627" name="__codelineno-0-627"></a>        <span class="n">z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span>
</span><span id="__span-0-628"><a id="__codelineno-0-628" name="__codelineno-0-628"></a>            <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_scale</span><span class="p">,</span> <span class="n">is_causal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enable_gqa</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-629"><a id="__codelineno-0-629" name="__codelineno-0-629"></a>        <span class="p">)</span>
</span><span id="__span-0-630"><a id="__codelineno-0-630" name="__codelineno-0-630"></a>    <span class="k">return</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.encode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encode</span>


</h3>
          <div class="doc-overloads">
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">]</span>
</span></code></pre></div><div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="kc">True</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">]</span>
</span></code></pre></div>          </div>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">return_attention_pattern</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">return_attention_score</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="o">|</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="p">]</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="o">|</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>        <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch n_qk_heads q_pos k_pos"</span><span class="p">],</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="p">]</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode to sparse head activations.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span>
<span class="normal"><a href="#__codelineno-0-661">661</a></span>
<span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span>
<span class="normal"><a href="#__codelineno-0-694">694</a></span>
<span class="normal"><a href="#__codelineno-0-695">695</a></span>
<span class="normal"><a href="#__codelineno-0-696">696</a></span>
<span class="normal"><a href="#__codelineno-0-697">697</a></span>
<span class="normal"><a href="#__codelineno-0-698">698</a></span>
<span class="normal"><a href="#__codelineno-0-699">699</a></span>
<span class="normal"><a href="#__codelineno-0-700">700</a></span>
<span class="normal"><a href="#__codelineno-0-701">701</a></span>
<span class="normal"><a href="#__codelineno-0-702">702</a></span>
<span class="normal"><a href="#__codelineno-0-703">703</a></span>
<span class="normal"><a href="#__codelineno-0-704">704</a></span>
<span class="normal"><a href="#__codelineno-0-705">705</a></span>
<span class="normal"><a href="#__codelineno-0-706">706</a></span>
<span class="normal"><a href="#__codelineno-0-707">707</a></span>
<span class="normal"><a href="#__codelineno-0-708">708</a></span>
<span class="normal"><a href="#__codelineno-0-709">709</a></span>
<span class="normal"><a href="#__codelineno-0-710">710</a></span>
<span class="normal"><a href="#__codelineno-0-711">711</a></span>
<span class="normal"><a href="#__codelineno-0-712">712</a></span>
<span class="normal"><a href="#__codelineno-0-713">713</a></span>
<span class="normal"><a href="#__codelineno-0-714">714</a></span>
<span class="normal"><a href="#__codelineno-0-715">715</a></span>
<span class="normal"><a href="#__codelineno-0-716">716</a></span>
<span class="normal"><a href="#__codelineno-0-717">717</a></span>
<span class="normal"><a href="#__codelineno-0-718">718</a></span>
<span class="normal"><a href="#__codelineno-0-719">719</a></span>
<span class="normal"><a href="#__codelineno-0-720">720</a></span>
<span class="normal"><a href="#__codelineno-0-721">721</a></span>
<span class="normal"><a href="#__codelineno-0-722">722</a></span>
<span class="normal"><a href="#__codelineno-0-723">723</a></span>
<span class="normal"><a href="#__codelineno-0-724">724</a></span>
<span class="normal"><a href="#__codelineno-0-725">725</a></span>
<span class="normal"><a href="#__codelineno-0-726">726</a></span>
<span class="normal"><a href="#__codelineno-0-727">727</a></span>
<span class="normal"><a href="#__codelineno-0-728">728</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-656"><a id="__codelineno-0-656" name="__codelineno-0-656"></a><span class="nd">@override</span>
</span><span id="__span-0-657"><a id="__codelineno-0-657" name="__codelineno-0-657"></a><span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span>
</span><span id="__span-0-658"><a id="__codelineno-0-658" name="__codelineno-0-658"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-659"><a id="__codelineno-0-659" name="__codelineno-0-659"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-660"><a id="__codelineno-0-660" name="__codelineno-0-660"></a>    <span class="n">return_hidden_pre</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-661"><a id="__codelineno-0-661" name="__codelineno-0-661"></a>    <span class="n">return_attention_pattern</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-662"><a id="__codelineno-0-662" name="__codelineno-0-662"></a>    <span class="n">return_attention_score</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-663"><a id="__codelineno-0-663" name="__codelineno-0-663"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-664"><a id="__codelineno-0-664" name="__codelineno-0-664"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-665"><a id="__codelineno-0-665" name="__codelineno-0-665"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-666"><a id="__codelineno-0-666" name="__codelineno-0-666"></a>    <span class="n">Tuple</span><span class="p">[</span>
</span><span id="__span-0-667"><a id="__codelineno-0-667" name="__codelineno-0-667"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-668"><a id="__codelineno-0-668" name="__codelineno-0-668"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-669"><a id="__codelineno-0-669" name="__codelineno-0-669"></a>    <span class="p">],</span>
</span><span id="__span-0-670"><a id="__codelineno-0-670" name="__codelineno-0-670"></a>    <span class="n">Tuple</span><span class="p">[</span>
</span><span id="__span-0-671"><a id="__codelineno-0-671" name="__codelineno-0-671"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-672"><a id="__codelineno-0-672" name="__codelineno-0-672"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-673"><a id="__codelineno-0-673" name="__codelineno-0-673"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch n_qk_heads q_pos k_pos"</span><span class="p">],</span>
</span><span id="__span-0-674"><a id="__codelineno-0-674" name="__codelineno-0-674"></a>    <span class="p">],</span>
</span><span id="__span-0-675"><a id="__codelineno-0-675" name="__codelineno-0-675"></a><span class="p">]:</span>
</span><span id="__span-0-676"><a id="__codelineno-0-676" name="__codelineno-0-676"></a><span class="w">    </span><span class="sd">"""Encode to sparse head activations."""</span>
</span><span id="__span-0-677"><a id="__codelineno-0-677" name="__codelineno-0-677"></a>    <span class="c1"># Compute Q, K, V</span>
</span><span id="__span-0-678"><a id="__codelineno-0-678" name="__codelineno-0-678"></a>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-679"><a id="__codelineno-0-679" name="__codelineno-0-679"></a>
</span><span id="__span-0-680"><a id="__codelineno-0-680" name="__codelineno-0-680"></a>    <span class="n">pattern</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-681"><a id="__codelineno-0-681" name="__codelineno-0-681"></a>    <span class="n">scores</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-682"><a id="__codelineno-0-682" name="__codelineno-0-682"></a>
</span><span id="__span-0-683"><a id="__codelineno-0-683" name="__codelineno-0-683"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">return_attention_pattern</span> <span class="ow">or</span> <span class="n">return_attention_score</span><span class="p">):</span>
</span><span id="__span-0-684"><a id="__codelineno-0-684" name="__codelineno-0-684"></a>        <span class="n">query</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-685"><a id="__codelineno-0-685" name="__codelineno-0-685"></a>        <span class="n">key</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-686"><a id="__codelineno-0-686" name="__codelineno-0-686"></a>        <span class="n">value</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-687"><a id="__codelineno-0-687" name="__codelineno-0-687"></a>        <span class="k">with</span> <span class="n">sdpa_kernel</span><span class="p">(</span>
</span><span id="__span-0-688"><a id="__codelineno-0-688" name="__codelineno-0-688"></a>            <span class="n">backends</span><span class="o">=</span><span class="p">[</span>
</span><span id="__span-0-689"><a id="__codelineno-0-689" name="__codelineno-0-689"></a>                <span class="n">SDPBackend</span><span class="o">.</span><span class="n">FLASH_ATTENTION</span><span class="p">,</span>
</span><span id="__span-0-690"><a id="__codelineno-0-690" name="__codelineno-0-690"></a>                <span class="n">SDPBackend</span><span class="o">.</span><span class="n">CUDNN_ATTENTION</span><span class="p">,</span>
</span><span id="__span-0-691"><a id="__codelineno-0-691" name="__codelineno-0-691"></a>                <span class="n">SDPBackend</span><span class="o">.</span><span class="n">EFFICIENT_ATTENTION</span><span class="p">,</span>
</span><span id="__span-0-692"><a id="__codelineno-0-692" name="__codelineno-0-692"></a>                <span class="n">SDPBackend</span><span class="o">.</span><span class="n">MATH</span><span class="p">,</span>
</span><span id="__span-0-693"><a id="__codelineno-0-693" name="__codelineno-0-693"></a>            <span class="p">]</span>
</span><span id="__span-0-694"><a id="__codelineno-0-694" name="__codelineno-0-694"></a>        <span class="p">):</span>
</span><span id="__span-0-695"><a id="__codelineno-0-695" name="__codelineno-0-695"></a>            <span class="n">z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span>
</span><span id="__span-0-696"><a id="__codelineno-0-696" name="__codelineno-0-696"></a>                <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_scale</span><span class="p">,</span> <span class="n">is_causal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enable_gqa</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-697"><a id="__codelineno-0-697" name="__codelineno-0-697"></a>            <span class="p">)</span>
</span><span id="__span-0-698"><a id="__codelineno-0-698" name="__codelineno-0-698"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="__span-0-699"><a id="__codelineno-0-699" name="__codelineno-0-699"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-700"><a id="__codelineno-0-700" name="__codelineno-0-700"></a>        <span class="c1"># Attention pattern</span>
</span><span id="__span-0-701"><a id="__codelineno-0-701" name="__codelineno-0-701"></a>        <span class="c1"># n_qk_heads batch q_pos k_pos</span>
</span><span id="__span-0-702"><a id="__codelineno-0-702" name="__codelineno-0-702"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># (n_qk_heads, batch, seq_len, d_qk_head)</span>
</span><span id="__span-0-703"><a id="__codelineno-0-703" name="__codelineno-0-703"></a>        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (n_qk_heads, batch, d_qk_head, seq_len)</span>
</span><span id="__span-0-704"><a id="__codelineno-0-704" name="__codelineno-0-704"></a>        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"nbqd,nbdk-&gt;nbqk"</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_scale</span>
</span><span id="__span-0-705"><a id="__codelineno-0-705" name="__codelineno-0-705"></a>        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_causal_mask</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</span><span id="__span-0-706"><a id="__codelineno-0-706" name="__codelineno-0-706"></a>        <span class="n">pattern</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-707"><a id="__codelineno-0-707" name="__codelineno-0-707"></a>
</span><span id="__span-0-708"><a id="__codelineno-0-708" name="__codelineno-0-708"></a>        <span class="c1"># Head outputs</span>
</span><span id="__span-0-709"><a id="__codelineno-0-709" name="__codelineno-0-709"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_head_outputs</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span><span id="__span-0-710"><a id="__codelineno-0-710" name="__codelineno-0-710"></a>
</span><span id="__span-0-711"><a id="__codelineno-0-711" name="__codelineno-0-711"></a>    <span class="c1"># Scale feature activations by decoder norm if configured</span>
</span><span id="__span-0-712"><a id="__codelineno-0-712" name="__codelineno-0-712"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_include_decoder_norm</span><span class="p">:</span>
</span><span id="__span-0-713"><a id="__codelineno-0-713" name="__codelineno-0-713"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">hidden_pre</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">()</span>
</span><span id="__span-0-714"><a id="__codelineno-0-714" name="__codelineno-0-714"></a>
</span><span id="__span-0-715"><a id="__codelineno-0-715" name="__codelineno-0-715"></a>    <span class="n">feature_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">(</span><span class="n">hidden_pre</span><span class="p">)</span>
</span><span id="__span-0-716"><a id="__codelineno-0-716" name="__codelineno-0-716"></a>
</span><span id="__span-0-717"><a id="__codelineno-0-717" name="__codelineno-0-717"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">sparsity_include_decoder_norm</span><span class="p">:</span>
</span><span id="__span-0-718"><a id="__codelineno-0-718" name="__codelineno-0-718"></a>        <span class="n">feature_acts</span> <span class="o">=</span> <span class="n">feature_acts</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">()</span>
</span><span id="__span-0-719"><a id="__codelineno-0-719" name="__codelineno-0-719"></a>        <span class="n">hidden_pre</span> <span class="o">=</span> <span class="n">hidden_pre</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">()</span>
</span><span id="__span-0-720"><a id="__codelineno-0-720" name="__codelineno-0-720"></a>
</span><span id="__span-0-721"><a id="__codelineno-0-721" name="__codelineno-0-721"></a>    <span class="n">return_values</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature_acts</span><span class="p">]</span>
</span><span id="__span-0-722"><a id="__codelineno-0-722" name="__codelineno-0-722"></a>    <span class="k">if</span> <span class="n">return_hidden_pre</span><span class="p">:</span>
</span><span id="__span-0-723"><a id="__codelineno-0-723" name="__codelineno-0-723"></a>        <span class="n">return_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hidden_pre</span><span class="p">)</span>
</span><span id="__span-0-724"><a id="__codelineno-0-724" name="__codelineno-0-724"></a>    <span class="k">if</span> <span class="n">return_attention_pattern</span> <span class="ow">and</span> <span class="n">pattern</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-725"><a id="__codelineno-0-725" name="__codelineno-0-725"></a>        <span class="n">return_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pattern</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span><span id="__span-0-726"><a id="__codelineno-0-726" name="__codelineno-0-726"></a>    <span class="k">if</span> <span class="n">return_attention_score</span> <span class="ow">and</span> <span class="n">scores</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-727"><a id="__codelineno-0-727" name="__codelineno-0-727"></a>        <span class="n">return_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span><span id="__span-0-728"><a id="__codelineno-0-728" name="__codelineno-0-728"></a>    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">return_values</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">return_values</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">return_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># type: ignore[return-value]</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.decode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decode</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decode</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Decode head activations to output.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-730">730</a></span>
<span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span>
<span class="normal"><a href="#__codelineno-0-736">736</a></span>
<span class="normal"><a href="#__codelineno-0-737">737</a></span>
<span class="normal"><a href="#__codelineno-0-738">738</a></span>
<span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span>
<span class="normal"><a href="#__codelineno-0-746">746</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-730"><a id="__codelineno-0-730" name="__codelineno-0-730"></a><span class="nd">@override</span>
</span><span id="__span-0-731"><a id="__codelineno-0-731" name="__codelineno-0-731"></a><span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_acts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="__span-0-732"><a id="__codelineno-0-732" name="__codelineno-0-732"></a><span class="w">    </span><span class="sd">"""Decode head activations to output."""</span>
</span><span id="__span-0-733"><a id="__codelineno-0-733" name="__codelineno-0-733"></a>    <span class="k">if</span> <span class="n">feature_acts</span><span class="o">.</span><span class="n">layout</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span><span class="p">:</span>
</span><span id="__span-0-734"><a id="__codelineno-0-734" name="__codelineno-0-734"></a>        <span class="k">return</span> <span class="p">(</span>
</span><span id="__span-0-735"><a id="__codelineno-0-735" name="__codelineno-0-735"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span>
</span><span id="__span-0-736"><a id="__codelineno-0-736" name="__codelineno-0-736"></a>                <span class="n">feature_acts</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="__span-0-737"><a id="__codelineno-0-737" name="__codelineno-0-737"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="__span-0-738"><a id="__codelineno-0-738" name="__codelineno-0-738"></a>            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-739"><a id="__codelineno-0-739" name="__codelineno-0-739"></a>            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span>
</span><span id="__span-0-740"><a id="__codelineno-0-740" name="__codelineno-0-740"></a>        <span class="p">)</span>
</span><span id="__span-0-741"><a id="__codelineno-0-741" name="__codelineno-0-741"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"bps,sd-&gt;bpd"</span><span class="p">,</span> <span class="n">feature_acts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="p">)</span>
</span><span id="__span-0-742"><a id="__codelineno-0-742" name="__codelineno-0-742"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-743"><a id="__codelineno-0-743" name="__codelineno-0-743"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span>
</span><span id="__span-0-744"><a id="__codelineno-0-744" name="__codelineno-0-744"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-745"><a id="__codelineno-0-745" name="__codelineno-0-745"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"data"</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span><span class="o">.</span><span class="n">redistribute</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span><span id="__span-0-746"><a id="__codelineno-0-746" name="__codelineno-0-746"></a>    <span class="k">return</span> <span class="n">out</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.set_decoder_to_fixed_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">set_decoder_to_fixed_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">set_decoder_to_fixed_norm</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n"><span title="float">float</span></span><span class="p">,</span> <span class="n">force_exact</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Set decoder weights to a fixed norm.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-905">905</a></span>
<span class="normal"><a href="#__codelineno-0-906">906</a></span>
<span class="normal"><a href="#__codelineno-0-907">907</a></span>
<span class="normal"><a href="#__codelineno-0-908">908</a></span>
<span class="normal"><a href="#__codelineno-0-909">909</a></span>
<span class="normal"><a href="#__codelineno-0-910">910</a></span>
<span class="normal"><a href="#__codelineno-0-911">911</a></span>
<span class="normal"><a href="#__codelineno-0-912">912</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-905"><a id="__codelineno-0-905" name="__codelineno-0-905"></a><span class="nd">@override</span>
</span><span id="__span-0-906"><a id="__codelineno-0-906" name="__codelineno-0-906"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-907"><a id="__codelineno-0-907" name="__codelineno-0-907"></a><span class="k">def</span><span class="w"> </span><span class="nf">set_decoder_to_fixed_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">force_exact</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="__span-0-908"><a id="__codelineno-0-908" name="__codelineno-0-908"></a><span class="w">    </span><span class="sd">"""Set decoder weights to a fixed norm."""</span>
</span><span id="__span-0-909"><a id="__codelineno-0-909" name="__codelineno-0-909"></a>    <span class="k">if</span> <span class="n">force_exact</span><span class="p">:</span>
</span><span id="__span-0-910"><a id="__codelineno-0-910" name="__codelineno-0-910"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">value</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span><span id="__span-0-911"><a id="__codelineno-0-911" name="__codelineno-0-911"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-912"><a id="__codelineno-0-912" name="__codelineno-0-912"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_O</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">value</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="nb">min</span><span class="o">=</span><span class="n">value</span><span class="p">))</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.set_encoder_to_fixed_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">set_encoder_to_fixed_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">set_encoder_to_fixed_norm</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n"><span title="float">float</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Set encoder weights to fixed norm.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-914">914</a></span>
<span class="normal"><a href="#__codelineno-0-915">915</a></span>
<span class="normal"><a href="#__codelineno-0-916">916</a></span>
<span class="normal"><a href="#__codelineno-0-917">917</a></span>
<span class="normal"><a href="#__codelineno-0-918">918</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-914"><a id="__codelineno-0-914" name="__codelineno-0-914"></a><span class="nd">@override</span>
</span><span id="__span-0-915"><a id="__codelineno-0-915" name="__codelineno-0-915"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-916"><a id="__codelineno-0-916" name="__codelineno-0-916"></a><span class="k">def</span><span class="w"> </span><span class="nf">set_encoder_to_fixed_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="__span-0-917"><a id="__codelineno-0-917" name="__codelineno-0-917"></a><span class="w">    </span><span class="sd">"""Set encoder weights to fixed norm."""</span>
</span><span id="__span-0-918"><a id="__codelineno-0-918" name="__codelineno-0-918"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"set_encoder_to_fixed_norm does not make sense for lorsa"</span><span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.dim_maps" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">dim_maps</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">dim_maps</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="lm_saes.utils.distributed.DimMap">DimMap</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return a dictionary mapping parameter names to dimension maps.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="lm_saes.utils.distributed.DimMap">DimMap</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary mapping parameter names to DimMap objects.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-942">942</a></span>
<span class="normal"><a href="#__codelineno-0-943">943</a></span>
<span class="normal"><a href="#__codelineno-0-944">944</a></span>
<span class="normal"><a href="#__codelineno-0-945">945</a></span>
<span class="normal"><a href="#__codelineno-0-946">946</a></span>
<span class="normal"><a href="#__codelineno-0-947">947</a></span>
<span class="normal"><a href="#__codelineno-0-948">948</a></span>
<span class="normal"><a href="#__codelineno-0-949">949</a></span>
<span class="normal"><a href="#__codelineno-0-950">950</a></span>
<span class="normal"><a href="#__codelineno-0-951">951</a></span>
<span class="normal"><a href="#__codelineno-0-952">952</a></span>
<span class="normal"><a href="#__codelineno-0-953">953</a></span>
<span class="normal"><a href="#__codelineno-0-954">954</a></span>
<span class="normal"><a href="#__codelineno-0-955">955</a></span>
<span class="normal"><a href="#__codelineno-0-956">956</a></span>
<span class="normal"><a href="#__codelineno-0-957">957</a></span>
<span class="normal"><a href="#__codelineno-0-958">958</a></span>
<span class="normal"><a href="#__codelineno-0-959">959</a></span>
<span class="normal"><a href="#__codelineno-0-960">960</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-942"><a id="__codelineno-0-942" name="__codelineno-0-942"></a><span class="nd">@override</span>
</span><span id="__span-0-943"><a id="__codelineno-0-943" name="__codelineno-0-943"></a><span class="k">def</span><span class="w"> </span><span class="nf">dim_maps</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DimMap</span><span class="p">]:</span>
</span><span id="__span-0-944"><a id="__codelineno-0-944" name="__codelineno-0-944"></a><span class="w">    </span><span class="sd">"""Return a dictionary mapping parameter names to dimension maps.</span>
</span><span id="__span-0-945"><a id="__codelineno-0-945" name="__codelineno-0-945"></a>
</span><span id="__span-0-946"><a id="__codelineno-0-946" name="__codelineno-0-946"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-947"><a id="__codelineno-0-947" name="__codelineno-0-947"></a><span class="sd">        A dictionary mapping parameter names to DimMap objects.</span>
</span><span id="__span-0-948"><a id="__codelineno-0-948" name="__codelineno-0-948"></a><span class="sd">    """</span>
</span><span id="__span-0-949"><a id="__codelineno-0-949" name="__codelineno-0-949"></a>    <span class="n">base_maps</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()</span>
</span><span id="__span-0-950"><a id="__codelineno-0-950" name="__codelineno-0-950"></a>    <span class="k">return</span> <span class="p">{</span>
</span><span id="__span-0-951"><a id="__codelineno-0-951" name="__codelineno-0-951"></a>        <span class="o">**</span><span class="n">base_maps</span><span class="p">,</span>
</span><span id="__span-0-952"><a id="__codelineno-0-952" name="__codelineno-0-952"></a>        <span class="s2">"W_Q"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-953"><a id="__codelineno-0-953" name="__codelineno-0-953"></a>        <span class="s2">"W_K"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-954"><a id="__codelineno-0-954" name="__codelineno-0-954"></a>        <span class="s2">"W_V"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-955"><a id="__codelineno-0-955" name="__codelineno-0-955"></a>        <span class="s2">"W_O"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-956"><a id="__codelineno-0-956" name="__codelineno-0-956"></a>        <span class="s2">"b_Q"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-957"><a id="__codelineno-0-957" name="__codelineno-0-957"></a>        <span class="s2">"b_K"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-958"><a id="__codelineno-0-958" name="__codelineno-0-958"></a>        <span class="s2">"b_V"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
</span><span id="__span-0-959"><a id="__codelineno-0-959" name="__codelineno-0-959"></a>        <span class="s2">"b_D"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({}),</span>
</span><span id="__span-0-960"><a id="__codelineno-0-960" name="__codelineno-0-960"></a>    <span class="p">}</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.prepare_input" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_input</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">prepare_input</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tuple">tuple</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">],</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare input tensor.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-962">962</a></span>
<span class="normal"><a href="#__codelineno-0-963">963</a></span>
<span class="normal"><a href="#__codelineno-0-964">964</a></span>
<span class="normal"><a href="#__codelineno-0-965">965</a></span>
<span class="normal"><a href="#__codelineno-0-966">966</a></span>
<span class="normal"><a href="#__codelineno-0-967">967</a></span>
<span class="normal"><a href="#__codelineno-0-968">968</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-962"><a id="__codelineno-0-962" name="__codelineno-0-962"></a><span class="nd">@override</span>
</span><span id="__span-0-963"><a id="__codelineno-0-963" name="__codelineno-0-963"></a><span class="k">def</span><span class="w"> </span><span class="nf">prepare_input</span><span class="p">(</span>
</span><span id="__span-0-964"><a id="__codelineno-0-964" name="__codelineno-0-964"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="__span-0-965"><a id="__codelineno-0-965" name="__codelineno-0-965"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
</span><span id="__span-0-966"><a id="__codelineno-0-966" name="__codelineno-0-966"></a><span class="w">    </span><span class="sd">"""Prepare input tensor."""</span>
</span><span id="__span-0-967"><a id="__codelineno-0-967" name="__codelineno-0-967"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_point_in</span><span class="p">]</span>
</span><span id="__span-0-968"><a id="__codelineno-0-968" name="__codelineno-0-968"></a>    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="p">{},</span> <span class="p">{}</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.LowRankSparseAttention.prepare_label" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_label</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">prepare_label</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare label tensor.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/lorsa.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-970">970</a></span>
<span class="normal"><a href="#__codelineno-0-971">971</a></span>
<span class="normal"><a href="#__codelineno-0-972">972</a></span>
<span class="normal"><a href="#__codelineno-0-973">973</a></span>
<span class="normal"><a href="#__codelineno-0-974">974</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-970"><a id="__codelineno-0-970" name="__codelineno-0-970"></a><span class="nd">@override</span>
</span><span id="__span-0-971"><a id="__codelineno-0-971" name="__codelineno-0-971"></a><span class="k">def</span><span class="w"> </span><span class="nf">prepare_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="__span-0-972"><a id="__codelineno-0-972" name="__codelineno-0-972"></a><span class="w">    </span><span class="sd">"""Prepare label tensor."""</span>
</span><span id="__span-0-973"><a id="__codelineno-0-973" name="__codelineno-0-973"></a>    <span class="n">label</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">hook_point_out</span><span class="p">]</span>
</span><span id="__span-0-974"><a id="__codelineno-0-974" name="__codelineno-0-974"></a>    <span class="k">return</span> <span class="n">label</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.MOLTConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">MOLTConfig</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            BaseSAEConfig


  
      pydantic-model
   (lm_saes.abstract_sae.BaseSAEConfig)" href="#lm_saes.BaseSAEConfig">BaseSAEConfig</a></code></p>

        <p>Configuration for Mixture of Linear Transforms (MOLT).</p>
<p>MOLT is a more efficient alternative to transcoders that sparsely replaces
MLP computation in transformers. It converts dense MLP layers into sparse,
interpretable linear transforms.</p>

    
      <p>Config:</p>
      <ul>
          <li><code>arbitrary_types_allowed</code>: <code class="highlight language-python"><span class="kc">True</span></code></li>
      </ul>

        <p>Fields:</p>
        <ul>
            <li>
              <code><span title="lm_saes.molt.MOLTConfig.device">device</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.molt.MOLTConfig.dtype">dtype</span></code>
                (<code><span title="torch.dtype">dtype</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            d_model


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.d_model)" href="#lm_saes.BaseSAEConfig.d_model">d_model</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            expansion_factor


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.expansion_factor)" href="#lm_saes.BaseSAEConfig.expansion_factor">expansion_factor</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_decoder_bias


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.use_decoder_bias)" href="#lm_saes.BaseSAEConfig.use_decoder_bias">use_decoder_bias</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            act_fn


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.act_fn)" href="#lm_saes.BaseSAEConfig.act_fn">act_fn</a></code>
                (<code><span title="typing.Literal">Literal</span>['relu', 'jumprelu', 'topk', 'batchtopk', 'batchlayertopk', 'layertopk']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            norm_activation


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.norm_activation)" href="#lm_saes.BaseSAEConfig.norm_activation">norm_activation</a></code>
                (<code><span title="typing.Literal">Literal</span>['token-wise', 'batch-wise', 'dataset-wise', 'inference']</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_include_decoder_norm


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.sparsity_include_decoder_norm)" href="#lm_saes.BaseSAEConfig.sparsity_include_decoder_norm">sparsity_include_decoder_norm</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            top_k


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.top_k)" href="#lm_saes.BaseSAEConfig.top_k">top_k</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            use_triton_kernel


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.use_triton_kernel)" href="#lm_saes.BaseSAEConfig.use_triton_kernel">use_triton_kernel</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            sparsity_threshold_for_triton_spmm_kernel


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.sparsity_threshold_for_triton_spmm_kernel)" href="#lm_saes.BaseSAEConfig.sparsity_threshold_for_triton_spmm_kernel">sparsity_threshold_for_triton_spmm_kernel</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            jumprelu_threshold_window


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.jumprelu_threshold_window)" href="#lm_saes.BaseSAEConfig.jumprelu_threshold_window">jumprelu_threshold_window</a></code>
                (<code><span title="float">float</span></code>)
            </li>
            <li>
              <code><span title="lm_saes.molt.MOLTConfig.sae_type">sae_type</span></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            hook_point_in


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.hook_point_in)" href="#lm_saes.MOLTConfig.hook_point_in">hook_point_in</a></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            hook_point_out


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.hook_point_out)" href="#lm_saes.MOLTConfig.hook_point_out">hook_point_out</a></code>
                (<code><span title="str">str</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="            rank_counts


  
      pydantic-field
   (lm_saes.molt.MOLTConfig.rank_counts)" href="#lm_saes.MOLTConfig.rank_counts">rank_counts</a></code>
                (<code><span title="dict">dict</span>[<span title="int">int</span>, <span title="int">int</span>]</code>)
            </li>
        </ul>




<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.MOLTConfig.hook_point_in" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">hook_point_in</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">hook_point_in</span><span class="p">:</span> <span class="n"><span title="str">str</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Hook point to capture input activations from.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.MOLTConfig.hook_point_out" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">hook_point_out</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">hook_point_out</span><span class="p">:</span> <span class="n"><span title="str">str</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Hook point to output activations to.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.MOLTConfig.rank_counts" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">rank_counts</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">rank_counts</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="int">int</span></span><span class="p">,</span> <span class="n"><span title="int">int</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Dictionary mapping rank values to their integer counts.
Example: {4: 128, 8: 256, 16: 128} means 128 transforms of rank 4, 256 transforms of rank 8, and 128 transforms of rank 16.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.MOLTConfig.d_sae" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">d_sae</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">d_sae</span><span class="p">:</span> <span class="n"><span title="int">int</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Calculate d_sae based on total rank counts.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.MOLTConfig.available_ranks" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">available_ranks</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">available_ranks</span><span class="p">:</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="int">int</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get sorted list of available ranks.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="lm_saes.MOLTConfig.num_rank_types" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">num_rank_types</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">num_rank_types</span><span class="p">:</span> <span class="n"><span title="int">int</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Number of different rank types.</p>

    </div>

</div>




<div class="doc doc-object doc-function">


<h3 id="lm_saes.MOLTConfig.generate_rank_assignments" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">generate_rank_assignments</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">generate_rank_assignments</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="int">int</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Generate rank assignment for each of the d_sae linear transforms.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="list">list</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of rank assignments for each transform.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="list">list</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For example: [1, 1, 1, 1, 2, 2, 4].</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-58"><a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="k">def</span><span class="w"> </span><span class="nf">generate_rank_assignments</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
</span><span id="__span-0-59"><a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="w">    </span><span class="sd">"""Generate rank assignment for each of the d_sae linear transforms.</span>
</span><span id="__span-0-60"><a id="__codelineno-0-60" name="__codelineno-0-60"></a>
</span><span id="__span-0-61"><a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-62"><a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        List of rank assignments for each transform.</span>
</span><span id="__span-0-63"><a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        For example: [1, 1, 1, 1, 2, 2, 4].</span>
</span><span id="__span-0-64"><a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    """</span>
</span><span id="__span-0-65"><a id="__codelineno-0-65" name="__codelineno-0-65"></a>    <span class="n">assignments</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-66"><a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
</span><span id="__span-0-67"><a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="n">assignments</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">rank</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_counts</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>
</span><span id="__span-0-68"><a id="__codelineno-0-68" name="__codelineno-0-68"></a>    <span class="k">return</span> <span class="n">assignments</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.MOLTConfig.get_local_rank_assignments" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_local_rank_assignments</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">get_local_rank_assignments</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">model_parallel_size</span><span class="p">:</span> <span class="n"><span title="int">int</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="list">list</span></span><span class="p">[</span><span class="n"><span title="int">int</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get rank assignments for a specific local device in distributed running.</p>
<p>Each device gets all rank groups, with each group evenly divided across devices.
This ensures consistent encoder/decoder sharding without feature_acts redistribution.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model_parallel_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of model parallel devices for training and inference.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="list">list</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of rank assignments for this local device</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="list">list</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For example:</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="list">list</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>global_rank_assignments = [1, 1, 2, 2], model_parallel_size = 2 -&gt; local_rank_assignments = [1, 2]</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span>
<span class="normal"><a href="#__codelineno-0-87">87</a></span>
<span class="normal"><a href="#__codelineno-0-88">88</a></span>
<span class="normal"><a href="#__codelineno-0-89">89</a></span>
<span class="normal"><a href="#__codelineno-0-90">90</a></span>
<span class="normal"><a href="#__codelineno-0-91">91</a></span>
<span class="normal"><a href="#__codelineno-0-92">92</a></span>
<span class="normal"><a href="#__codelineno-0-93">93</a></span>
<span class="normal"><a href="#__codelineno-0-94">94</a></span>
<span class="normal"><a href="#__codelineno-0-95">95</a></span>
<span class="normal"><a href="#__codelineno-0-96">96</a></span>
<span class="normal"><a href="#__codelineno-0-97">97</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-70"><a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_local_rank_assignments</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
</span><span id="__span-0-71"><a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="w">    </span><span class="sd">"""Get rank assignments for a specific local device in distributed running.</span>
</span><span id="__span-0-72"><a id="__codelineno-0-72" name="__codelineno-0-72"></a>
</span><span id="__span-0-73"><a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">    Each device gets all rank groups, with each group evenly divided across devices.</span>
</span><span id="__span-0-74"><a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    This ensures consistent encoder/decoder sharding without feature_acts redistribution.</span>
</span><span id="__span-0-75"><a id="__codelineno-0-75" name="__codelineno-0-75"></a>
</span><span id="__span-0-76"><a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">    Args:</span>
</span><span id="__span-0-77"><a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">        model_parallel_size: Number of model parallel devices for training and inference.</span>
</span><span id="__span-0-78"><a id="__codelineno-0-78" name="__codelineno-0-78"></a>
</span><span id="__span-0-79"><a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-80"><a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        List of rank assignments for this local device</span>
</span><span id="__span-0-81"><a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">        For example:</span>
</span><span id="__span-0-82"><a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">        global_rank_assignments = [1, 1, 2, 2], model_parallel_size = 2 -&gt; local_rank_assignments = [1, 2]</span>
</span><span id="__span-0-83"><a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">    """</span>
</span><span id="__span-0-84"><a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="n">local_assignments</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-85"><a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
</span><span id="__span-0-86"><a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="n">global_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_counts</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
</span><span id="__span-0-87"><a id="__codelineno-0-87" name="__codelineno-0-87"></a>
</span><span id="__span-0-88"><a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="c1"># Verify even division</span>
</span><span id="__span-0-89"><a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="k">assert</span> <span class="n">global_count</span> <span class="o">%</span> <span class="n">model_parallel_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span>
</span><span id="__span-0-90"><a id="__codelineno-0-90" name="__codelineno-0-90"></a>            <span class="sa">f</span><span class="s2">"Transform rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> global count </span><span class="si">{</span><span class="n">global_count</span><span class="si">}</span><span class="s2"> not divisible by "</span>
</span><span id="__span-0-91"><a id="__codelineno-0-91" name="__codelineno-0-91"></a>            <span class="sa">f</span><span class="s2">"model_parallel_size </span><span class="si">{</span><span class="n">model_parallel_size</span><span class="si">}</span><span class="s2">"</span>
</span><span id="__span-0-92"><a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="p">)</span>
</span><span id="__span-0-93"><a id="__codelineno-0-93" name="__codelineno-0-93"></a>
</span><span id="__span-0-94"><a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="n">local_count</span> <span class="o">=</span> <span class="n">global_count</span> <span class="o">//</span> <span class="n">model_parallel_size</span>
</span><span id="__span-0-95"><a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="n">local_assignments</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">rank</span><span class="p">]</span> <span class="o">*</span> <span class="n">local_count</span><span class="p">)</span>
</span><span id="__span-0-96"><a id="__codelineno-0-96" name="__codelineno-0-96"></a>
</span><span id="__span-0-97"><a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="k">return</span> <span class="n">local_assignments</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="lm_saes.MixtureOfLinearTransform" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">MixtureOfLinearTransform</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">MixtureOfLinearTransform</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">cfg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            MOLTConfig


  
      pydantic-model
   (lm_saes.molt.MOLTConfig)" href="#lm_saes.MOLTConfig">MOLTConfig</a></span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n"><span title="torch.distributed.device_mesh.DeviceMesh">DeviceMesh</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="lm_saes.abstract_sae.AbstractSparseAutoEncoder">AbstractSparseAutoEncoder</span></code></p>



        <p>Mixture of Linear Transforms (MOLT) model.</p>
<p>MOLT is a sparse autoencoder variant that uses d_sae linear transforms,
each with its own rank for UtVt decomposition.</p>
<p>Mathematical Formulation:
- Encoder: (et  x - bt) where  is the activation function
- Decoder:  f  (U @ V @ x) where f are feature activations
- Decoder norm: ||UV||_F for each transform i</p>
<p>The rank of each transform is determined by the rank_counts configuration,
allowing for adaptive model capacity allocation.</p>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-136"><a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">MOLTConfig</span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">:</span> <span class="n">DeviceMesh</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-137"><a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-138"><a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
</span><span id="__span-0-139"><a id="__codelineno-0-139" name="__codelineno-0-139"></a>
</span><span id="__span-0-140"><a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="c1"># Generate rank assignment for each linear transform</span>
</span><span id="__span-0-141"><a id="__codelineno-0-141" name="__codelineno-0-141"></a>    <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-142"><a id="__codelineno-0-142" name="__codelineno-0-142"></a>        <span class="c1"># In distributed training/inference, get local rank assignments</span>
</span><span id="__span-0-143"><a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="c1"># Use model dimension for tensor parallelism</span>
</span><span id="__span-0-144"><a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="n">mesh_dim_names</span> <span class="o">=</span> <span class="n">device_mesh</span><span class="o">.</span><span class="n">mesh_dim_names</span>
</span><span id="__span-0-145"><a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="k">if</span> <span class="n">mesh_dim_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-146"><a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="n">model_dim_index</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-147"><a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-148"><a id="__codelineno-0-148" name="__codelineno-0-148"></a>            <span class="n">model_dim_index</span> <span class="o">=</span> <span class="n">mesh_dim_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"model"</span><span class="p">)</span> <span class="k">if</span> <span class="s2">"model"</span> <span class="ow">in</span> <span class="n">mesh_dim_names</span> <span class="k">else</span> <span class="mi">0</span>
</span><span id="__span-0-149"><a id="__codelineno-0-149" name="__codelineno-0-149"></a>        <span class="n">local_rank</span> <span class="o">=</span> <span class="n">device_mesh</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">(</span>
</span><span id="__span-0-150"><a id="__codelineno-0-150" name="__codelineno-0-150"></a>            <span class="n">mesh_dim</span><span class="o">=</span><span class="n">model_dim_index</span>
</span><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="p">)</span>  <span class="c1"># this rank stands for device rank of this process</span>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="n">model_parallel_size</span> <span class="o">=</span> <span class="n">device_mesh</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">mesh_dim</span><span class="o">=</span><span class="n">model_dim_index</span><span class="p">)</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rank_assignments</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get_local_rank_assignments</span><span class="p">(</span><span class="n">model_parallel_size</span><span class="p">)</span>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cfg</span><span class="o">.</span><span class="n">rank_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a>                <span class="sa">f</span><span class="s2">"Rank </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2"> global transforms, device rank </span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_assignments</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="si">}</span><span class="s2"> transforms"</span>
</span><span id="__span-0-159"><a id="__codelineno-0-159" name="__codelineno-0-159"></a>            <span class="p">)</span>
</span><span id="__span-0-160"><a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="c1"># Non-distributed case</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rank_assignments</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">generate_rank_assignments</span><span class="p">()</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="c1"># Encoder parameters (standard SAE encoder)</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="c1"># Decoder parameters: d_sae linear transforms, each with UtVt decomposition</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="c1"># Group by rank for efficient parameter storage</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterDict</span><span class="p">()</span>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">V_matrices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterDict</span><span class="p">()</span>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">cfg</span><span class="o">.</span><span class="n">available_ranks</span><span class="p">:</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a>            <span class="n">count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_assignments</span> <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="n">rank</span><span class="p">)</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>            <span class="c1"># Always create parameters for all rank types for consistency</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a>            <span class="c1"># In non-distributed case, we can skip empty tensors</span>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a>            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">rank</span><span class="p">)]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a>                <span class="p">)</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">V_matrices</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">rank</span><span class="p">)]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-183"><a id="__codelineno-0-183" name="__codelineno-0-183"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-184"><a id="__codelineno-0-184" name="__codelineno-0-184"></a>                <span class="p">)</span>
</span><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a>        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="c1"># Distributed initialization</span>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="n">w_e_placements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"W_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="n">b_e_placements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">)</span>
</span><span id="__span-0-192"><a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-193"><a id="__codelineno-0-193" name="__codelineno-0-193"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-194"><a id="__codelineno-0-194" name="__codelineno-0-194"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-195"><a id="__codelineno-0-195" name="__codelineno-0-195"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-196"><a id="__codelineno-0-196" name="__codelineno-0-196"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-197"><a id="__codelineno-0-197" name="__codelineno-0-197"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-198"><a id="__codelineno-0-198" name="__codelineno-0-198"></a>                <span class="n">placements</span><span class="o">=</span><span class="n">w_e_placements</span><span class="p">,</span>
</span><span id="__span-0-199"><a id="__codelineno-0-199" name="__codelineno-0-199"></a>            <span class="p">)</span>
</span><span id="__span-0-200"><a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="p">)</span>
</span><span id="__span-0-201"><a id="__codelineno-0-201" name="__codelineno-0-201"></a>
</span><span id="__span-0-202"><a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_E</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-203"><a id="__codelineno-0-203" name="__codelineno-0-203"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-204"><a id="__codelineno-0-204" name="__codelineno-0-204"></a>                <span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span>
</span><span id="__span-0-205"><a id="__codelineno-0-205" name="__codelineno-0-205"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-206"><a id="__codelineno-0-206" name="__codelineno-0-206"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-207"><a id="__codelineno-0-207" name="__codelineno-0-207"></a>                <span class="n">placements</span><span class="o">=</span><span class="n">b_e_placements</span><span class="p">,</span>
</span><span id="__span-0-208"><a id="__codelineno-0-208" name="__codelineno-0-208"></a>            <span class="p">)</span>
</span><span id="__span-0-209"><a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="p">)</span>
</span><span id="__span-0-210"><a id="__codelineno-0-210" name="__codelineno-0-210"></a>
</span><span id="__span-0-211"><a id="__codelineno-0-211" name="__codelineno-0-211"></a>        <span class="c1"># Decoder parameters: d_sae linear transforms, each with UtVt decomposition</span>
</span><span id="__span-0-212"><a id="__codelineno-0-212" name="__codelineno-0-212"></a>        <span class="c1"># Group by rank for efficient parameter storage</span>
</span><span id="__span-0-213"><a id="__codelineno-0-213" name="__codelineno-0-213"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterDict</span><span class="p">()</span>
</span><span id="__span-0-214"><a id="__codelineno-0-214" name="__codelineno-0-214"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">V_matrices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterDict</span><span class="p">()</span>
</span><span id="__span-0-215"><a id="__codelineno-0-215" name="__codelineno-0-215"></a>
</span><span id="__span-0-216"><a id="__codelineno-0-216" name="__codelineno-0-216"></a>        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">cfg</span><span class="o">.</span><span class="n">available_ranks</span><span class="p">:</span>
</span><span id="__span-0-217"><a id="__codelineno-0-217" name="__codelineno-0-217"></a>            <span class="n">local_count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_assignments</span> <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="n">rank</span><span class="p">)</span>
</span><span id="__span-0-218"><a id="__codelineno-0-218" name="__codelineno-0-218"></a>            <span class="k">assert</span> <span class="n">local_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> has local_count=0, sharding logic error"</span>
</span><span id="__span-0-219"><a id="__codelineno-0-219" name="__codelineno-0-219"></a>
</span><span id="__span-0-220"><a id="__codelineno-0-220" name="__codelineno-0-220"></a>            <span class="c1"># Create DTensor with GLOBAL shape</span>
</span><span id="__span-0-221"><a id="__codelineno-0-221" name="__codelineno-0-221"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">rank</span><span class="p">)]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-222"><a id="__codelineno-0-222" name="__codelineno-0-222"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-223"><a id="__codelineno-0-223" name="__codelineno-0-223"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">rank_counts</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span>  <span class="c1"># GLOBAL count</span>
</span><span id="__span-0-224"><a id="__codelineno-0-224" name="__codelineno-0-224"></a>                    <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-225"><a id="__codelineno-0-225" name="__codelineno-0-225"></a>                    <span class="n">rank</span><span class="p">,</span>
</span><span id="__span-0-226"><a id="__codelineno-0-226" name="__codelineno-0-226"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-227"><a id="__codelineno-0-227" name="__codelineno-0-227"></a>                    <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-228"><a id="__codelineno-0-228" name="__codelineno-0-228"></a>                    <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"U_matrices"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-229"><a id="__codelineno-0-229" name="__codelineno-0-229"></a>                <span class="p">)</span>
</span><span id="__span-0-230"><a id="__codelineno-0-230" name="__codelineno-0-230"></a>            <span class="p">)</span>
</span><span id="__span-0-231"><a id="__codelineno-0-231" name="__codelineno-0-231"></a>
</span><span id="__span-0-232"><a id="__codelineno-0-232" name="__codelineno-0-232"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">V_matrices</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">rank</span><span class="p">)]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-233"><a id="__codelineno-0-233" name="__codelineno-0-233"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-234"><a id="__codelineno-0-234" name="__codelineno-0-234"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">rank_counts</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span>  <span class="c1"># GLOBAL count</span>
</span><span id="__span-0-235"><a id="__codelineno-0-235" name="__codelineno-0-235"></a>                    <span class="n">rank</span><span class="p">,</span>
</span><span id="__span-0-236"><a id="__codelineno-0-236" name="__codelineno-0-236"></a>                    <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-237"><a id="__codelineno-0-237" name="__codelineno-0-237"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-238"><a id="__codelineno-0-238" name="__codelineno-0-238"></a>                    <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-239"><a id="__codelineno-0-239" name="__codelineno-0-239"></a>                    <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"V_matrices"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-240"><a id="__codelineno-0-240" name="__codelineno-0-240"></a>                <span class="p">)</span>
</span><span id="__span-0-241"><a id="__codelineno-0-241" name="__codelineno-0-241"></a>            <span class="p">)</span>
</span><span id="__span-0-242"><a id="__codelineno-0-242" name="__codelineno-0-242"></a>
</span><span id="__span-0-243"><a id="__codelineno-0-243" name="__codelineno-0-243"></a>        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_decoder_bias</span><span class="p">:</span>
</span><span id="__span-0-244"><a id="__codelineno-0-244" name="__codelineno-0-244"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
</span><span id="__span-0-245"><a id="__codelineno-0-245" name="__codelineno-0-245"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="__span-0-246"><a id="__codelineno-0-246" name="__codelineno-0-246"></a>                    <span class="n">cfg</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="__span-0-247"><a id="__codelineno-0-247" name="__codelineno-0-247"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-248"><a id="__codelineno-0-248" name="__codelineno-0-248"></a>                    <span class="n">device_mesh</span><span class="o">=</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-249"><a id="__codelineno-0-249" name="__codelineno-0-249"></a>                    <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_D"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-250"><a id="__codelineno-0-250" name="__codelineno-0-250"></a>                <span class="p">)</span>
</span><span id="__span-0-251"><a id="__codelineno-0-251" name="__codelineno-0-251"></a>            <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="lm_saes.MixtureOfLinearTransform.dim_maps" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">dim_maps</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">dim_maps</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="lm_saes.utils.distributed.DimMap">DimMap</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return dimension maps for distributed training.</p>
<p>Encoder and decoder use consistent sharding:
- W_E sharded along d_sae (output) dimension
- U/V matrices sharded along transform count (first) dimension
This ensures feature_acts from encoder can directly feed decoder without redistribution.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-253"><a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="k">def</span><span class="w"> </span><span class="nf">dim_maps</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DimMap</span><span class="p">]:</span>
</span><span id="__span-0-254"><a id="__codelineno-0-254" name="__codelineno-0-254"></a><span class="w">    </span><span class="sd">"""Return dimension maps for distributed training.</span>
</span><span id="__span-0-255"><a id="__codelineno-0-255" name="__codelineno-0-255"></a>
</span><span id="__span-0-256"><a id="__codelineno-0-256" name="__codelineno-0-256"></a><span class="sd">    Encoder and decoder use consistent sharding:</span>
</span><span id="__span-0-257"><a id="__codelineno-0-257" name="__codelineno-0-257"></a><span class="sd">    - W_E sharded along d_sae (output) dimension</span>
</span><span id="__span-0-258"><a id="__codelineno-0-258" name="__codelineno-0-258"></a><span class="sd">    - U/V matrices sharded along transform count (first) dimension</span>
</span><span id="__span-0-259"><a id="__codelineno-0-259" name="__codelineno-0-259"></a><span class="sd">    This ensures feature_acts from encoder can directly feed decoder without redistribution.</span>
</span><span id="__span-0-260"><a id="__codelineno-0-260" name="__codelineno-0-260"></a><span class="sd">    """</span>
</span><span id="__span-0-261"><a id="__codelineno-0-261" name="__codelineno-0-261"></a>    <span class="n">base_maps</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()</span>
</span><span id="__span-0-262"><a id="__codelineno-0-262" name="__codelineno-0-262"></a>
</span><span id="__span-0-263"><a id="__codelineno-0-263" name="__codelineno-0-263"></a>    <span class="n">molt_maps</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-264"><a id="__codelineno-0-264" name="__codelineno-0-264"></a>        <span class="s2">"W_E"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>  <span class="c1"># Shard along d_sae dimension</span>
</span><span id="__span-0-265"><a id="__codelineno-0-265" name="__codelineno-0-265"></a>        <span class="s2">"b_E"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>  <span class="c1"># Shard along d_sae dimension</span>
</span><span id="__span-0-266"><a id="__codelineno-0-266" name="__codelineno-0-266"></a>        <span class="c1"># U and V matrices sharded along transform count dimension</span>
</span><span id="__span-0-267"><a id="__codelineno-0-267" name="__codelineno-0-267"></a>        <span class="c1"># This matches the W_E sharding pattern for feature_acts compatibility</span>
</span><span id="__span-0-268"><a id="__codelineno-0-268" name="__codelineno-0-268"></a>        <span class="s2">"U_matrices"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>  <span class="c1"># Shard along transform count</span>
</span><span id="__span-0-269"><a id="__codelineno-0-269" name="__codelineno-0-269"></a>        <span class="s2">"V_matrices"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>  <span class="c1"># Shard along transform count</span>
</span><span id="__span-0-270"><a id="__codelineno-0-270" name="__codelineno-0-270"></a>        <span class="s2">"b_D"</span><span class="p">:</span> <span class="n">DimMap</span><span class="p">({}),</span>  <span class="c1"># Replicate decoder bias</span>
</span><span id="__span-0-271"><a id="__codelineno-0-271" name="__codelineno-0-271"></a>    <span class="p">}</span>
</span><span id="__span-0-272"><a id="__codelineno-0-272" name="__codelineno-0-272"></a>
</span><span id="__span-0-273"><a id="__codelineno-0-273" name="__codelineno-0-273"></a>    <span class="k">return</span> <span class="n">base_maps</span> <span class="o">|</span> <span class="n">molt_maps</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.MixtureOfLinearTransform.encoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">encoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">encoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the norm of the encoder weight.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-275"><a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="nd">@override</span>
</span><span id="__span-0-276"><a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"encoder_norm"</span><span class="p">)</span>
</span><span id="__span-0-277"><a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="k">def</span><span class="w"> </span><span class="nf">encoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-278"><a id="__codelineno-0-278" name="__codelineno-0-278"></a><span class="w">    </span><span class="sd">"""Compute the norm of the encoder weight."""</span>
</span><span id="__span-0-279"><a id="__codelineno-0-279" name="__codelineno-0-279"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-280"><a id="__codelineno-0-280" name="__codelineno-0-280"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-281"><a id="__codelineno-0-281" name="__codelineno-0-281"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-282"><a id="__codelineno-0-282" name="__codelineno-0-282"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-283"><a id="__codelineno-0-283" name="__codelineno-0-283"></a>        <span class="k">return</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-284"><a id="__codelineno-0-284" name="__codelineno-0-284"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="o">.</span><span class="n">to_local</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">),</span>
</span><span id="__span-0-285"><a id="__codelineno-0-285" name="__codelineno-0-285"></a>            <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-286"><a id="__codelineno-0-286" name="__codelineno-0-286"></a>            <span class="n">placements</span><span class="o">=</span><span class="n">DimMap</span><span class="p">({</span><span class="s2">"model"</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">keepdim</span> <span class="k">else</span> <span class="mi">0</span><span class="p">})</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>
</span><span id="__span-0-287"><a id="__codelineno-0-287" name="__codelineno-0-287"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.MixtureOfLinearTransform.decoder_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decoder_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="p">:</span> <span class="n"><span title="bool">bool</span></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the Frobenius norm of each linear transform's UtVt decomposition.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-289"><a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="nd">@override</span>
</span><span id="__span-0-290"><a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"decoder_norm"</span><span class="p">)</span>
</span><span id="__span-0-291"><a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="k">def</span><span class="w"> </span><span class="nf">decoder_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-292"><a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="w">    </span><span class="sd">"""Compute the Frobenius norm of each linear transform's UtVt decomposition."""</span>
</span><span id="__span-0-293"><a id="__codelineno-0-293" name="__codelineno-0-293"></a>    <span class="c1"># Pre-compute norms for all rank groups and concatenate</span>
</span><span id="__span-0-294"><a id="__codelineno-0-294" name="__codelineno-0-294"></a>    <span class="n">norm_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-295"><a id="__codelineno-0-295" name="__codelineno-0-295"></a>
</span><span id="__span-0-296"><a id="__codelineno-0-296" name="__codelineno-0-296"></a>    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">available_ranks</span><span class="p">:</span>
</span><span id="__span-0-297"><a id="__codelineno-0-297" name="__codelineno-0-297"></a>        <span class="n">rank_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
</span><span id="__span-0-298"><a id="__codelineno-0-298" name="__codelineno-0-298"></a>        <span class="k">if</span> <span class="n">rank_str</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span><span class="p">:</span>
</span><span id="__span-0-299"><a id="__codelineno-0-299" name="__codelineno-0-299"></a>            <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>  <span class="c1"># (count, d_model, rank)</span>
</span><span id="__span-0-300"><a id="__codelineno-0-300" name="__codelineno-0-300"></a>            <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">V_matrices</span><span class="p">[</span><span class="n">rank_str</span><span class="p">]</span>  <span class="c1"># (count, rank, d_model)</span>
</span><span id="__span-0-301"><a id="__codelineno-0-301" name="__codelineno-0-301"></a>
</span><span id="__span-0-302"><a id="__codelineno-0-302" name="__codelineno-0-302"></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">)</span> <span class="o">==</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">),</span> <span class="s2">"U and V must have the same type"</span>
</span><span id="__span-0-303"><a id="__codelineno-0-303" name="__codelineno-0-303"></a>            <span class="c1"># Handle DTensor case - work with local shards</span>
</span><span id="__span-0-304"><a id="__codelineno-0-304" name="__codelineno-0-304"></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-305"><a id="__codelineno-0-305" name="__codelineno-0-305"></a>                <span class="n">U_local</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">to_local</span><span class="p">()</span>
</span><span id="__span-0-306"><a id="__codelineno-0-306" name="__codelineno-0-306"></a>                <span class="n">V_local</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">to_local</span><span class="p">()</span>
</span><span id="__span-0-307"><a id="__codelineno-0-307" name="__codelineno-0-307"></a>
</span><span id="__span-0-308"><a id="__codelineno-0-308" name="__codelineno-0-308"></a>                <span class="c1"># Compute ||U_i @ V_i||_F for each transform (local shard)</span>
</span><span id="__span-0-309"><a id="__codelineno-0-309" name="__codelineno-0-309"></a>                <span class="n">UV_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">U_local</span><span class="p">,</span> <span class="n">V_local</span><span class="p">)</span>  <span class="c1"># (local_count, d_model, d_model)</span>
</span><span id="__span-0-310"><a id="__codelineno-0-310" name="__codelineno-0-310"></a>                <span class="n">UV_norms_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">UV_local</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">UV_local</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="s2">"fro"</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (local_count,)</span>
</span><span id="__span-0-311"><a id="__codelineno-0-311" name="__codelineno-0-311"></a>
</span><span id="__span-0-312"><a id="__codelineno-0-312" name="__codelineno-0-312"></a>                <span class="c1"># Convert back to DTensor with proper placement</span>
</span><span id="__span-0-313"><a id="__codelineno-0-313" name="__codelineno-0-313"></a>                <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-314"><a id="__codelineno-0-314" name="__codelineno-0-314"></a>                <span class="n">UV_norms</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-315"><a id="__codelineno-0-315" name="__codelineno-0-315"></a>                    <span class="n">UV_norms_local</span><span class="p">,</span>
</span><span id="__span-0-316"><a id="__codelineno-0-316" name="__codelineno-0-316"></a>                    <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-317"><a id="__codelineno-0-317" name="__codelineno-0-317"></a>                    <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"U_matrices"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">)[</span>
</span><span id="__span-0-318"><a id="__codelineno-0-318" name="__codelineno-0-318"></a>                        <span class="mi">0</span><span class="p">:</span><span class="mi">1</span>
</span><span id="__span-0-319"><a id="__codelineno-0-319" name="__codelineno-0-319"></a>                    <span class="p">],</span>  <span class="c1"># Only keep first dimension placement</span>
</span><span id="__span-0-320"><a id="__codelineno-0-320" name="__codelineno-0-320"></a>                <span class="p">)</span>
</span><span id="__span-0-321"><a id="__codelineno-0-321" name="__codelineno-0-321"></a>                <span class="n">norm_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">UV_norms</span><span class="p">)</span>
</span><span id="__span-0-322"><a id="__codelineno-0-322" name="__codelineno-0-322"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-323"><a id="__codelineno-0-323" name="__codelineno-0-323"></a>                <span class="c1"># Non-distributed case</span>
</span><span id="__span-0-324"><a id="__codelineno-0-324" name="__codelineno-0-324"></a>                <span class="n">UV</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>  <span class="c1"># (count, d_model, d_model)</span>
</span><span id="__span-0-325"><a id="__codelineno-0-325" name="__codelineno-0-325"></a>                <span class="n">UV_norms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">UV</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">UV</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="s2">"fro"</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (count,)</span>
</span><span id="__span-0-326"><a id="__codelineno-0-326" name="__codelineno-0-326"></a>                <span class="n">norm_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">UV_norms</span><span class="p">)</span>
</span><span id="__span-0-327"><a id="__codelineno-0-327" name="__codelineno-0-327"></a>
</span><span id="__span-0-328"><a id="__codelineno-0-328" name="__codelineno-0-328"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">norm_list</span><span class="p">:</span>
</span><span id="__span-0-329"><a id="__codelineno-0-329" name="__codelineno-0-329"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-330"><a id="__codelineno-0-330" name="__codelineno-0-330"></a>            <span class="c1"># Create replicated DTensor for zero norms</span>
</span><span id="__span-0-331"><a id="__codelineno-0-331" name="__codelineno-0-331"></a>            <span class="n">norms</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-332"><a id="__codelineno-0-332" name="__codelineno-0-332"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
</span><span id="__span-0-333"><a id="__codelineno-0-333" name="__codelineno-0-333"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-334"><a id="__codelineno-0-334" name="__codelineno-0-334"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>  <span class="c1"># Same as b_E sharding</span>
</span><span id="__span-0-335"><a id="__codelineno-0-335" name="__codelineno-0-335"></a>            <span class="p">)</span>
</span><span id="__span-0-336"><a id="__codelineno-0-336" name="__codelineno-0-336"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-337"><a id="__codelineno-0-337" name="__codelineno-0-337"></a>            <span class="n">norms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">d_sae</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-338"><a id="__codelineno-0-338" name="__codelineno-0-338"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-339"><a id="__codelineno-0-339" name="__codelineno-0-339"></a>        <span class="c1"># Concatenate all norms in correct order</span>
</span><span id="__span-0-340"><a id="__codelineno-0-340" name="__codelineno-0-340"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">norm_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">DTensor</span><span class="p">):</span>
</span><span id="__span-0-341"><a id="__codelineno-0-341" name="__codelineno-0-341"></a>            <span class="c1"># CRITICAL FIX: Avoid full_tensor() to prevent numerical errors</span>
</span><span id="__span-0-342"><a id="__codelineno-0-342" name="__codelineno-0-342"></a>            <span class="c1"># Instead, directly concatenate the DTensors which preserves numerical precision</span>
</span><span id="__span-0-343"><a id="__codelineno-0-343" name="__codelineno-0-343"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-344"><a id="__codelineno-0-344" name="__codelineno-0-344"></a>
</span><span id="__span-0-345"><a id="__codelineno-0-345" name="__codelineno-0-345"></a>            <span class="c1"># Convert each DTensor norm to local tensor and concatenate locally</span>
</span><span id="__span-0-346"><a id="__codelineno-0-346" name="__codelineno-0-346"></a>            <span class="n">local_norms</span> <span class="o">=</span> <span class="p">[</span><span class="n">norm</span><span class="o">.</span><span class="n">to_local</span><span class="p">()</span> <span class="k">for</span> <span class="n">norm</span> <span class="ow">in</span> <span class="n">norm_list</span><span class="p">]</span>
</span><span id="__span-0-347"><a id="__codelineno-0-347" name="__codelineno-0-347"></a>
</span><span id="__span-0-348"><a id="__codelineno-0-348" name="__codelineno-0-348"></a>            <span class="c1"># Concatenate local norms and convert back to DTensor</span>
</span><span id="__span-0-349"><a id="__codelineno-0-349" name="__codelineno-0-349"></a>            <span class="n">norms_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">local_norms</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-350"><a id="__codelineno-0-350" name="__codelineno-0-350"></a>            <span class="n">norms</span> <span class="o">=</span> <span class="n">DTensor</span><span class="o">.</span><span class="n">from_local</span><span class="p">(</span>
</span><span id="__span-0-351"><a id="__codelineno-0-351" name="__codelineno-0-351"></a>                <span class="n">norms_local</span><span class="p">,</span>
</span><span id="__span-0-352"><a id="__codelineno-0-352" name="__codelineno-0-352"></a>                <span class="n">device_mesh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
</span><span id="__span-0-353"><a id="__codelineno-0-353" name="__codelineno-0-353"></a>                <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_maps</span><span class="p">()[</span><span class="s2">"b_E"</span><span class="p">]</span><span class="o">.</span><span class="n">placements</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">),</span>  <span class="c1"># Same as b_E (d_sae dimension)</span>
</span><span id="__span-0-354"><a id="__codelineno-0-354" name="__codelineno-0-354"></a>            <span class="p">)</span>
</span><span id="__span-0-355"><a id="__codelineno-0-355" name="__codelineno-0-355"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-356"><a id="__codelineno-0-356" name="__codelineno-0-356"></a>            <span class="n">norms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">norm_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (d_sae,)</span>
</span><span id="__span-0-357"><a id="__codelineno-0-357" name="__codelineno-0-357"></a>
</span><span id="__span-0-358"><a id="__codelineno-0-358" name="__codelineno-0-358"></a>    <span class="k">if</span> <span class="n">keepdim</span><span class="p">:</span>
</span><span id="__span-0-359"><a id="__codelineno-0-359" name="__codelineno-0-359"></a>        <span class="k">return</span> <span class="n">norms</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-360"><a id="__codelineno-0-360" name="__codelineno-0-360"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-361"><a id="__codelineno-0-361" name="__codelineno-0-361"></a>        <span class="k">return</span> <span class="n">norms</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.MixtureOfLinearTransform.set_encoder_to_fixed_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">set_encoder_to_fixed_norm</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">set_encoder_to_fixed_norm</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n"><span title="float">float</span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Set encoder weights to a fixed norm.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-399"><a id="__codelineno-0-399" name="__codelineno-0-399"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-400"><a id="__codelineno-0-400" name="__codelineno-0-400"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"set_encoder_to_fixed_norm"</span><span class="p">)</span>
</span><span id="__span-0-401"><a id="__codelineno-0-401" name="__codelineno-0-401"></a><span class="k">def</span><span class="w"> </span><span class="nf">set_encoder_to_fixed_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-402"><a id="__codelineno-0-402" name="__codelineno-0-402"></a><span class="w">    </span><span class="sd">"""Set encoder weights to a fixed norm."""</span>
</span><span id="__span-0-403"><a id="__codelineno-0-403" name="__codelineno-0-403"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_E</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">value</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_norm</span><span class="p">(</span><span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.MixtureOfLinearTransform.decode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">decode</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">decode</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Decode feature activations back to model space using MOLT transforms.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feature_acts</code>
            </td>
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_sae'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_sae']</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Feature activations from encode()</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Must contain 'original_x' - the original input tensor</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch d_model'] | <span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, 'batch seq_len d_model']</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Reconstructed tensor in model space</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span>
<span class="normal"><a href="#__codelineno-0-661">661</a></span>
<span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-655"><a id="__codelineno-0-655" name="__codelineno-0-655"></a><span class="nd">@override</span>
</span><span id="__span-0-656"><a id="__codelineno-0-656" name="__codelineno-0-656"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"decode"</span><span class="p">)</span>
</span><span id="__span-0-657"><a id="__codelineno-0-657" name="__codelineno-0-657"></a><span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span>
</span><span id="__span-0-658"><a id="__codelineno-0-658" name="__codelineno-0-658"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-659"><a id="__codelineno-0-659" name="__codelineno-0-659"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-660"><a id="__codelineno-0-660" name="__codelineno-0-660"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_sae"</span><span class="p">],</span>
</span><span id="__span-0-661"><a id="__codelineno-0-661" name="__codelineno-0-661"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_sae"</span><span class="p">],</span>
</span><span id="__span-0-662"><a id="__codelineno-0-662" name="__codelineno-0-662"></a>    <span class="p">],</span>
</span><span id="__span-0-663"><a id="__codelineno-0-663" name="__codelineno-0-663"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-664"><a id="__codelineno-0-664" name="__codelineno-0-664"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-665"><a id="__codelineno-0-665" name="__codelineno-0-665"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">],</span>
</span><span id="__span-0-666"><a id="__codelineno-0-666" name="__codelineno-0-666"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-667"><a id="__codelineno-0-667" name="__codelineno-0-667"></a><span class="p">]:</span>
</span><span id="__span-0-668"><a id="__codelineno-0-668" name="__codelineno-0-668"></a><span class="w">    </span><span class="sd">"""Decode feature activations back to model space using MOLT transforms.</span>
</span><span id="__span-0-669"><a id="__codelineno-0-669" name="__codelineno-0-669"></a>
</span><span id="__span-0-670"><a id="__codelineno-0-670" name="__codelineno-0-670"></a><span class="sd">    Args:</span>
</span><span id="__span-0-671"><a id="__codelineno-0-671" name="__codelineno-0-671"></a><span class="sd">        feature_acts: Feature activations from encode()</span>
</span><span id="__span-0-672"><a id="__codelineno-0-672" name="__codelineno-0-672"></a><span class="sd">        **kwargs: Must contain 'original_x' - the original input tensor</span>
</span><span id="__span-0-673"><a id="__codelineno-0-673" name="__codelineno-0-673"></a>
</span><span id="__span-0-674"><a id="__codelineno-0-674" name="__codelineno-0-674"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-675"><a id="__codelineno-0-675" name="__codelineno-0-675"></a><span class="sd">        Reconstructed tensor in model space</span>
</span><span id="__span-0-676"><a id="__codelineno-0-676" name="__codelineno-0-676"></a><span class="sd">    """</span>
</span><span id="__span-0-677"><a id="__codelineno-0-677" name="__codelineno-0-677"></a>    <span class="k">assert</span> <span class="s2">"original_x"</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">,</span> <span class="s2">"MOLT decode requires 'original_x' in kwargs"</span>
</span><span id="__span-0-678"><a id="__codelineno-0-678" name="__codelineno-0-678"></a>
</span><span id="__span-0-679"><a id="__codelineno-0-679" name="__codelineno-0-679"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">"original_x"</span><span class="p">]</span>
</span><span id="__span-0-680"><a id="__codelineno-0-680" name="__codelineno-0-680"></a>
</span><span id="__span-0-681"><a id="__codelineno-0-681" name="__codelineno-0-681"></a>    <span class="c1"># Choose decoding strategy based on distributed setup</span>
</span><span id="__span-0-682"><a id="__codelineno-0-682" name="__codelineno-0-682"></a>    <span class="n">is_distributed</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
</span><span id="__span-0-683"><a id="__codelineno-0-683" name="__codelineno-0-683"></a>        <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">rank</span><span class="p">)],</span> <span class="n">DTensor</span><span class="p">)</span>
</span><span id="__span-0-684"><a id="__codelineno-0-684" name="__codelineno-0-684"></a>        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">available_ranks</span>
</span><span id="__span-0-685"><a id="__codelineno-0-685" name="__codelineno-0-685"></a>        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span>
</span><span id="__span-0-686"><a id="__codelineno-0-686" name="__codelineno-0-686"></a>    <span class="p">)</span>
</span><span id="__span-0-687"><a id="__codelineno-0-687" name="__codelineno-0-687"></a>
</span><span id="__span-0-688"><a id="__codelineno-0-688" name="__codelineno-0-688"></a>    <span class="k">if</span> <span class="n">is_distributed</span><span class="p">:</span>
</span><span id="__span-0-689"><a id="__codelineno-0-689" name="__codelineno-0-689"></a>        <span class="n">reconstruction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decode_distributed</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-690"><a id="__codelineno-0-690" name="__codelineno-0-690"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-691"><a id="__codelineno-0-691" name="__codelineno-0-691"></a>        <span class="n">reconstruction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decode_single_gpu</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-692"><a id="__codelineno-0-692" name="__codelineno-0-692"></a>
</span><span id="__span-0-693"><a id="__codelineno-0-693" name="__codelineno-0-693"></a>    <span class="k">return</span> <span class="n">reconstruction</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.MixtureOfLinearTransform.compute_training_metrics" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">compute_training_metrics</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_training_metrics</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="o">*</span><span class="p">,</span> <span class="n">l0</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n">feature_acts</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="float">float</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute per-rank group training metrics for MOLT.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span>
<span class="normal"><a href="#__codelineno-0-778">778</a></span>
<span class="normal"><a href="#__codelineno-0-779">779</a></span>
<span class="normal"><a href="#__codelineno-0-780">780</a></span>
<span class="normal"><a href="#__codelineno-0-781">781</a></span>
<span class="normal"><a href="#__codelineno-0-782">782</a></span>
<span class="normal"><a href="#__codelineno-0-783">783</a></span>
<span class="normal"><a href="#__codelineno-0-784">784</a></span>
<span class="normal"><a href="#__codelineno-0-785">785</a></span>
<span class="normal"><a href="#__codelineno-0-786">786</a></span>
<span class="normal"><a href="#__codelineno-0-787">787</a></span>
<span class="normal"><a href="#__codelineno-0-788">788</a></span>
<span class="normal"><a href="#__codelineno-0-789">789</a></span>
<span class="normal"><a href="#__codelineno-0-790">790</a></span>
<span class="normal"><a href="#__codelineno-0-791">791</a></span>
<span class="normal"><a href="#__codelineno-0-792">792</a></span>
<span class="normal"><a href="#__codelineno-0-793">793</a></span>
<span class="normal"><a href="#__codelineno-0-794">794</a></span>
<span class="normal"><a href="#__codelineno-0-795">795</a></span>
<span class="normal"><a href="#__codelineno-0-796">796</a></span>
<span class="normal"><a href="#__codelineno-0-797">797</a></span>
<span class="normal"><a href="#__codelineno-0-798">798</a></span>
<span class="normal"><a href="#__codelineno-0-799">799</a></span>
<span class="normal"><a href="#__codelineno-0-800">800</a></span>
<span class="normal"><a href="#__codelineno-0-801">801</a></span>
<span class="normal"><a href="#__codelineno-0-802">802</a></span>
<span class="normal"><a href="#__codelineno-0-803">803</a></span>
<span class="normal"><a href="#__codelineno-0-804">804</a></span>
<span class="normal"><a href="#__codelineno-0-805">805</a></span>
<span class="normal"><a href="#__codelineno-0-806">806</a></span>
<span class="normal"><a href="#__codelineno-0-807">807</a></span>
<span class="normal"><a href="#__codelineno-0-808">808</a></span>
<span class="normal"><a href="#__codelineno-0-809">809</a></span>
<span class="normal"><a href="#__codelineno-0-810">810</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-774"><a id="__codelineno-0-774" name="__codelineno-0-774"></a><span class="nd">@override</span>
</span><span id="__span-0-775"><a id="__codelineno-0-775" name="__codelineno-0-775"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</span><span id="__span-0-776"><a id="__codelineno-0-776" name="__codelineno-0-776"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_training_metrics</span><span class="p">(</span>
</span><span id="__span-0-777"><a id="__codelineno-0-777" name="__codelineno-0-777"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-778"><a id="__codelineno-0-778" name="__codelineno-0-778"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-779"><a id="__codelineno-0-779" name="__codelineno-0-779"></a>    <span class="n">l0</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-780"><a id="__codelineno-0-780" name="__codelineno-0-780"></a>    <span class="n">feature_acts</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-781"><a id="__codelineno-0-781" name="__codelineno-0-781"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-782"><a id="__codelineno-0-782" name="__codelineno-0-782"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-783"><a id="__codelineno-0-783" name="__codelineno-0-783"></a><span class="w">    </span><span class="sd">"""Compute per-rank group training metrics for MOLT."""</span>
</span><span id="__span-0-784"><a id="__codelineno-0-784" name="__codelineno-0-784"></a>    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="__span-0-785"><a id="__codelineno-0-785" name="__codelineno-0-785"></a>    <span class="n">feature_idx</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-786"><a id="__codelineno-0-786" name="__codelineno-0-786"></a>    <span class="n">total_rank_sum</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span id="__span-0-787"><a id="__codelineno-0-787" name="__codelineno-0-787"></a>
</span><span id="__span-0-788"><a id="__codelineno-0-788" name="__codelineno-0-788"></a>    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">available_ranks</span><span class="p">:</span>
</span><span id="__span-0-789"><a id="__codelineno-0-789" name="__codelineno-0-789"></a>        <span class="n">rank_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
</span><span id="__span-0-790"><a id="__codelineno-0-790" name="__codelineno-0-790"></a>        <span class="k">if</span> <span class="n">rank_str</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">U_matrices</span><span class="p">:</span>
</span><span id="__span-0-791"><a id="__codelineno-0-791" name="__codelineno-0-791"></a>            <span class="c1"># Extract features for this rank group</span>
</span><span id="__span-0-792"><a id="__codelineno-0-792" name="__codelineno-0-792"></a>            <span class="n">end_idx</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-793"><a id="__codelineno-0-793" name="__codelineno-0-793"></a>                <span class="n">feature_idx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">rank_counts</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
</span><span id="__span-0-794"><a id="__codelineno-0-794" name="__codelineno-0-794"></a>            <span class="p">)</span>  <span class="c1"># rank_counts[rank] is the GLOBAL count of this rank group</span>
</span><span id="__span-0-795"><a id="__codelineno-0-795" name="__codelineno-0-795"></a>            <span class="n">rank_features</span> <span class="o">=</span> <span class="n">feature_acts</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">feature_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
</span><span id="__span-0-796"><a id="__codelineno-0-796" name="__codelineno-0-796"></a>
</span><span id="__span-0-797"><a id="__codelineno-0-797" name="__codelineno-0-797"></a>            <span class="c1"># Count active transforms (l0) for this rank group</span>
</span><span id="__span-0-798"><a id="__codelineno-0-798" name="__codelineno-0-798"></a>            <span class="n">rank_l0</span> <span class="o">=</span> <span class="p">(</span><span class="n">rank_features</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-799"><a id="__codelineno-0-799" name="__codelineno-0-799"></a>            <span class="n">rank_l0_mean</span> <span class="o">=</span> <span class="n">item</span><span class="p">(</span><span class="n">rank_l0</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span><span id="__span-0-800"><a id="__codelineno-0-800" name="__codelineno-0-800"></a>
</span><span id="__span-0-801"><a id="__codelineno-0-801" name="__codelineno-0-801"></a>            <span class="c1"># Record metrics</span>
</span><span id="__span-0-802"><a id="__codelineno-0-802" name="__codelineno-0-802"></a>            <span class="n">metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">"molt_metrics/l0_rank</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_l0_mean</span>
</span><span id="__span-0-803"><a id="__codelineno-0-803" name="__codelineno-0-803"></a>            <span class="n">metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">"molt_metrics/l0_rank</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">_ratio"</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_l0_mean</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">rank_counts</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
</span><span id="__span-0-804"><a id="__codelineno-0-804" name="__codelineno-0-804"></a>            <span class="n">total_rank_sum</span> <span class="o">+=</span> <span class="n">rank_l0_mean</span> <span class="o">*</span> <span class="n">rank</span>
</span><span id="__span-0-805"><a id="__codelineno-0-805" name="__codelineno-0-805"></a>
</span><span id="__span-0-806"><a id="__codelineno-0-806" name="__codelineno-0-806"></a>            <span class="n">feature_idx</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">rank_counts</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
</span><span id="__span-0-807"><a id="__codelineno-0-807" name="__codelineno-0-807"></a>
</span><span id="__span-0-808"><a id="__codelineno-0-808" name="__codelineno-0-808"></a>    <span class="c1"># Record total rank sum</span>
</span><span id="__span-0-809"><a id="__codelineno-0-809" name="__codelineno-0-809"></a>    <span class="n">metrics</span><span class="p">[</span><span class="s2">"molt_metrics/total_rank_sum"</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_rank_sum</span>
</span><span id="__span-0-810"><a id="__codelineno-0-810" name="__codelineno-0-810"></a>    <span class="k">return</span> <span class="n">metrics</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="lm_saes.MixtureOfLinearTransform.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">encoder_kwargs</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">decoder_kwargs</span><span class="p">:</span> <span class="n"><span title="dict">dict</span></span><span class="p">[</span><span class="n"><span title="str">str</span></span><span class="p">,</span> <span class="n"><span title="typing.Any">Any</span></span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">]</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="o">|</span> <span class="n"><span title="jaxtyping.Float">Float</span></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Forward pass through the autoencoder.
Ensure that the input activations are normalized by calling <code>normalize_activations</code> before calling this method.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/lm_saes/molt.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-812">812</a></span>
<span class="normal"><a href="#__codelineno-0-813">813</a></span>
<span class="normal"><a href="#__codelineno-0-814">814</a></span>
<span class="normal"><a href="#__codelineno-0-815">815</a></span>
<span class="normal"><a href="#__codelineno-0-816">816</a></span>
<span class="normal"><a href="#__codelineno-0-817">817</a></span>
<span class="normal"><a href="#__codelineno-0-818">818</a></span>
<span class="normal"><a href="#__codelineno-0-819">819</a></span>
<span class="normal"><a href="#__codelineno-0-820">820</a></span>
<span class="normal"><a href="#__codelineno-0-821">821</a></span>
<span class="normal"><a href="#__codelineno-0-822">822</a></span>
<span class="normal"><a href="#__codelineno-0-823">823</a></span>
<span class="normal"><a href="#__codelineno-0-824">824</a></span>
<span class="normal"><a href="#__codelineno-0-825">825</a></span>
<span class="normal"><a href="#__codelineno-0-826">826</a></span>
<span class="normal"><a href="#__codelineno-0-827">827</a></span>
<span class="normal"><a href="#__codelineno-0-828">828</a></span>
<span class="normal"><a href="#__codelineno-0-829">829</a></span>
<span class="normal"><a href="#__codelineno-0-830">830</a></span>
<span class="normal"><a href="#__codelineno-0-831">831</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-812"><a id="__codelineno-0-812" name="__codelineno-0-812"></a><span class="nd">@override</span>
</span><span id="__span-0-813"><a id="__codelineno-0-813" name="__codelineno-0-813"></a><span class="nd">@timer</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="s2">"forward"</span><span class="p">)</span>
</span><span id="__span-0-814"><a id="__codelineno-0-814" name="__codelineno-0-814"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-815"><a id="__codelineno-0-815" name="__codelineno-0-815"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-816"><a id="__codelineno-0-816" name="__codelineno-0-816"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-817"><a id="__codelineno-0-817" name="__codelineno-0-817"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">],</span>
</span><span id="__span-0-818"><a id="__codelineno-0-818" name="__codelineno-0-818"></a>        <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-819"><a id="__codelineno-0-819" name="__codelineno-0-819"></a>    <span class="p">],</span>
</span><span id="__span-0-820"><a id="__codelineno-0-820" name="__codelineno-0-820"></a>    <span class="n">encoder_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
</span><span id="__span-0-821"><a id="__codelineno-0-821" name="__codelineno-0-821"></a>    <span class="n">decoder_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
</span><span id="__span-0-822"><a id="__codelineno-0-822" name="__codelineno-0-822"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-0-823"><a id="__codelineno-0-823" name="__codelineno-0-823"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch d_model"</span><span class="p">],</span>
</span><span id="__span-0-824"><a id="__codelineno-0-824" name="__codelineno-0-824"></a>    <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">"batch seq_len d_model"</span><span class="p">],</span>
</span><span id="__span-0-825"><a id="__codelineno-0-825" name="__codelineno-0-825"></a><span class="p">]:</span>
</span><span id="__span-0-826"><a id="__codelineno-0-826" name="__codelineno-0-826"></a><span class="w">    </span><span class="sd">"""Forward pass through the autoencoder.</span>
</span><span id="__span-0-827"><a id="__codelineno-0-827" name="__codelineno-0-827"></a><span class="sd">    Ensure that the input activations are normalized by calling `normalize_activations` before calling this method.</span>
</span><span id="__span-0-828"><a id="__codelineno-0-828" name="__codelineno-0-828"></a><span class="sd">    """</span>
</span><span id="__span-0-829"><a id="__codelineno-0-829" name="__codelineno-0-829"></a>    <span class="n">feature_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_kwargs</span><span class="p">)</span>
</span><span id="__span-0-830"><a id="__codelineno-0-830" name="__codelineno-0-830"></a>    <span class="n">reconstructed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">feature_acts</span><span class="p">,</span> <span class="n">original_x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-831"><a id="__codelineno-0-831" name="__codelineno-0-831"></a>    <span class="k">return</span> <span class="n">reconstructed</span>
</span></code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["content.code.copy", "content.footnote.tooltips"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>