# NEW HEADER
import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import io
from functools import lru_cache
from typing import Any, Optional, Tuple, List, Dict

import msgpack
import numpy as np
import plotly.graph_objects as go
import torch
from datasets import Dataset
from fastapi import FastAPI, Response, HTTPException, UploadFile, File, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
try:
    from torchvision import transforms
except ImportError:
    transforms = None
    print("WARNING: torchvision not found, image processing will be disabled")

from lm_saes.backend import LanguageModel
from lm_saes.config import MongoDBConfig, SAEConfig
from lm_saes.database import MongoClient
from lm_saes.resource_loaders import load_dataset_shard, load_model
from lm_saes.sae import SparseAutoEncoder
import subprocess
import json
import tempfile
import os
import time

import random
import chess

# æ·»åŠ HookedTransformerå¯¼å…¥
try:
    from transformer_lens import HookedTransformer
    HOOKED_TRANSFORMER_AVAILABLE = True
except ImportError:
    HookedTransformer = None
    HOOKED_TRANSFORMER_AVAILABLE = False
    print("WARNING: transformer_lens not found, HookedTransformer will not be available")

from lm_saes.lc0_mapping.lc0_mapping import (
    idx_to_uci_mappings,
    get_mapping_index,
)
from lm_saes.circuit.leela_board import LeelaBoard
from move_evaluation import evaluate_move_quality  # å¼•å…¥èµ°æ³•è¯„æµ‹

# å¯¼å…¥æˆ˜æœ¯ç‰¹å¾åˆ†æ
try:
    from tactic_features import analyze_tactic_features, validate_fens
    from lm_saes import LowRankSparseAttention
    TACTIC_FEATURES_AVAILABLE = True
except ImportError:
    analyze_tactic_features = None
    validate_fens = None
    LowRankSparseAttention = None
    TACTIC_FEATURES_AVAILABLE = False
    print("WARNING: tactic_features not found, tactic analysis will not be available")

device = "cuda" if torch.cuda.is_available() else "cpu"

app = FastAPI()

app.add_middleware(GZipMiddleware, minimum_size=1000)

client = MongoClient(MongoDBConfig())
sae_series = os.environ.get("SAE_SERIES", "default")
tokenizer_only = os.environ.get("TOKENIZER_ONLY", "false").lower() == "true"
if tokenizer_only:
    print("WARNING: Tokenizer only mode is enabled, some features may not be available")

# Remove global caches in favor of LRU cache
# sae_cache: dict[str, SparseAutoEncoder] = {}
# lm_cache: dict[str, LanguageModel] = {}
# dataset_cache: dict[tuple[str, int, int], Dataset] = {}


@lru_cache(maxsize=8)
def get_model(name: str) -> LanguageModel:
    """Load and cache a language model.

    Args:
        name: Name of the model to load

    Returns:
        LanguageModel: The loaded model

    Raises:
        ValueError: If the model is not found
    """
    cfg = client.get_model_cfg(name)
    if cfg is None:
        raise ValueError(f"Model {name} not found")
    cfg.tokenizer_only = tokenizer_only
    return load_model(cfg)


@lru_cache(maxsize=16)
def get_dataset(name: str, shard_idx: int = 0, n_shards: int = 1) -> Dataset:
    """Load and cache a dataset shard.

    Args:
        name: Name of the dataset
        shard_idx: Index of the shard to load
        n_shards: Total number of shards

    Returns:
        Dataset: The loaded dataset shard

    Raises:
        AssertionError: If the dataset is not found
    """
    cfg = client.get_dataset_cfg(name)
    assert cfg is not None, f"Dataset {name} not found"
    return load_dataset_shard(cfg, shard_idx, n_shards)


@lru_cache(maxsize=8)
def get_sae(name: str) -> SparseAutoEncoder:
    """Load and cache a sparse autoencoder.

    Args:
        name: Name of the SAE to load

    Returns:
        SparseAutoEncoder: The loaded SAE

    Raises:
        AssertionError: If the SAE is not found
    """
    path = client.get_sae_path(name, sae_series)
    assert path is not None, f"SAE {name} not found"
    cfg = SAEConfig.from_pretrained(path)
    sae = SparseAutoEncoder.from_config(cfg)
    sae.eval()
    return sae


# æ·»åŠ å…¨å±€æ¨¡å‹ç¼“å­˜ï¼ˆå…ˆåˆå§‹åŒ–æœ¬åœ°ç¼“å­˜ï¼Œcircuits_serviceå¯¼å…¥åä¼šæ›´æ–°ï¼‰
_hooked_models = {}
_transcoders_cache: Dict[str, Dict[int, SparseAutoEncoder]] = {}
_lorsas_cache: Dict[str, Any] = {}  # List[LowRankSparseAttention]ï¼Œä½¿ç”¨Anyé¿å…å¯¼å…¥é—®é¢˜
_replacement_models_cache: Dict[str, Any] = {}  # ReplacementModelç¼“å­˜

# æ·»åŠ å…¨å±€åŠ è½½æ—¥å¿—ç¼“å­˜ï¼ˆç”¨äºå‰ç«¯æ˜¾ç¤ºï¼‰
_loading_logs: Dict[str, list] = {}  # model_name -> [log1, log2, ...]

# æ·»åŠ å…¨å±€åŠ è½½çŠ¶æ€è·Ÿè¸ªï¼ˆç”¨äºé¿å…é‡å¤åŠ è½½ï¼‰
import threading
_loading_locks: Dict[str, threading.Lock] = {}  # model_name -> Lock
_loading_status: Dict[str, dict] = {}  # model_name -> {"is_loading": bool, "loading_task": asyncio.Task or None}

# æ·»åŠ å…¨å±€åŠ è½½çŠ¶æ€è·Ÿè¸ªï¼ˆç”¨äºé¿å…é‡å¤åŠ è½½ï¼‰
_loading_status: Dict[str, dict] = {}  # model_name -> {"is_loading": bool, "progress": {"tc": int, "lorsa": int}, "lock": threading.Lock}
import threading

def get_hooked_model(model_name: str = 'lc0/BT4-1024x15x32h'):
    """è·å–æˆ–åŠ è½½HookedTransformeræ¨¡å‹ - ä»…æ”¯æŒBT4ï¼ˆå¸¦å…¨å±€ç¼“å­˜ï¼‰"""
    global _hooked_models
    
    # å¼ºåˆ¶ä½¿ç”¨BT4æ¨¡å‹
    model_name = 'lc0/BT4-1024x15x32h'
    
    # å…ˆæ£€æŸ¥circuits_serviceçš„ç¼“å­˜
    if CIRCUITS_SERVICE_AVAILABLE and get_cached_models is not None:
        cached_hooked_model, _, _, _ = get_cached_models(model_name)
        if cached_hooked_model is not None:
            print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„HookedTransformeræ¨¡å‹: {model_name}")
            return cached_hooked_model
    
    # æ£€æŸ¥æœ¬åœ°ç¼“å­˜
    if model_name not in _hooked_models:
        if not HOOKED_TRANSFORMER_AVAILABLE:
            raise ValueError("HookedTransformerä¸å¯ç”¨ï¼Œè¯·å®‰è£…transformer_lens")
        
        print(f"ğŸ” æ­£åœ¨åŠ è½½HookedTransformeræ¨¡å‹: {model_name}")
        model = HookedTransformer.from_pretrained_no_processing(
            model_name,
            dtype=torch.float32,
        ).eval()
        _hooked_models[model_name] = model
        
        # å¦‚æœcircuits_serviceå¯ç”¨ï¼Œä¹Ÿæ›´æ–°å…±äº«ç¼“å­˜
        if CIRCUITS_SERVICE_AVAILABLE and set_cached_models is not None:
            # éœ€è¦transcoderså’Œlorsasæ‰èƒ½è°ƒç”¨set_cached_modelsï¼Œè¿™é‡Œåªç¼“å­˜æ¨¡å‹
            _global_hooked_models[model_name] = model
        
        print(f"âœ… HookedTransformeræ¨¡å‹ {model_name} åŠ è½½æˆåŠŸ")
    
    return _hooked_models[model_name]

def get_cached_transcoders_and_lorsas(model_name: str) -> Tuple[Optional[Dict[int, SparseAutoEncoder]], Optional[List[LowRankSparseAttention]]]:
    """è·å–ç¼“å­˜çš„transcoderså’Œlorsasï¼ˆä¼˜å…ˆä½¿ç”¨circuits_serviceçš„å…±äº«ç¼“å­˜ï¼‰"""
    # å…ˆæ£€æŸ¥circuits_serviceçš„ç¼“å­˜
    if CIRCUITS_SERVICE_AVAILABLE and get_cached_models is not None:
        _, cached_transcoders, cached_lorsas, _ = get_cached_models(model_name)
        if cached_transcoders is not None and cached_lorsas is not None:
            return cached_transcoders, cached_lorsas
    
    # æ£€æŸ¥æœ¬åœ°ç¼“å­˜
    global _transcoders_cache, _lorsas_cache
    return _transcoders_cache.get(model_name), _lorsas_cache.get(model_name)

def get_available_models():
    """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ - ä»…æ”¯æŒBT4"""
    return [
        {'name': 'lc0/BT4-1024x15x32h', 'display_name': 'BT4-1024x15x32h'},
    ]


def make_serializable(obj):
    if isinstance(obj, (torch.Tensor, np.ndarray)):
        return obj.tolist()
    if isinstance(obj, dict):
        return {k: make_serializable(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [make_serializable(v) for v in obj]
    return obj


def trim_minimum(
    origins: list[dict[str, Any] | None],
    feature_acts_indices: np.ndarray,
    feature_acts_values: np.ndarray,
) -> tuple[list[dict[str, Any] | None], np.ndarray, np.ndarray]:
    """Trim multiple arrays to the length of the shortest non-None array.

    Args:
        origins: Origins
        feature_acts_indices: Feature acts indices
        feature_acts_values: Feature acts values

    Returns:
        list: List of trimmed arrays
    """
    # æ£€æŸ¥æ˜¯å¦ä¸ºå›½é™…è±¡æ£‹æ¨¡å‹ï¼ˆé€šè¿‡æ£€æŸ¥originsä¸­æ˜¯å¦åŒ…å«FENæ•°æ®ï¼‰
    has_fen_data = any(
        origin is not None and origin.get("key") == "fen" 
        for origin in origins if origin is not None
    )

    if has_fen_data:
        # å¯¹äºå›½é™…è±¡æ£‹æ¨¡å‹ï¼Œå¼ºåˆ¶æœ€å°é•¿åº¦ä¸º64ï¼ˆæ£‹ç›˜æ ¼å­æ•°ï¼‰
        min_length = max(64, feature_acts_indices[-1] + 10)
    else:
        # å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
        min_length = min(len(origins), feature_acts_indices[-1] + 10)
    
    feature_acts_indices_mask = feature_acts_indices <= min_length
    return origins[:int(min_length)], feature_acts_indices[feature_acts_indices_mask], feature_acts_values[feature_acts_indices_mask]


@app.exception_handler(AssertionError)
async def assertion_error_handler(request, exc):
    return Response(content=str(exc), status_code=400)


@app.exception_handler(torch.cuda.OutOfMemoryError)
async def oom_error_handler(request, exc):
    print("CUDA Out of memory. Clearing cache.")
    # Clear LRU caches
    get_model.cache_clear()
    get_dataset.cache_clear()
    get_sae.cache_clear()
    return Response(content="CUDA Out of memory", status_code=500)


@app.get("/dictionaries")
def list_dictionaries():
    return client.list_saes(sae_series=sae_series, has_analyses=True)


@app.get("/images/{dataset_name}")
def get_image(dataset_name: str, context_idx: int, image_idx: int, shard_idx: int = 0, n_shards: int = 1):
    dataset = get_dataset(dataset_name, shard_idx, n_shards)
    data = dataset[int(context_idx)]

    image_key = next((key for key in ["image", "images"] if key in data), None)
    if image_key is None:
        return Response(content="Image not found", status_code=404)

    if len(data[image_key]) <= image_idx:
        return Response(content="Image not found", status_code=404)

    image_tensor = data[image_key][image_idx]

    # Convert tensor to PIL Image and then to bytes
    image = transforms.ToPILImage()(image_tensor.to(torch.uint8))
    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format="PNG")

    return Response(content=img_byte_arr.getvalue(), media_type="image/png")


@app.get("/dictionaries/{name}/features/{feature_index}")
def get_feature(
    name: str,
    feature_index: str | int,
    feature_analysis_name: str | None = None,
):
    # Parse feature_index if it's a string
    if isinstance(feature_index, str) and feature_index != "random":
        try:
            feature_index = int(feature_index)
        except ValueError:
            return Response(
                content=f"Feature index {feature_index} is not a valid integer",
                status_code=400,
            )
    print(f'{feature_analysis_name = }')
    print(f'{name = }')
    # Get feature data
    feature = (
        client.get_random_alive_feature(
            sae_name=name,
            sae_series=sae_series,
            name=feature_analysis_name,
        )
        if feature_index == "random"
        else client.get_feature(
            sae_name=name,
            sae_series=sae_series,
            index=feature_index)
    )

    if feature is None:
        return Response(
            content=f"Feature {feature_index} not found in SAE {name}",
            status_code=404,
        )

    analysis = next(
        (
            a for a in feature.analyses
            if a.name == feature_analysis_name or feature_analysis_name is None
        ),
        None,
    )
    print(f'{analysis = }')
    if analysis is None:
        return Response(
            content=f"Feature analysis {feature_analysis_name} not found in SAE {name}"
            if feature_analysis_name is not None
            else f"No feature analysis found in SAE {name}",
            status_code=404,
        )

    def process_sample(
        *,
        sparse_feature_acts,
        context_idx,
        dataset_name,
        model_name,
        shard_idx=None,
        n_shards=None,
    ):
        """Process a sample to extract and format feature data.

        Args:
            sparse_feature_acts: Sparse feature activations,
                optional z pattern activations
            decoder_norms: Decoder norms
            context_idx: Context index in the dataset
            dataset_name: Name of the dataset
            model_name: Name of the model
            shard_idx: Index of the dataset shard, defaults to 0
            n_shards: Total number of shards, defaults to 1

        Returns:
            dict: Processed sample data
        """
        model = get_model(model_name)
        
        data = get_dataset(dataset_name, shard_idx, n_shards)[context_idx.item()]

        # Get origins for the features
        origins = model.trace({k: [v] for k, v in data.items()})[0]

        # Process image data if present
        image_key = next(
            (key for key in ["image", "images"] if key in data),
            None,
        )
        if image_key is not None:
            image_urls = [
                f"/images/{dataset_name}?context_idx={context_idx}&"
                f"shard_idx={shard_idx}&n_shards={n_shards}&"
                f"image_idx={img_idx}"
                for img_idx in range(len(data[image_key]))
            ]
            del data[image_key]
            data["images"] = image_urls

        # Trim to matching lengths
        (
            feature_acts_indices,
            feature_acts_values,
            z_pattern_indices,
            z_pattern_values,
        ) = sparse_feature_acts

        origins, feature_acts_indices, feature_acts_values = trim_minimum(
            origins,
            feature_acts_indices,
            feature_acts_values,
        )
        assert (
            origins is not None
            and feature_acts_indices is not None
            and feature_acts_values is not None
        ), "Origins and feature acts must not be None"

        # æ£€æŸ¥æ˜¯å¦ä¸ºå›½é™…è±¡æ£‹æ¨¡å‹ï¼ˆå¤šç§æ£€æµ‹æ–¹å¼ï¼‰
        has_fen_data = any(
            origin is not None and origin.get("key") == "fen" 
            for origin in origins if origin is not None
        )
        
        # é€šè¿‡æ¨¡å‹åç§°æˆ–æ•°æ®é›†åç§°åˆ¤æ–­æ˜¯å¦ä¸ºæ£‹ç±»æ¨¡å‹
        is_chess_model = (
            has_fen_data or 
            "chess" in model_name.lower() or 
            "lc0" in model_name.lower() or
            "chess" in dataset_name.lower() or
            "lc0" in dataset_name.lower()
        )
        
        if is_chess_model:
            # å¯¹äºå›½é™…è±¡æ£‹æ¨¡å‹ï¼Œåˆ›å»ºé•¿åº¦ä¸º64çš„å¯†é›†æ¿€æ´»æ•°ç»„
            dense_feature_acts = np.zeros(64)
            
            # å¼ºåˆ¶ç±»å‹
            feature_acts_indices = np.asarray(feature_acts_indices, dtype=np.int64)
            feature_acts_values = np.asarray(feature_acts_values, dtype=np.float32)

            # å¯é€‰ï¼šè¿‡æ»¤éæ³•ç´¢å¼•
            valid_mask = (feature_acts_indices >= 0) & (feature_acts_indices < 64)
            feature_acts_indices = feature_acts_indices[valid_mask]
            feature_acts_values = feature_acts_values[valid_mask]

            # ç„¶åå† zip å¾ªç¯æˆ–ç›´æ¥å‘é‡åŒ–å†™å…¥
            for idx, val in zip(feature_acts_indices, feature_acts_values):
                        dense_feature_acts[idx] = val
            
            # ç¡®ä¿FENæ•°æ®å­˜åœ¨
            if "fen" not in data:
                # å¦‚æœæ²¡æœ‰FENæ•°æ®ï¼Œå°è¯•ä»originsä¸­æå–
                fen_origins = [origin for origin in origins if origin is not None and origin.get("key") == "fen"]
                if fen_origins:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªFEN originçš„èŒƒå›´æ¥æå–æ–‡æœ¬
                    fen_origin = fen_origins[0]
                    if "range" in fen_origin and "text" in data:
                        start, end = fen_origin["range"]
                        data["fen"] = data["text"][start:end]
                    else:
                        # å¦‚æœæ²¡æœ‰rangeä¿¡æ¯ï¼Œä½¿ç”¨æ•´ä¸ªæ–‡æœ¬
                        data["fen"] = data.get("text", "")
                else:
                    # å¦‚æœå®Œå…¨æ²¡æœ‰FENä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
                    data["fen"] = "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
            
        else:
            # å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            dense_feature_acts = np.zeros(len(origins))
            
            for i, (idx, val) in enumerate(zip(feature_acts_indices, feature_acts_values)):
                try:
                    # ç¡®ä¿idxæ˜¯æœ‰æ•ˆçš„æ•´æ•°
                    if hasattr(idx, 'item'):
                        idx = idx.item()
                    elif hasattr(idx, '__int__'):
                        idx = int(idx)
                    else:
                        idx = int(float(idx))
                    
                    # ç¡®ä¿valæ˜¯æœ‰æ•ˆçš„æ•°å€¼
                    if hasattr(val, 'item'):
                        val = val.item()
                    elif hasattr(val, '__float__'):
                        val = float(val)
                    else:
                        val = float(val)
                    
                    # æ£€æŸ¥ç´¢å¼•èŒƒå›´
                    if 0 <= idx < len(origins):
                        dense_feature_acts[idx] = val
                        
                except (ValueError, TypeError, IndexError):
                    continue

        # Process text data if present
        if "text" in data:
            text_ranges = [
                origin["range"] for origin in origins
                if origin is not None and origin["key"] == "text"
            ]
            if text_ranges:
                max_text_origin = max(text_ranges, key=lambda x: x[1])
                data["text"] = data["text"][: max_text_origin[1]]

        # å¯¹äºå›½é™…è±¡æ£‹æ¨¡å‹ï¼Œä½¿ç”¨FENä½œä¸ºæ–‡æœ¬
        if is_chess_model:
            data["text"] = data.get("fen", "No FEN data")

        return {
            **data,
            "origins": origins,
            "feature_acts": dense_feature_acts,  # è¿”å›å¯†é›†æ¿€æ´»æ•°ç»„
            "feature_acts_indices": feature_acts_indices,
            "feature_acts_values": feature_acts_values,
            "z_pattern_indices": z_pattern_indices,
            "z_pattern_values": z_pattern_values,
        }
    
    def process_sparse_feature_acts(
        feature_acts_indices: np.ndarray,
        feature_acts_values: np.ndarray,
        z_pattern_indices: np.ndarray | None = None,
        z_pattern_values: np.ndarray | None = None,
    ) -> list[tuple[np.ndarray, np.ndarray, np.ndarray | None, np.ndarray | None]]:
        """Process sparse feature acts.
        
        Args:
            feature_acts_indices: Feature acts indices
            feature_acts_values: Feature acts values
            z_pattern_indices: Z pattern indices
            z_pattern_values: Z pattern values
        
        TODO: This is really ugly, we should find a better way to do this.
        """

        if feature_acts_indices.size == 0 or feature_acts_indices.shape[1] == 0:
            return


        _, feature_acts_counts = np.unique(
            feature_acts_indices[0],
            return_counts=True,
        )

        _, z_pattern_counts = (
            np.unique(z_pattern_indices[0], return_counts=True)
            if z_pattern_indices is not None
            else (None, None)
        )

        feature_acts_sample_ranges = np.concatenate(
            [[0], np.cumsum(feature_acts_counts)]
        )

        z_pattern_sample_ranges = (
            np.concatenate([[0], np.cumsum(z_pattern_counts)])
            if z_pattern_counts is not None
            else None
        )

        feature_acts_sample_ranges = list(
            zip(feature_acts_sample_ranges[:-1], feature_acts_sample_ranges[1:])
        )

        if z_pattern_sample_ranges is not None:
            z_pattern_sample_ranges = list(
                zip(z_pattern_sample_ranges[:-1], z_pattern_sample_ranges[1:])
            )
            if len(feature_acts_sample_ranges) != len(z_pattern_sample_ranges):
                z_pattern_sample_ranges = [(None, None)] * len(feature_acts_sample_ranges)
        else:
            z_pattern_sample_ranges = [(None, None)] * len(feature_acts_sample_ranges)

        for (feature_acts_start, feature_acts_end), (z_pattern_start, z_pattern_end) in zip(feature_acts_sample_ranges, z_pattern_sample_ranges):
            feature_acts_indices_i = feature_acts_indices[1, feature_acts_start:feature_acts_end]
            feature_acts_values_i = feature_acts_values[feature_acts_start:feature_acts_end]
            z_pattern_indices_i = z_pattern_indices[1:, z_pattern_start:z_pattern_end] if z_pattern_indices is not None else None
            z_pattern_values_i = z_pattern_values[z_pattern_start:z_pattern_end] if z_pattern_values is not None else None

            yield feature_acts_indices_i, feature_acts_values_i, z_pattern_indices_i, z_pattern_values_i


    sample_groups = []
    for sampling in analysis.samplings:
        try:
            # Using zip to process correlated data instead of indexing
            samples = [
                process_sample(
                    sparse_feature_acts=sparse_feature_acts,
                    context_idx=context_idx,
                    dataset_name=dataset_name,
                    model_name=model_name,
                    shard_idx=shard_idx,
                    n_shards=n_shards,
                )
                for sparse_feature_acts, context_idx, dataset_name, model_name, shard_idx, n_shards in zip(
                    process_sparse_feature_acts(
                        sampling.feature_acts_indices,
                        sampling.feature_acts_values,
                        sampling.z_pattern_indices,
                        sampling.z_pattern_values,
                    ),
                    sampling.context_idx,
                    sampling.dataset_name,
                    sampling.model_name,
                    sampling.shard_idx if sampling.shard_idx is not None else [0] * len(sampling.feature_acts_indices),
                    sampling.n_shards if sampling.n_shards is not None else [1] * len(sampling.feature_acts_indices),
                )
            ]
            

            sample_groups.append(
                {
                    "analysis_name": sampling.name,
                    "samples": samples,
                }
            )
        except Exception as e:
            # è¿”å›400é”™è¯¯å“åº”
            return Response(
                content=f"å¤„ç†sampling '{sampling.name}' æ—¶å‡ºé”™: {str(e)}", 
                status_code=400
            )

    # Prepare response
    response_data = {
        "feature_index": feature.index,
        "analysis_name": analysis.name,
        "interpretation": feature.interpretation,
        "dictionary_name": feature.sae_name,
        "decoder_norms": analysis.decoder_norms,
        "decoder_similarity_matrices": analysis.decoder_similarity_matrices,
        "decoder_inner_product_matrices": analysis.decoder_inner_product_matrices,
        "act_times": analysis.act_times,
        "max_feature_act": analysis.max_feature_acts,
        "n_analyzed_tokens": analysis.n_analyzed_tokens,
        "sample_groups": sample_groups,
        "is_bookmarked": client.is_bookmarked(sae_name=name, sae_series=sae_series, feature_index=feature.index),
    }

    return Response(
        content=msgpack.packb(make_serializable(response_data)),
        media_type="application/x-msgpack",
    )


@app.get("/dictionaries/{name}")
def get_dictionary(name: str):
    # Get feature activation times
    feature_activation_times = client.get_feature_act_times(name, sae_series=sae_series)
    if feature_activation_times is None:
        return Response(content=f"Dictionary {name} not found", status_code=404)

    # Create histogram of log activation times
    log_act_times = np.log10(np.array(list(feature_activation_times.values())))
    feature_activation_times_histogram = go.Histogram(
        x=log_act_times,
        nbinsx=100,
        hovertemplate="Count: %{y}<br>Range: %{x}<extra></extra>",
        marker_color="#636EFA",
        showlegend=False,
    ).to_plotly_json()

    # Get alive feature count
    alive_feature_count = client.get_alive_feature_count(name, sae_series=sae_series)
    if alive_feature_count is None:
        return Response(content=f"SAE {name} not found", status_code=404)

    # Prepare and return response
    response_data = {
        "dictionary_name": name,
        "feature_activation_times_histogram": [feature_activation_times_histogram],
        "alive_feature_count": alive_feature_count,
    }

    return Response(
        content=msgpack.packb(make_serializable(response_data)),
        media_type="application/x-msgpack",
    )


@app.get("/dictionaries/{name}/analyses")
def get_analyses(name: str):
    """Get all available analyses for a dictionary.

    Args:
        name: Name of the dictionary/SAE

    Returns:
        List of analysis names
    """
    # Get a random feature to check its available analyses
    feature = client.get_random_alive_feature(sae_name=name, sae_series=sae_series)
    if feature is None:
        return Response(content=f"Dictionary {name} not found", status_code=404)

    # Extract unique analysis names from feature
    analyses = list(set(analysis.name for analysis in feature.analyses))
    return analyses


@app.post("/dictionaries/{name}/features/{feature_index}/bookmark")
def add_bookmark(name: str, feature_index: int):
    """Add a bookmark for a feature.

    Args:
        name: Name of the dictionary/SAE
        feature_index: Index of the feature to bookmark

    Returns:
        Success response or error
    """
    try:
        success = client.add_bookmark(sae_name=name, sae_series=sae_series, feature_index=feature_index)
        if success:
            return {"message": "Bookmark added successfully"}
        else:
            return Response(content="Feature is already bookmarked", status_code=409)
    except ValueError as e:
        return Response(content=str(e), status_code=404)


@app.delete("/dictionaries/{name}/features/{feature_index}/bookmark")
def remove_bookmark(name: str, feature_index: int):
    """Remove a bookmark for a feature.

    Args:
        name: Name of the dictionary/SAE
        feature_index: Index of the feature to remove bookmark from

    Returns:
        Success response or error
    """
    success = client.remove_bookmark(sae_name=name, sae_series=sae_series, feature_index=feature_index)
    if success:
        return {"message": "Bookmark removed successfully"}
    else:
        return Response(content="Bookmark not found", status_code=404)


@app.get("/dictionaries/{name}/features/{feature_index}/bookmark")
def check_bookmark(name: str, feature_index: int):
    """Check if a feature is bookmarked.

    Args:
        name: Name of the dictionary/SAE
        feature_index: Index of the feature

    Returns:
        Bookmark status
    """
    is_bookmarked = client.is_bookmarked(sae_name=name, sae_series=sae_series, feature_index=feature_index)
    return {"is_bookmarked": is_bookmarked}


@app.get("/bookmarks")
def list_bookmarks(sae_name: Optional[str] = None, sae_series: Optional[str] = None, limit: int = 100, skip: int = 0):
    """List bookmarks with optional filtering.

    Args:
        sae_name: Optional SAE name filter
        sae_series: Optional SAE series filter
        limit: Maximum number of bookmarks to return
        skip: Number of bookmarks to skip (for pagination)

    Returns:
        List of bookmarks
    """
    bookmarks = client.list_bookmarks(sae_name=sae_name, sae_series=sae_series, limit=limit, skip=skip)

    # Convert to dict for JSON serialization
    bookmark_data = []
    for bookmark in bookmarks:
        bookmark_dict = bookmark.model_dump()
        # Convert datetime to ISO string for JSON
        bookmark_dict["created_at"] = bookmark.created_at.isoformat()
        bookmark_data.append(bookmark_dict)

    return {
        "bookmarks": bookmark_data,
        "total_count": client.get_bookmark_count(sae_name=sae_name, sae_series=sae_series),
    }


@app.post("/circuit/sync_clerps_to_interpretations")
def sync_clerps_to_interpretations(request: dict):

    try:
        nodes = request.get("nodes", [])
        lorsa_analysis_name = request.get("lorsa_analysis_name")
        tc_analysis_name = request.get("tc_analysis_name")
        
        if not isinstance(nodes, list):
            raise HTTPException(status_code=400, detail="nodes must be a list")
        
        print(f"ğŸ”„ å¼€å§‹åŒæ­¥clerpsåˆ°interpretations:")
        print(f"   - èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
        print(f"   - LoRSAæ¨¡æ¿: {lorsa_analysis_name}")
        print(f"   - TCæ¨¡æ¿: {tc_analysis_name}")
        
        synced_count = 0
        skipped_count = 0
        error_count = 0
        results = []
        
        for node in nodes:
            node_id = node.get('node_id')
            clerp = node.get('clerp')
            feature_idx = node.get('feature')
            layer = node.get('layer')
            feature_type = node.get('feature_type', '').lower()
            
            # è·³è¿‡æ²¡æœ‰clerpæˆ–clerpä¸ºç©ºçš„èŠ‚ç‚¹
            if not clerp or not isinstance(clerp, str) or clerp.strip() == '':
                skipped_count += 1
                continue
            
            # æ„å»ºSAEåç§°
            sae_name = None
            if 'lorsa' in feature_type:
                if lorsa_analysis_name:
                    sae_name = lorsa_analysis_name.replace("{}", str(layer))
                else:
                    sae_name = f"BT4_lorsa_L{layer}A"
            elif 'transcoder' in feature_type or 'cross layer transcoder' in feature_type:
                if tc_analysis_name:
                    sae_name = tc_analysis_name.replace("{}", str(layer))
                else:
                    sae_name = f"BT4_tc_L{layer}M"
            
            if not sae_name or feature_idx is None:
                skipped_count += 1
                continue
            
            try:
                # è§£ç clerpï¼ˆå¦‚æœæ˜¯URLç¼–ç çš„ï¼‰
                import urllib.parse
                decoded_clerp = urllib.parse.unquote(clerp)
                
                # åˆ›å»ºinterpretationå­—å…¸
                interpretation_dict = {
                    "text": decoded_clerp,
                    "method": "circuit_clerp",
                    "validation": []
                }
                
                # ä¿å­˜åˆ°MongoDB
                client.update_feature(
                    sae_name=sae_name,
                    sae_series=sae_series,
                    feature_index=feature_idx,
                    update_data={"interpretation": interpretation_dict}
                )
                
                synced_count += 1
                results.append({
                    "node_id": node_id,
                    "sae_name": sae_name,
                    "feature_index": feature_idx,
                    "status": "synced"
                })
                
                print(f"âœ… å·²åŒæ­¥èŠ‚ç‚¹ {node_id}: {sae_name}[{feature_idx}]")
                
            except Exception as e:
                error_count += 1
                results.append({
                    "node_id": node_id,
                    "sae_name": sae_name,
                    "feature_index": feature_idx,
                    "status": "error",
                    "error": str(e)
                })
                print(f"âŒ åŒæ­¥èŠ‚ç‚¹ {node_id} å¤±è´¥: {e}")
        
        summary = {
            "total_nodes": len(nodes),
            "synced": synced_count,
            "skipped": skipped_count,
            "errors": error_count,
            "results": results[:50]  # åªè¿”å›å‰50ä¸ªè¯¦ç»†ç»“æœ
        }
        
        print(f"âœ… åŒæ­¥å®Œæˆ: {synced_count} æˆåŠŸ, {skipped_count} è·³è¿‡, {error_count} å¤±è´¥")
        
        return summary
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åŒæ­¥å¤±è´¥: {str(e)}")


@app.post("/circuit/sync_interpretations_to_clerps")
def sync_interpretations_to_clerps(request: dict):
    try:
        nodes = request.get("nodes", [])
        lorsa_analysis_name = request.get("lorsa_analysis_name")
        tc_analysis_name = request.get("tc_analysis_name")
        
        if not isinstance(nodes, list):
            raise HTTPException(status_code=400, detail="nodes must be a list")
        
        print(f"ğŸ”„ å¼€å§‹ä»interpretationsåŒæ­¥åˆ°clerps:")
        print(f"   - èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
        print(f"   - LoRSAæ¨¡æ¿: {lorsa_analysis_name}")
        print(f"   - TCæ¨¡æ¿: {tc_analysis_name}")
        
        updated_nodes = []
        found_count = 0
        not_found_count = 0
        
        for node in nodes:
            node_id = node.get('node_id')
            feature_idx = node.get('feature')
            layer = node.get('layer')
            feature_type = node.get('feature_type', '').lower()
            
            # æ„å»ºSAEåç§°
            sae_name = None
            if 'lorsa' in feature_type:
                if lorsa_analysis_name:
                    sae_name = lorsa_analysis_name.replace("{}", str(layer))
                else:
                    sae_name = f"BT4_lorsa_L{layer}A"
            elif 'transcoder' in feature_type or 'cross layer transcoder' in feature_type:
                if tc_analysis_name:
                    sae_name = tc_analysis_name.replace("{}", str(layer))
                else:
                    sae_name = f"BT4_tc_L{layer}M"
            
            updated_node = {**node}  # å¤åˆ¶åŸèŠ‚ç‚¹æ•°æ®
            
            if sae_name and feature_idx is not None:
                try:
                    # ä»MongoDBè¯»å–feature
                    feature = client.get_feature(
                        sae_name=sae_name,
                        sae_series=sae_series,
                        index=feature_idx
                    )
                    
                    if feature and feature.interpretation:
                        interp = feature.interpretation
                        if isinstance(interp, dict):
                            clerp_text = interp.get("text", "")
                        else:
                            clerp_text = getattr(interp, "text", "")
                        
                        if clerp_text:
                            updated_node["clerp"] = clerp_text
                            found_count += 1
                            print(f"âœ… æ‰¾åˆ°èŠ‚ç‚¹ {node_id} çš„interpretation: {sae_name}[{feature_idx}]")
                        else:
                            not_found_count += 1
                    else:
                        not_found_count += 1
                        
                except Exception as e:
                    print(f"âš ï¸ è¯»å–èŠ‚ç‚¹ {node_id} çš„interpretationå¤±è´¥: {e}")
                    not_found_count += 1
            else:
                not_found_count += 1
            
            updated_nodes.append(updated_node)
        
        summary = {
            "total_nodes": len(nodes),
            "found": found_count,
            "not_found": not_found_count,
            "updated_nodes": updated_nodes
        }
        
        print(f"âœ… åŒæ­¥å®Œæˆ: {found_count} æ‰¾åˆ°, {not_found_count} æœªæ‰¾åˆ°")
        
        return summary
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åŒæ­¥å¤±è´¥: {str(e)}")


@app.post("/dictionaries/{name}/features/{feature_index}/interpret")
def interpret_feature(
    name: str,
    feature_index: int,
    type: str,
    custom_interpretation: Optional[str] = None
):
    """
    å¤„ç†ç‰¹å¾è§£é‡Šï¼šè‡ªåŠ¨ç”Ÿæˆã€è‡ªå®šä¹‰ä¿å­˜æˆ–éªŒè¯
    
    Args:
        name: SAEåç§°
        feature_index: ç‰¹å¾ç´¢å¼•
        type: è§£é‡Šç±»å‹ (auto/custom/validate)
        custom_interpretation: è‡ªå®šä¹‰è§£é‡Šæ–‡æœ¬ï¼ˆtype=customæ—¶éœ€è¦ï¼‰
    
    Returns:
        Interpretationå¯¹è±¡ï¼ˆå­—å…¸æ ¼å¼ï¼‰
    """
    try:
        # è·å–ç‰¹å¾
        feature = client.get_feature(
            sae_name=name,
            sae_series=sae_series,
            index=feature_index
        )
        
        if feature is None:
            raise HTTPException(
                status_code=404,
                detail=f"Feature {feature_index} not found in SAE {name}"
            )
        
        if type == "custom":
            # ä¿å­˜è‡ªå®šä¹‰è§£é‡Š
            if not custom_interpretation:
                raise HTTPException(
                    status_code=400,
                    detail="custom_interpretation is required for type=custom"
                )
            
            # FastAPIåº”è¯¥å·²ç»è‡ªåŠ¨è§£ç äº†URLç¼–ç çš„å‚æ•°
            # å¦‚æœä»æœ‰é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ urllib.parse.unquote è§£ç 
            import urllib.parse
            decoded_interpretation = urllib.parse.unquote(custom_interpretation)
            
            print(f"ğŸ“ æ”¶åˆ°è§£é‡Šæ–‡æœ¬:")
            print(f"   - åŸå§‹: {custom_interpretation}")
            print(f"   - è§£ç : {decoded_interpretation}")
            
            # åˆ›å»ºè§£é‡Šå­—å…¸ï¼ˆåªåŒ…å«å¿…éœ€å­—æ®µï¼Œå…¶ä»–å­—æ®µä¸è¿”å›ä»¥ç¬¦åˆå‰ç«¯schemaçš„optionalå®šä¹‰ï¼‰
            interpretation_dict = {
                "text": decoded_interpretation,
                "method": "custom",
                "validation": []
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            try:
                client.update_feature(
                    sae_name=name,
                    sae_series=sae_series,
                    feature_index=feature_index,
                    update_data={"interpretation": interpretation_dict}
                )
            except Exception as update_error:
                print(f"Failed to update feature interpretation: {update_error}")
                raise HTTPException(
                    status_code=500,
                    detail=f"Failed to save interpretation: {str(update_error)}"
                )
            
            return interpretation_dict
        
        elif type == "auto":
            raise HTTPException(
                status_code=501,
                detail="Automatic interpretation is not yet implemented. Please use custom interpretation."
            )
        
        elif type == "validate":
            if not feature.interpretation:
                raise HTTPException(
                    status_code=400,
                    detail="No interpretation available to validate"
                )
            
            interp = feature.interpretation
            print(f"ğŸ“– è¯»å–è§£é‡Šæ–‡æœ¬: {interp.get('text', '') if isinstance(interp, dict) else getattr(interp, 'text', '')}")
            
            if isinstance(interp, dict):
                result = {
                    "text": interp.get("text", ""),
                    "method": interp.get("method", "unknown"),
                    "validation": interp.get("validation", [])
                }
                if interp.get("passed") is not None:
                    result["passed"] = interp.get("passed")
                if interp.get("complexity") is not None:
                    result["complexity"] = interp.get("complexity")
                if interp.get("consistency") is not None:
                    result["consistency"] = interp.get("consistency")
                return result
            else:
                # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•è®¿é—®å±æ€§
                result = {
                    "text": getattr(interp, "text", ""),
                    "method": getattr(interp, "method", "unknown"),
                    "validation": getattr(interp, "validation", [])
                }
                # åªæœ‰å½“å€¼ä¸æ˜¯Noneæ—¶æ‰æ·»åŠ å¯é€‰å­—æ®µ
                passed = getattr(interp, "passed", None)
                if passed is not None:
                    result["passed"] = passed
                complexity = getattr(interp, "complexity", None)
                if complexity is not None:
                    result["complexity"] = complexity
                consistency = getattr(interp, "consistency", None)
                if consistency is not None:
                    result["consistency"] = consistency
                return result
        
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid type: {type}. Must be 'auto', 'custom', or 'validate'"
            )
    
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Failed to process interpretation: {str(e)}"
        )


@app.put("/dictionaries/{name}/features/{feature_index}/bookmark")
def update_bookmark(name: str, feature_index: int, tags: Optional[list[str]] = None, notes: Optional[str] = None):
    """Update a bookmark with new tags or notes.

    Args:
        name: Name of the dictionary/SAE
        feature_index: Index of the feature
        tags: Optional new tags for the bookmark
        notes: Optional new notes for the bookmark

    Returns:
        Success response or error
    """
    success = client.update_bookmark(
        sae_name=name, sae_series=sae_series, feature_index=feature_index, tags=tags, notes=notes
    )
    if success:
        return {"message": "Bookmark updated successfully"}
    else:
        return Response(content="Bookmark not found", status_code=404)


# LC0 å¼•æ“ç±»
class LC0Engine:
    def __init__(self, model):
        self.model = model
        self.model.eval()

    def play(self, chess_board):
        try:
            # ä½¿ç”¨ notebook åŒæ¬¾æ¥å£è¿›è¡Œæ¨ç†
            fen = chess_board.fen()
            print(f"ğŸ” å¤„ç†FEN: {fen}")

            # åˆ›å»º LeelaBoard å®ä¾‹æ¥å¤„ç†æ˜ å°„
            lboard = LeelaBoard.from_fen(fen, history_synthesis=True)
            lboard.pc_board = chess_board  # ä½¿ç”¨ç°æœ‰çš„æ£‹ç›˜çŠ¶æ€

            with torch.no_grad():
                output, cache = self.model.run_with_cache(fen, prepend_bos=False)
                if isinstance(output, (list, tuple)) and len(output) >= 1:
                    policy_output = output[0]
                else:
                    policy_output = output
                if policy_output.dim() == 2:
                    policy_logits = policy_output[0]
                else:
                    policy_logits = policy_output

            legal_moves = list(chess_board.legal_moves)
            legal_uci_set = set(move.uci() for move in legal_moves)
            sorted_indices = torch.argsort(policy_logits, descending=True)

            top10 = []
            for idx in sorted_indices[:10].tolist():
                uci = lboard.idx2uci(idx)
                logit = float(policy_logits[idx].item())
                top10.append((uci, logit))
            
            print("ğŸ” æ¨¡å‹è¾“å‡ºè°ƒè¯•ä¿¡æ¯:")
            print(f"   - policy_logits shape: {tuple(policy_logits.shape)}")
            print(f"   - åˆæ³•ç§»åŠ¨æ•°é‡: {len(legal_moves)}")
            print("   - å‰10ä¸ªæœ€é«˜æ¦‚ç‡move (uci, logit):")
            print("     " + ", ".join([f"{uci}:{logit:.4f}" for uci, logit in top10]))

            # ä¾æ¬¡å°è¯•æœ€é«˜æ¦‚ç‡ç´¢å¼•å¯¹åº”çš„ UCIï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªåˆæ³•ç§»åŠ¨
            for rank, idx in enumerate(sorted_indices.tolist(), start=1):
                uci = lboard.idx2uci(idx)
                if uci in legal_uci_set:
                    move = chess.Move.from_uci(uci)
                    print(f"âœ… é€‰æ‹©æœ€å¤§æ¦‚ç‡åˆæ³•ç§»åŠ¨: {uci} (æ¦‚ç‡æ’å: {rank}, logit: {policy_logits[idx].item():.4f})")
                    return move

            # å¦‚æœæœªæ‰¾åˆ°åˆæ³•ç§»åŠ¨ï¼Œæ‰“å°æŠ¥é”™å¹¶æŠ›å¼‚å¸¸
            print("âŒ é”™è¯¯ï¼šæ¨¡å‹æœªèƒ½æ‰¾åˆ°ä»»ä½•åˆæ³•ç§»åŠ¨ï¼")
            print(f"   - å½“å‰å±€é¢ FEN: {fen}")
            print(f"   - ç¤ºä¾‹åˆæ³•ç§»åŠ¨: {[m.uci() for m in legal_moves[:10]]}")
            print(f"   - å°è¯•äº†å‰ {min(len(sorted_indices), 50)} ä¸ªæœ€é«˜æ¦‚ç‡çš„token")
            raise ValueError("æ¨¡å‹æœªèƒ½æ‰¾åˆ°ä»»ä½•åˆæ³•ç§»åŠ¨")

        except Exception as e:
            print(f"âŒ LC0Engine.play() å‡ºé”™: {e}")
            raise e


@app.post("/play_game")
def play_game(request: dict):
    """
    ä¸æ¨¡å‹å¯¹æˆ˜ï¼šè¾“å…¥å½“å‰å±€é¢ FENï¼Œè¿”å›æ¨¡å‹å»ºè®®çš„ä¸‹ä¸€æ­¥ç§»åŠ¨ (UCI æ ¼å¼)
    """
    fen = request.get("fen")
    # å¼ºåˆ¶ä½¿ç”¨BT4æ¨¡å‹
    model_name = "lc0/BT4-1024x15x32h"
    
    if not fen:
        raise HTTPException(status_code=400, detail="FEN å­—ç¬¦ä¸²ä¸èƒ½ä¸ºç©º")
    
    try:
        board = chess.Board(fen)
    except Exception as e:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ FEN å­—ç¬¦ä¸²")
    
    try:
        # æ£€æŸ¥HookedTransformeræ˜¯å¦å¯ç”¨
        if not HOOKED_TRANSFORMER_AVAILABLE:
            print("âŒ é”™è¯¯ï¼šHookedTransformerä¸å¯ç”¨")
            raise HTTPException(status_code=503, detail="HookedTransformerä¸å¯ç”¨ï¼Œè¯·å®‰è£…transformer_lens")
        
        # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
        model = get_hooked_model(model_name)
        
        # åˆ›å»ºå¼•æ“å¹¶è·å–ç§»åŠ¨ï¼ˆä¸åšéšæœºå›é€€ï¼‰
        engine = LC0Engine(model)
        move = engine.play(board)
        return {"move": move.uci(), "model_used": model_name}
        
    except ValueError as e:
        print(f"âŒ æ¨¡å‹æ‰¾ä¸åˆ°åˆæ³•ç§»åŠ¨: {e}")
        raise HTTPException(status_code=400, detail=f"æ¨¡å‹æ‰¾ä¸åˆ°åˆæ³•ç§»åŠ¨: {str(e)}")
    except Exception as e:
        print(f"âŒ å¤„ç†ç§»åŠ¨æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†ç§»åŠ¨æ—¶å‡ºé”™: {str(e)}")


# åœ¨play_gameæ¥å£åæ·»åŠ å±€é¢åˆ†ææ¥å£
@app.post("/analyze/board")
def analyze_board(request: dict):
    """ä½¿ç”¨HookedTransformeræ¨¡å‹åˆ†æå½“å‰å±€é¢ï¼Œå¹¶è¿”å›è¡Œæ£‹æ–¹èƒœç‡ã€å’Œæ£‹ç‡åŠå¯¹æ–¹èƒœç‡"""
    fen = request.get("fen")
    # å¼ºåˆ¶ä½¿ç”¨BT4æ¨¡å‹
    model_name = "lc0/BT4-1024x15x32h"
    
    if not fen:
        raise HTTPException(status_code=400, detail="FENå­—ç¬¦ä¸²ä¸èƒ½ä¸ºç©º")
    try:
        if not HOOKED_TRANSFORMER_AVAILABLE:
            raise HTTPException(status_code=503, detail="HookedTransformerä¸å¯ç”¨ï¼Œè¯·å®‰è£…transformer_lens")
        
        # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
        model = get_hooked_model(model_name)
        
        with torch.no_grad():
            output, _ = model.run_with_cache(fen, prepend_bos=False)
        
        # æ¨¡å‹è¾“å‡ºæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«ä¸‰ä¸ªå…ƒç´ ï¼š
        # output[0]: logits, shape [1, 1858]
        # output[1]: WDL, shape [1, 3] - [å½“å‰è¡Œæ£‹æ–¹èƒœç‡, å’Œæ£‹ç‡, å½“å‰è¡Œæ£‹æ–¹è´¥ç‡]
        # output[2]: å…¶ä»–è¾“å‡º, shape [1, 1]
        
        if isinstance(output, (list, tuple)) and len(output) >= 2:
            wdl_tensor = output[1]  # è·å–WDLè¾“å‡º
            if wdl_tensor.shape == torch.Size([1, 3]):
                # WDLå·²ç»æ˜¯æ¦‚ç‡åˆ†å¸ƒï¼Œä¸éœ€è¦softmax
                current_player_win = wdl_tensor[0][0].item()  # å½“å‰è¡Œæ£‹æ–¹èƒœç‡
                draw_prob = wdl_tensor[0][1].item()  # å’Œæ£‹ç‡
                current_player_loss = wdl_tensor[0][2].item()  # å½“å‰è¡Œæ£‹æ–¹è´¥ç‡
                
                # ç›´æ¥è¿”å›å½“å‰è¡Œæ£‹æ–¹çš„èƒœç‡ä¿¡æ¯ï¼Œä¸è¿›è¡Œç¿»è½¬
                # [å½“å‰è¡Œæ£‹æ–¹èƒœç‡, å’Œæ£‹ç‡, å¯¹æ–¹èƒœç‡]
                evaluation = [current_player_win, draw_prob, current_player_loss]
            else:
                print(f"WDLè¾“å‡ºå½¢çŠ¶ä¸æ­£ç¡®: {wdl_tensor.shape}, æœŸæœ› [1, 3]")
                evaluation = [0.5, 0.2, 0.3]
        else:
            print(f"æ¨¡å‹è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®ï¼ŒæœŸæœ›åŒ…å«è‡³å°‘2ä¸ªå…ƒç´ çš„åˆ—è¡¨ï¼Œå®é™…å¾—åˆ°: {type(output)}")
            evaluation = [0.5, 0.2, 0.3]
        
        return {"evaluation": evaluation, "model_used": model_name}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å±€é¢åˆ†æå‡ºé”™: {str(e)}")


@app.get("/models")
def get_models():
    """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    return {"models": get_available_models()}


# å¯¼å…¥circuits_service
try:
    from circuits_service import (
        run_circuit_trace, 
        check_dense_features, 
        load_model_and_transcoders,
        get_cached_models,
        set_cached_models,
        _global_hooked_models,
        _global_transcoders_cache,
        _global_lorsas_cache,
        _global_replacement_models_cache
    )
    from lm_saes.circuit.replacement_lc0_model import ReplacementModel
    CIRCUITS_SERVICE_AVAILABLE = True
    # å¦‚æœcircuits_serviceå¯ç”¨ï¼Œå°†æœ¬åœ°ç¼“å­˜æŒ‡å‘å…±äº«ç¼“å­˜
    _hooked_models = _global_hooked_models
    _transcoders_cache = _global_transcoders_cache
    _lorsas_cache = _global_lorsas_cache
    _replacement_models_cache = _global_replacement_models_cache
except ImportError as e:
    run_circuit_trace = None
    check_dense_features = None
    load_model_and_transcoders = None
    get_cached_models = None
    set_cached_models = None
    _global_hooked_models = {}
    _global_transcoders_cache = {}
    _global_lorsas_cache = {}
    _global_replacement_models_cache = {}
    ReplacementModel = None
    CIRCUITS_SERVICE_AVAILABLE = False
    print(f"WARNING: circuits_service not found, circuit tracing will not be available: {e}")

# å¯¼å…¥patchingæœåŠ¡
try:
    from patching import run_patching_analysis
    PATCHING_SERVICE_AVAILABLE = True
except ImportError:
    run_patching_analysis = None
    PATCHING_SERVICE_AVAILABLE = False
    print("WARNING: patching service not found, patching analysis will not be available")

# å¯¼å…¥interventionæœåŠ¡
try:
    from intervention import run_feature_steering_analysis
    INTERVENTION_SERVICE_AVAILABLE = True
except ImportError:
    run_feature_steering_analysis = None
    INTERVENTION_SERVICE_AVAILABLE = False
    print("WARNING: intervention service not found, steering analysis will not be available")

# å¯¼å…¥è‡ªå¯¹å¼ˆæœåŠ¡
try:
    from self_play import run_self_play, analyze_game_positions
    SELF_PLAY_SERVICE_AVAILABLE = True
except ImportError:
    run_self_play = None
    analyze_game_positions = None
    SELF_PLAY_SERVICE_AVAILABLE = False
    print("WARNING: self-play service not found, self-play functionality will not be available")

# å¯¼å…¥Logit LensæœåŠ¡
try:
    from logit_lens import IntegratedPolicyLens
    LOGIT_LENS_AVAILABLE = True
except ImportError:
    IntegratedPolicyLens = None
    LOGIT_LENS_AVAILABLE = False
    print("WARNING: logit_lens not found, logit lens functionality will not be available")

# å…¨å±€Logit Lensç¼“å­˜
_logit_lens_instances = {}


@app.post("/circuit/preload_models")
def preload_circuit_models(request: dict):
    """
    é¢„åŠ è½½transcoderså’Œlorsasæ¨¡å‹ï¼Œä»¥ä¾¿åç»­çš„circuit traceèƒ½å¤Ÿå¿«é€Ÿä½¿ç”¨
    
    Args:
        request: åŒ…å«æ¨¡å‹ä¿¡æ¯çš„è¯·æ±‚ä½“
            - model_name: æ¨¡å‹åç§° (å¯é€‰ï¼Œé»˜è®¤: "lc0/BT4-1024x15x32h")
    
    Returns:
        é¢„åŠ è½½çŠ¶æ€å’Œç»“æœ
    """
    model_name = request.get("model_name", "lc0/BT4-1024x15x32h")
    
    try:
        if not CIRCUITS_SERVICE_AVAILABLE or load_model_and_transcoders is None:
            raise HTTPException(status_code=503, detail="Circuit tracing service not available")
        
        # è·å–æˆ–åˆ›å»ºåŠ è½½é”
        global _loading_locks, _loading_status, _loading_logs
        if model_name not in _loading_locks:
            _loading_locks[model_name] = threading.Lock()
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»é¢„åŠ è½½
        cached_transcoders, cached_lorsas = get_cached_transcoders_and_lorsas(model_name)
        if cached_transcoders is not None and cached_lorsas is not None:
            # æ£€æŸ¥æ˜¯å¦å®Œæ•´ï¼ˆ15å±‚ï¼‰
            if len(cached_transcoders) == 15 and len(cached_lorsas) == 15:
                print(f"âœ… Transcoderså’ŒLoRSAså·²ç»é¢„åŠ è½½: {model_name}")
                return {
                    "status": "already_loaded",
                    "message": f"æ¨¡å‹ {model_name} çš„transcoderså’Œlorsaså·²ç»é¢„åŠ è½½",
                    "model_name": model_name,
                    "n_layers": len(cached_lorsas),
                    "transcoders_count": len(cached_transcoders),
                    "lorsas_count": len(cached_lorsas)
                }
        
        # ä½¿ç”¨é”æ¥é¿å…å¹¶å‘åŠ è½½
        with _loading_locks[model_name]:
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²ç»åŠ è½½ï¼ˆå¯èƒ½åœ¨ç­‰å¾…é”çš„è¿‡ç¨‹ä¸­å·²ç»åŠ è½½å®Œæˆï¼‰
            cached_transcoders, cached_lorsas = get_cached_transcoders_and_lorsas(model_name)
            if cached_transcoders is not None and cached_lorsas is not None:
                if len(cached_transcoders) == 15 and len(cached_lorsas) == 15:
                    print(f"âœ… Transcoderså’ŒLoRSAså·²ç»é¢„åŠ è½½ï¼ˆåœ¨é”å†…æ£€æŸ¥ï¼‰: {model_name}")
                    return {
                        "status": "already_loaded",
                        "message": f"æ¨¡å‹ {model_name} çš„transcoderså’Œlorsaså·²ç»é¢„åŠ è½½",
                        "model_name": model_name,
                        "n_layers": len(cached_lorsas),
                        "transcoders_count": len(cached_transcoders),
                        "lorsas_count": len(cached_lorsas)
                    }
            
            # æ ‡è®°æ­£åœ¨åŠ è½½
            _loading_status[model_name] = {"is_loading": True}
            print(f"ğŸ” å¼€å§‹é¢„åŠ è½½transcoderså’Œlorsas: {model_name}")
            
            try:
                # è·å–HookedTransformeræ¨¡å‹
                hooked_model = get_hooked_model(model_name)
                
                # æ ¹æ®æ¨¡å‹åç§°è®¾ç½®æ­£ç¡®çš„è·¯å¾„
                base_path = "/inspire/hdd/global_user/hezhengfu-240208120186/rlin_projects/rlin_projects/chess-SAEs-N"
                if 'BT4' in model_name:
                    tc_base_path = f"{base_path}/result_BT4/tc"
                    lorsa_base_path = f"{base_path}/result_BT4/lorsa"
                    n_layers = 15
                else:
                    raise HTTPException(status_code=400, detail="Unsupported Model!")
                
                # åˆå§‹åŒ–åŠ è½½æ—¥å¿—
                if model_name not in _loading_logs:
                    _loading_logs[model_name] = []
                loading_logs = _loading_logs[model_name]
                loading_logs.clear()  # æ¸…ç©ºæ—§çš„æ—¥å¿—
                print(f"ğŸ“ åˆå§‹åŒ–åŠ è½½æ—¥å¿—åˆ—è¡¨: model_name={model_name}, åˆ—è¡¨ID={id(loading_logs)}")
                
                # åŠ è½½transcoderså’Œlorsas
                device = "cuda" if torch.cuda.is_available() else "cpu"
                replacement_model, transcoders, lorsas = load_model_and_transcoders(
                    model_name=model_name,
                    device=device,
                    tc_base_path=tc_base_path,
                    lorsa_base_path=lorsa_base_path,
                    n_layers=n_layers,
                    hooked_model=hooked_model,
                    loading_logs=loading_logs
                )
                
                # ç¡®ä¿æ—¥å¿—å·²å†™å…¥
                print(f"ğŸ“ åŠ è½½å®Œæˆåçš„æ—¥å¿—æ•°é‡: {len(loading_logs)}")
                print(f"ğŸ“ å…¨å±€å­—å…¸ä¸­çš„æ—¥å¿—æ•°é‡: {len(_loading_logs.get(model_name, []))}")
                
                # ç¼“å­˜transcoderså’Œlorsasï¼ˆåŒæ—¶æ›´æ–°å…±äº«ç¼“å­˜å’Œæœ¬åœ°ç¼“å­˜ï¼‰
                global _transcoders_cache, _lorsas_cache, _replacement_models_cache
                _transcoders_cache[model_name] = transcoders
                _lorsas_cache[model_name] = lorsas
                _replacement_models_cache[model_name] = replacement_model
                
                # å¦‚æœcircuits_serviceå¯ç”¨ï¼Œä¹Ÿæ›´æ–°å…±äº«ç¼“å­˜
                if CIRCUITS_SERVICE_AVAILABLE and set_cached_models is not None:
                    set_cached_models(model_name, hooked_model, transcoders, lorsas, replacement_model)
                
                print(f"âœ… é¢„åŠ è½½å®Œæˆ: {model_name}")
                print(f"   - Transcoders: {len(transcoders)} å±‚")
                print(f"   - LoRSAs: {len(lorsas)} å±‚")
                
                # æ·»åŠ å®Œæˆæ—¥å¿—
                if model_name in _loading_logs:
                    _loading_logs[model_name].append({
                        "timestamp": time.time(),
                        "message": f"âœ… é¢„åŠ è½½å®Œæˆ: {model_name}"
                    })
                    _loading_logs[model_name].append({
                        "timestamp": time.time(),
                        "message": f"   - Transcoders: {len(transcoders)} å±‚"
                    })
                    _loading_logs[model_name].append({
                        "timestamp": time.time(),
                        "message": f"   - LoRSAs: {len(lorsas)} å±‚"
                    })
                
                # æ ‡è®°åŠ è½½å®Œæˆ
                _loading_status[model_name] = {"is_loading": False}
                
                return {
                    "status": "loaded",
                    "message": f"æˆåŠŸé¢„åŠ è½½æ¨¡å‹ {model_name} çš„transcoderså’Œlorsas",
                    "model_name": model_name,
                    "n_layers": n_layers,
                    "transcoders_count": len(transcoders),
                    "lorsas_count": len(lorsas),
                    "device": device
                }
            except Exception as e:
                # æ ‡è®°åŠ è½½å¤±è´¥
                _loading_status[model_name] = {"is_loading": False}
                raise
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        # æ·»åŠ é”™è¯¯æ—¥å¿—ï¼ˆ_loading_logs å’Œ _loading_status å·²åœ¨å‡½æ•°å¼€å¤´å£°æ˜ä¸º globalï¼‰
        if model_name in _loading_logs:
            _loading_logs[model_name].append({
                "timestamp": time.time(),
                "message": f"âŒ é¢„åŠ è½½å¤±è´¥: {str(e)}"
            })
        # æ ‡è®°åŠ è½½å¤±è´¥
        if model_name in _loading_status:
            _loading_status[model_name] = {"is_loading": False}
        raise HTTPException(status_code=500, detail=f"é¢„åŠ è½½å¤±è´¥: {str(e)}")


@app.get("/circuit/loading_logs")
def get_loading_logs(model_name: str = "lc0/BT4-1024x15x32h"):
    """
    è·å–æ¨¡å‹åŠ è½½æ—¥å¿—
    
    Args:
        model_name: æ¨¡å‹åç§° (æŸ¥è¯¢å‚æ•°ï¼Œé»˜è®¤: "lc0/BT4-1024x15x32h")
    
    Returns:
        åŠ è½½æ—¥å¿—åˆ—è¡¨
    """
    global _loading_logs
    # URLè§£ç ï¼Œå¤„ç†å¯èƒ½çš„åŒé‡ç¼–ç é—®é¢˜
    import urllib.parse
    decoded_model_name = urllib.parse.unquote(model_name)
    # å¦‚æœè¿˜æ˜¯ç¼–ç çš„ï¼Œå†è§£ç ä¸€æ¬¡
    if '%' in decoded_model_name:
        decoded_model_name = urllib.parse.unquote(decoded_model_name)
    
    # å°è¯•å¤šç§å¯èƒ½çš„é”®å
    logs = _loading_logs.get(decoded_model_name, [])
    if not logs:
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•åŸå§‹é”®å
        logs = _loading_logs.get(model_name, [])
    
    # è°ƒè¯•ä¿¡æ¯
    
    return {
        "model_name": decoded_model_name,
        "logs": logs,
        "total_count": len(logs)
    }



@app.post("/circuit_trace")
def circuit_trace(request: dict):
    """
    è¿è¡Œcircuit traceåˆ†æå¹¶è¿”å›graphæ•°æ®
    
    Args:
        request: åŒ…å«åˆ†æå‚æ•°çš„è¯·æ±‚ä½“
            - fen: FENå­—ç¬¦ä¸² (å¿…éœ€)
            - move_uci: è¦åˆ†æçš„UCIç§»åŠ¨ (å¿…éœ€)
            - side: åˆ†æä¾§ (q/k/both, é»˜è®¤: "k")
            - max_feature_nodes: æœ€å¤§ç‰¹å¾èŠ‚ç‚¹æ•° (é»˜è®¤: 4096)
            - node_threshold: èŠ‚ç‚¹é˜ˆå€¼ (é»˜è®¤: 0.73)
            - edge_threshold: è¾¹é˜ˆå€¼ (é»˜è®¤: 0.57)
            - max_n_logits: æœ€å¤§logitæ•°é‡ (é»˜è®¤: 1)
            - desired_logit_prob: æœŸæœ›logitæ¦‚ç‡ (é»˜è®¤: 0.95)
            - batch_size: æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 1)
            - order_mode: æ’åºæ¨¡å¼ (positive/negative, é»˜è®¤: "positive")
            - encoder_demean: æ˜¯å¦å¯¹encoderè¿›è¡Œdemean (é»˜è®¤: False)
            - save_activation_info: æ˜¯å¦ä¿å­˜æ¿€æ´»ä¿¡æ¯ (é»˜è®¤: False)
    
    Returns:
        Graphæ•°æ® (JSONæ ¼å¼)
    """
    try:
        # æ£€æŸ¥circuits_serviceæ˜¯å¦å¯ç”¨
        if not CIRCUITS_SERVICE_AVAILABLE:
            raise HTTPException(status_code=503, detail="Circuit tracing service not available")
        
        # æå–å‚æ•°
        fen = request.get("fen")
        if not fen:
            raise HTTPException(status_code=400, detail="FEN string is required")
        
        move_uci = request.get("move_uci")
        negative_move_uci = request.get("negative_move_uci", None)  # æ–°å¢negative_move_uciå‚æ•°
        
        side = request.get("side", "k")
        max_feature_nodes = request.get("max_feature_nodes", 4096)
        node_threshold = request.get("node_threshold", 0.73)
        edge_threshold = request.get("edge_threshold", 0.57)
        max_n_logits = request.get("max_n_logits", 1)
        desired_logit_prob = request.get("desired_logit_prob", 0.95)
        batch_size = request.get("batch_size", 1)
        order_mode = request.get("order_mode", "positive")
        encoder_demean = request.get("encoder_demean", False)
        save_activation_info = request.get("save_activation_info", True)  # é»˜è®¤å¯ç”¨æ¿€æ´»ä¿¡æ¯ä¿å­˜
        max_act_times = request.get("max_act_times", None)  # æ·»åŠ æœ€å¤§æ¿€æ´»æ¬¡æ•°å‚æ•°
        # å¼ºåˆ¶ä½¿ç”¨BT4æ¨¡å‹
        model_name = "lc0/BT4-1024x15x32h"
        
        print(f"ğŸ” Circuit Trace è¯·æ±‚å‚æ•°:")
        print(f"   - FEN: {fen}")
        print(f"   - Move UCI: {move_uci}")
        print(f"   - Negative Move UCI: {negative_move_uci}")
        print(f"   - Model Name: {model_name}")
        print(f"   - Side: {side}")
        print(f"   - Order Mode: {order_mode}")
        print(f"   - Max Act Times: {max_act_times}")
        
        # éªŒè¯ side å‚æ•°
        if side not in ["q", "k", "both"]:
            raise HTTPException(status_code=400, detail="side must be 'q', 'k', or 'both'")
        
        # éªŒè¯ order_mode å‚æ•°å’Œå¤„ç†bothæ¨¡å¼
        if order_mode == "both":
            # Bothæ¨¡å¼ï¼šéœ€è¦positive moveå’Œnegative move
            if not move_uci:
                raise HTTPException(status_code=400, detail="move_uci (positive move) is required for 'both' mode")
            if not negative_move_uci:
                raise HTTPException(status_code=400, detail="negative_move_uci is required for 'both' mode")
            # Bothæ¨¡å¼å¼ºåˆ¶sideä¸ºboth
            side = "both"
            # å°†order_modeè½¬æ¢ä¸ºmove_pairï¼Œä»¥ä¾¿åç«¯å¤„ç†
            order_mode = "move_pair"
        elif order_mode not in ["positive", "negative"]:
            raise HTTPException(status_code=400, detail="order_mode must be 'positive', 'negative', or 'both'")
        
        # éªŒè¯move_uci
        if not move_uci:
            raise HTTPException(status_code=400, detail="move_uci is required")
        
        # è·å–å·²ç¼“å­˜çš„HookedTransformeræ¨¡å‹
        hooked_model = get_hooked_model(model_name)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„transcoderså’Œlorsas
        cached_transcoders, cached_lorsas = get_cached_transcoders_and_lorsas(model_name)
        cached_replacement_model = _replacement_models_cache.get(model_name)
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨åŠ è½½
        global _loading_status, _loading_locks
        is_loading = _loading_status.get(model_name, {}).get("is_loading", False)
        
        # å¦‚æœç¼“å­˜ä¸å®Œæ•´ä¸”æ­£åœ¨åŠ è½½ï¼Œç­‰å¾…åŠ è½½å®Œæˆ
        cache_complete = (cached_transcoders is not None and cached_lorsas is not None and 
                         cached_replacement_model is not None and
                         len(cached_transcoders) == 15 and len(cached_lorsas) == 15)
        
        if not cache_complete and is_loading:
            print(f"â³ æ£€æµ‹åˆ°æ­£åœ¨åŠ è½½TC/LoRSAï¼Œç­‰å¾…åŠ è½½å®Œæˆï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰: {model_name}")
            # è·å–åŠ è½½é”ï¼ˆç­‰å¾…åŠ è½½å®Œæˆï¼‰
            if model_name not in _loading_locks:
                _loading_locks[model_name] = threading.Lock()
            
            # ç­‰å¾…åŠ è½½å®Œæˆï¼ˆæœ€å¤šç­‰å¾…10åˆ†é’Ÿï¼Œå› ä¸ºåŠ è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰
            max_wait_time = 600  # 10åˆ†é’Ÿ
            wait_start = time.time()
            wait_interval = 1  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
            while (time.time() - wait_start) < max_wait_time:
                is_loading = _loading_status.get(model_name, {}).get("is_loading", False)
                # é‡æ–°æ£€æŸ¥ç¼“å­˜
                cached_transcoders, cached_lorsas = get_cached_transcoders_and_lorsas(model_name)
                cached_replacement_model = _replacement_models_cache.get(model_name)
                cache_complete = (cached_transcoders is not None and cached_lorsas is not None and 
                                 cached_replacement_model is not None and
                                 len(cached_transcoders) == 15 and len(cached_lorsas) == 15)
                if cache_complete:
                    print(f"âœ… ç­‰å¾…åŠ è½½å®Œæˆï¼Œå·²è·å–å®Œæ•´ç¼“å­˜: {model_name} (ç­‰å¾…æ—¶é—´: {time.time() - wait_start:.1f}ç§’)")
                    break
                if not is_loading and not cache_complete:
                    # åŠ è½½å·²å®Œæˆä½†ç¼“å­˜ä¸å®Œæ•´ï¼Œå¯èƒ½æ˜¯åŠ è½½å¤±è´¥
                    print(f"âš ï¸ åŠ è½½å·²å®Œæˆä½†ç¼“å­˜ä¸å®Œæ•´ï¼Œå¯èƒ½éœ€è¦é‡æ–°åŠ è½½: {model_name}")
                    break
                time.sleep(wait_interval)
                elapsed = time.time() - wait_start
                if int(elapsed) % 10 == 0 and int(elapsed) > 0:  # æ¯10ç§’æ‰“å°ä¸€æ¬¡
                    print(f"â³ ä»åœ¨ç­‰å¾…åŠ è½½å®Œæˆ... (å·²ç­‰å¾… {elapsed:.1f}ç§’, TC: {len(cached_transcoders) if cached_transcoders else 0}, LoRSA: {len(cached_lorsas) if cached_lorsas else 0})")
            
            if not cache_complete:
                elapsed = time.time() - wait_start
                if elapsed >= max_wait_time:
                    print(f"âš ï¸ ç­‰å¾…åŠ è½½è¶…æ—¶ï¼ˆ{elapsed:.1f}ç§’ï¼‰ï¼Œä½†å°†ç»§ç»­ä½¿ç”¨å½“å‰ç¼“å­˜æˆ–æŠ¥é”™: {model_name}")
                else:
                    print(f"âš ï¸ åŠ è½½å®Œæˆä½†ç¼“å­˜ä¸å®Œæ•´ï¼Œå°†ä½¿ç”¨å½“å‰ç¼“å­˜æˆ–æŠ¥é”™: {model_name}")
        
        # æ ¹æ®æ¨¡å‹åç§°è®¾ç½®æ­£ç¡®çš„è·¯å¾„ï¼ˆå³ä½¿ä½¿ç”¨ç¼“å­˜ï¼Œä¹Ÿéœ€è¦è·¯å¾„ç”¨äºå…¼å®¹æ€§ï¼‰
        base_path = "/inspire/hdd/global_user/hezhengfu-240208120186/rlin_projects/rlin_projects/chess-SAEs-N"
        if 'BT4' in model_name:
            tc_base_path = f"{base_path}/result_BT4/tc"
            lorsa_base_path = f"{base_path}/result_BT4/lorsa"
        else:
            raise HTTPException(status_code=400, detail="Unsupported Model!")
        
        # ç­‰å¾…åå†æ¬¡æ£€æŸ¥ç¼“å­˜ï¼ˆå› ä¸ºç­‰å¾…è¿‡ç¨‹ä¸­ç¼“å­˜å¯èƒ½å·²ç»å®Œæ•´ï¼‰
        if not cache_complete:
            cached_transcoders, cached_lorsas = get_cached_transcoders_and_lorsas(model_name)
            cached_replacement_model = _replacement_models_cache.get(model_name)
            cache_complete = (cached_transcoders is not None and cached_lorsas is not None and 
                             cached_replacement_model is not None and
                             len(cached_transcoders) == 15 and len(cached_lorsas) == 15)
        
        if cache_complete:
            # ä½¿ç”¨ç¼“å­˜çš„transcoderså’Œlorsasï¼Œä¸éœ€è¦é‡æ–°åŠ è½½
            print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„transcodersã€lorsaså’Œreplacement_model: {model_name}")
        else:
            # æ£€æŸ¥æ˜¯å¦ä»åœ¨åŠ è½½
            is_still_loading = _loading_status.get(model_name, {}).get("is_loading", False)
            if is_still_loading:
                # å¦‚æœä»åœ¨åŠ è½½ï¼Œç»§ç»­ç­‰å¾…
                print(f"â³ ç¼“å­˜ä¸å®Œæ•´ä½†ä»åœ¨ä½¿ç”¨ä¸­åŠ è½½ï¼Œå°†ç»§ç»­ç­‰å¾…...")
                raise HTTPException(status_code=503, detail=f"æ¨¡å‹ {model_name} æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•ã€‚å½“å‰è¿›åº¦: TC {len(cached_transcoders) if cached_transcoders else 0}/15, LoRSA {len(cached_lorsas) if cached_lorsas else 0}/15")
            elif cached_transcoders is None or cached_lorsas is None:
                # å®Œå…¨æ²¡æœ‰ç¼“å­˜ï¼Œéœ€è¦åŠ è½½
                print(f"âš ï¸ æœªæ‰¾åˆ°ç¼“å­˜ï¼Œå°†é‡æ–°åŠ è½½transcoderså’Œlorsas: {model_name}")
                print("   æç¤ºï¼šå»ºè®®å…ˆè°ƒç”¨ /circuit/preload_models è¿›è¡Œé¢„åŠ è½½ä»¥åŠ é€Ÿ")
            else:
                # æœ‰éƒ¨åˆ†ç¼“å­˜ä½†ä¸å®Œæ•´ï¼Œä¹Ÿé‡æ–°åŠ è½½ï¼ˆè¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºåº”è¯¥ç­‰å¾…åŠ è½½å®Œæˆï¼‰
                print(f"âš ï¸ ç¼“å­˜ä¸å®Œæ•´ï¼ˆTC: {len(cached_transcoders)}, LoRSA: {len(cached_lorsas)}ï¼‰ï¼Œå°†é‡æ–°åŠ è½½: {model_name}")
        
        # è¿è¡Œcircuit traceï¼Œä¼ é€’å·²ç¼“å­˜çš„æ¨¡å‹å’Œtranscoders/lorsas
        graph_data = run_circuit_trace(
            prompt=fen,
            move_uci=move_uci,
            negative_move_uci=negative_move_uci,  # ä¼ é€’negative_move_uci
            model_name=model_name,  # æ·»åŠ æ¨¡å‹åç§°å‚æ•°
            tc_base_path=tc_base_path,  # ä¼ é€’æ­£ç¡®çš„TCè·¯å¾„
            lorsa_base_path=lorsa_base_path,  # ä¼ é€’æ­£ç¡®çš„LORSAè·¯å¾„
            side=side,
            max_feature_nodes=max_feature_nodes,
            node_threshold=node_threshold,
            edge_threshold=edge_threshold,
            max_n_logits=max_n_logits,
            desired_logit_prob=desired_logit_prob,
            batch_size=batch_size,
            order_mode=order_mode,
            encoder_demean=encoder_demean,
            save_activation_info=save_activation_info,
            act_times_max=max_act_times,  # ä¼ é€’æœ€å¤§æ¿€æ´»æ¬¡æ•°å‚æ•°
            log_level="INFO",
            hooked_model=hooked_model,  # ä¼ é€’å·²ç¼“å­˜çš„æ¨¡å‹
            cached_transcoders=cached_transcoders,  # ä¼ é€’ç¼“å­˜çš„transcoders
            cached_lorsas=cached_lorsas,  # ä¼ é€’ç¼“å­˜çš„lorsas
            cached_replacement_model=cached_replacement_model  # ä¼ é€’ç¼“å­˜çš„replacement_model
        )
        
        return graph_data
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Circuit trace analysis failed: {str(e)}")


@app.get("/circuit_trace/status")
def circuit_trace_status():
    """æ£€æŸ¥circuit traceæœåŠ¡çš„çŠ¶æ€"""
    return {
        "available": CIRCUITS_SERVICE_AVAILABLE,
        "hooked_transformer_available": HOOKED_TRANSFORMER_AVAILABLE
    }


@app.post("/circuit/check_dense_features")
def check_dense_features_api(request: dict):
    """
    æ£€æŸ¥circuitä¸­å“ªäº›èŠ‚ç‚¹æ˜¯dense featureï¼ˆæ¿€æ´»æ¬¡æ•°è¶…è¿‡é˜ˆå€¼ï¼‰
    
    Args:
        request: åŒ…å«æ£€æŸ¥å‚æ•°çš„è¯·æ±‚ä½“
            - nodes: èŠ‚ç‚¹åˆ—è¡¨
            - threshold: æ¿€æ´»æ¬¡æ•°é˜ˆå€¼ï¼ˆå¯é€‰ï¼ŒNoneè¡¨ç¤ºæ— é™å¤§ï¼‰
            - sae_series: SAEç³»åˆ—åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤: BT4-exp128ï¼‰
            - lorsa_analysis_name: LoRSAåˆ†æåç§°æ¨¡æ¿ï¼ˆå¯é€‰ï¼‰
            - tc_analysis_name: TCåˆ†æåç§°æ¨¡æ¿ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        denseèŠ‚ç‚¹çš„IDåˆ—è¡¨
    """
    try:
        # æ£€æŸ¥circuits_serviceæ˜¯å¦å¯ç”¨
        if not CIRCUITS_SERVICE_AVAILABLE or check_dense_features is None:
            raise HTTPException(status_code=503, detail="Dense feature check service not available")
        
        # æå–å‚æ•°
        nodes = request.get("nodes", [])
        if not isinstance(nodes, list):
            raise HTTPException(status_code=400, detail="nodes must be a list")
        
        threshold = request.get("threshold")
        if threshold is not None:
            try:
                threshold = int(threshold)
            except (ValueError, TypeError):
                raise HTTPException(status_code=400, detail="threshold must be an integer or null")
        
        sae_series = request.get("sae_series", "BT4-exp128")
        lorsa_analysis_name = request.get("lorsa_analysis_name")
        tc_analysis_name = request.get("tc_analysis_name")
        
        print(f"ğŸ” æ£€æŸ¥dense features: {len(nodes)} ä¸ªèŠ‚ç‚¹, é˜ˆå€¼={threshold}")
        print(f"   - LoRSAæ¨¡æ¿: {lorsa_analysis_name}")
        print(f"   - TCæ¨¡æ¿: {tc_analysis_name}")
        
        # è®¾ç½®MongoDBè¿æ¥
        mongo_config = MongoDBConfig()
        mongo_client_instance = MongoClient(mongo_config)
        
        # è°ƒç”¨æ£€æŸ¥å‡½æ•°
        dense_node_ids = check_dense_features(
            nodes=nodes,
            threshold=threshold,
            mongo_client=mongo_client_instance,
            sae_series=sae_series,
            lorsa_analysis_name=lorsa_analysis_name,
            tc_analysis_name=tc_analysis_name
        )
        
        print(f"âœ… æ‰¾åˆ° {len(dense_node_ids)} ä¸ªdenseèŠ‚ç‚¹")
        
        return {
            "dense_nodes": dense_node_ids,
            "total_nodes": len(nodes),
            "threshold": threshold
        }
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Dense feature check failed: {str(e)}")


@app.post("/patching_analysis")
def patching_analysis(request: dict):
    """
    è¿è¡Œpatchingåˆ†æå¹¶è¿”å›Token Predictionsç»“æœ
    
    Args:
        request: åŒ…å«åˆ†æå‚æ•°çš„è¯·æ±‚ä½“
            - fen: FENå­—ç¬¦ä¸² (å¿…éœ€)
            - feature_type: ç‰¹å¾ç±»å‹ ('transcoder' æˆ– 'lorsa') (å¿…éœ€)
            - layer: å±‚æ•° (å¿…éœ€)
            - pos: ä½ç½® (å¿…éœ€)
            - feature: ç‰¹å¾ç´¢å¼• (å¿…éœ€)
    
    Returns:
        Token Predictionsåˆ†æç»“æœ (JSONæ ¼å¼)
    """
    try:
        # æ£€æŸ¥patchingæœåŠ¡æ˜¯å¦å¯ç”¨
        if not PATCHING_SERVICE_AVAILABLE:
            raise HTTPException(status_code=503, detail="Patching service not available")
        
        # æå–å‚æ•°
        fen = request.get("fen")
        if not fen:
            raise HTTPException(status_code=400, detail="FEN string is required")
        
        feature_type = request.get("feature_type")
        if feature_type not in ['transcoder', 'lorsa']:
            raise HTTPException(status_code=400, detail="feature_type must be 'transcoder' or 'lorsa'")
        
        layer = request.get("layer")
        if layer is None or not isinstance(layer, int):
            raise HTTPException(status_code=400, detail="layer must be an integer")
        
        pos = request.get("pos")
        if pos is None or not isinstance(pos, int):
            raise HTTPException(status_code=400, detail="pos must be an integer")
        
        feature = request.get("feature")
        if feature is None or not isinstance(feature, int):
            raise HTTPException(status_code=400, detail="feature must be an integer")
        
        print(f"ğŸ” è¿è¡Œpatchingåˆ†æ: {feature_type} L{layer} pos{pos} feature{feature}")
        
        # è¿è¡Œpatchingåˆ†æ
        result = run_patching_analysis(
            fen=fen,
            feature_type=feature_type,
            layer=layer,
            pos=pos,
            feature=feature
        )
        
        if 'error' in result:
            raise HTTPException(status_code=400, detail=result['error'])
        
        print(f"âœ… Patchingåˆ†æå®Œæˆï¼Œæ‰¾åˆ° {result['statistics']['total_legal_moves']} ä¸ªåˆæ³•ç§»åŠ¨")
        
        return result
        
    except Exception as e:
        print(f"âŒ Patchingåˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Patching analysis failed: {str(e)}")


@app.get("/patching_analysis/status")
def patching_analysis_status():
    """æ£€æŸ¥patchingåˆ†ææœåŠ¡çš„çŠ¶æ€"""
    return {
        "available": PATCHING_SERVICE_AVAILABLE,
        "hooked_transformer_available": HOOKED_TRANSFORMER_AVAILABLE
    }


@app.post("/steering_analysis")
def steering_analysis(request: dict):
    """
    è¿è¡Œsteeringåˆ†æå¹¶è¿”å›Token Predictionsç»“æœï¼Œæ”¯æŒå¯è°ƒçš„steering_scale
    
    Args:
        request: åŒ…å«åˆ†æå‚æ•°çš„è¯·æ±‚ä½“
            - fen: FENå­—ç¬¦ä¸² (å¿…éœ€)
            - feature_type: ç‰¹å¾ç±»å‹ ('transcoder' æˆ– 'lorsa') (å¿…éœ€)
            - layer: å±‚æ•° (å¿…éœ€)
            - pos: ä½ç½® (å¿…éœ€)
            - feature: ç‰¹å¾ç´¢å¼• (å¿…éœ€)
            - steering_scale: æ”¾å¤§ç³»æ•° (å¯é€‰ï¼Œé»˜è®¤ 1)
    
    Returns:
        Token Predictionsåˆ†æç»“æœ (JSONæ ¼å¼)
    """
    try:
        if not INTERVENTION_SERVICE_AVAILABLE:
            raise HTTPException(status_code=503, detail="Steering service not available")

        fen = request.get("fen")
        if not fen:
            raise HTTPException(status_code=400, detail="FEN string is required")

        feature_type = request.get("feature_type")
        if feature_type not in ['transcoder', 'lorsa']:
            raise HTTPException(status_code=400, detail="feature_type must be 'transcoder' or 'lorsa'")

        layer = request.get("layer")
        if layer is None or not isinstance(layer, int):
            raise HTTPException(status_code=400, detail="layer must be an integer")

        pos = request.get("pos")
        if pos is None or not isinstance(pos, int):
            raise HTTPException(status_code=400, detail="pos must be an integer")

        feature = request.get("feature")
        if feature is None or not isinstance(feature, int):
            raise HTTPException(status_code=400, detail="feature must be an integer")

        steering_scale = request.get("steering_scale", 1)
        if not isinstance(steering_scale, (int, float)):
            raise HTTPException(status_code=400, detail="steering_scale must be a number")

        # è·å–metadataä¿¡æ¯
        metadata = request.get("metadata", {})

        print(f"ğŸ” è¿è¡Œsteeringåˆ†æ: {feature_type} L{layer} pos{pos} feature{feature} scale{steering_scale}")
        print(f"ğŸ“‹ Metadata: {metadata}")

        result = run_feature_steering_analysis(
            fen=fen,
            feature_type=feature_type,
            layer=layer,
            pos=pos,
            feature=feature,
            steering_scale=steering_scale,
            metadata=metadata
        )

        if 'error' in result:
            raise HTTPException(status_code=400, detail=result['error'])

        print(f"âœ… Steeringåˆ†æå®Œæˆï¼Œæ‰¾åˆ° {result['statistics']['total_legal_moves']} ä¸ªåˆæ³•ç§»åŠ¨")
        return result

    except Exception as e:
        print(f"âŒ Steeringåˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Steering analysis failed: {str(e)}")


@app.get("/steering_analysis/status")
def steering_analysis_status():
    """æ£€æŸ¥steeringåˆ†ææœåŠ¡çš„çŠ¶æ€"""
    return {
        "available": INTERVENTION_SERVICE_AVAILABLE,
        "hooked_transformer_available": HOOKED_TRANSFORMER_AVAILABLE
    }


@app.post("/self_play")
def start_self_play(request: dict):
    """
    å¼€å§‹è‡ªå¯¹å¼ˆå¹¶è¿”å›æ¸¸æˆæ•°æ®
    
    Args:
        request: åŒ…å«æ¸¸æˆå‚æ•°çš„è¯·æ±‚ä½“
            - initial_fen: åˆå§‹FENå­—ç¬¦ä¸² (å¯é€‰ï¼Œé»˜è®¤èµ·å§‹å±€é¢)
            - max_moves: æœ€å¤§ç§»åŠ¨æ•° (é»˜è®¤: 10)
            - temperature: æ¸©åº¦å‚æ•° (é»˜è®¤: 1.0)
    
    Returns:
        è‡ªå¯¹å¼ˆæ¸¸æˆæ•°æ® (JSONæ ¼å¼)
    """
    try:
        # æ£€æŸ¥è‡ªå¯¹å¼ˆæœåŠ¡æ˜¯å¦å¯ç”¨
        if not SELF_PLAY_SERVICE_AVAILABLE:
            raise HTTPException(status_code=503, detail="Self-play service not available")
        
        # æå–å‚æ•°
        initial_fen = request.get("initial_fen", "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1")
        max_moves = request.get("max_moves", 10)
        temperature = request.get("temperature", 1.0)
        
        # éªŒè¯å‚æ•°
        if not isinstance(max_moves, int) or max_moves <= 0:
            raise HTTPException(status_code=400, detail="max_moves must be a positive integer")
        
        if not isinstance(temperature, (int, float)) or temperature < 0:
            raise HTTPException(status_code=400, detail="temperature must be a non-negative number")
        
        print(f"ğŸ® å¼€å§‹è‡ªå¯¹å¼ˆ: {initial_fen[:50]}..., æœ€å¤§ç§»åŠ¨æ•°: {max_moves}, æ¸©åº¦: {temperature}")
        
        # å¼ºåˆ¶ä½¿ç”¨BT4æ¨¡å‹
        model_name = "lc0/BT4-1024x15x32h"
        hooked_model = get_hooked_model(model_name)
        
        # è¿è¡Œè‡ªå¯¹å¼ˆ
        game_result = run_self_play(
            initial_fen=initial_fen,
            max_moves=max_moves,
            temperature=temperature,
            model=hooked_model
        )
        
        print(f"âœ… è‡ªå¯¹å¼ˆå®Œæˆï¼Œå…±è¿›è¡Œäº† {len(game_result['moves'])} æ­¥")
        
        return game_result
        
    except Exception as e:
        print(f"âŒ è‡ªå¯¹å¼ˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Self-play failed: {str(e)}")


@app.post("/self_play/analyze")
def analyze_self_play_positions(request: dict):
    """
    åˆ†æè‡ªå¯¹å¼ˆä¸­çš„ä½ç½®åºåˆ—
    
    Args:
        request: åŒ…å«ä½ç½®åºåˆ—çš„è¯·æ±‚ä½“
            - positions: FENå­—ç¬¦ä¸²åˆ—è¡¨
    
    Returns:
        ä½ç½®åˆ†æç»“æœ (JSONæ ¼å¼)
    """
    try:
        # æ£€æŸ¥è‡ªå¯¹å¼ˆæœåŠ¡æ˜¯å¦å¯ç”¨
        if not SELF_PLAY_SERVICE_AVAILABLE:
            raise HTTPException(status_code=503, detail="Self-play service not available")
        
        # æå–å‚æ•°
        positions = request.get("positions", [])
        
        if not isinstance(positions, list) or not positions:
            raise HTTPException(status_code=400, detail="positions must be a non-empty list of FEN strings")
        
        print(f"ğŸ” åˆ†æä½ç½®åºåˆ—ï¼Œå…± {len(positions)} ä¸ªä½ç½®")
        
        # è·å–å·²ç¼“å­˜çš„HookedTransformeræ¨¡å‹
        hooked_model = get_hooked_model()
        
        # åˆ†æä½ç½®åºåˆ—
        analysis_result = analyze_game_positions(
            positions=positions,
            model=hooked_model
        )
        
        print(f"âœ… ä½ç½®åˆ†æå®Œæˆ")
        
        return {
            "positions_analysis": analysis_result,
            "total_positions": len(positions)
        }
        
    except Exception as e:
        print(f"âŒ ä½ç½®åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Position analysis failed: {str(e)}")


@app.get("/self_play/status")
def self_play_status():
    """æ£€æŸ¥è‡ªå¯¹å¼ˆæœåŠ¡çš„çŠ¶æ€"""
    return {
        "available": SELF_PLAY_SERVICE_AVAILABLE,
        "hooked_transformer_available": HOOKED_TRANSFORMER_AVAILABLE
    }


@app.post("/logit_lens/analyze")
def logit_lens_analyze(request: dict):
    """
    è¿è¡ŒLogit Lensåˆ†æ
    
    Args:
        request: åŒ…å«åˆ†æå‚æ•°çš„è¯·æ±‚ä½“
            - fen: FENå­—ç¬¦ä¸² (å¿…éœ€)
            - target_move: ç›®æ ‡ç§»åŠ¨UCI (å¯é€‰)
            - topk_vocab: è€ƒè™‘çš„é¡¶éƒ¨è¯æ±‡æ•°é‡ (å¯é€‰ï¼Œé»˜è®¤: 2000)
    
    Returns:
        Logit Lensåˆ†æç»“æœ (JSONæ ¼å¼)
    """
    try:
        # æ£€æŸ¥Logit LensæœåŠ¡æ˜¯å¦å¯ç”¨
        if not LOGIT_LENS_AVAILABLE:
            raise HTTPException(status_code=503, detail="Logit Lens service not available")
        
        # æå–å‚æ•°
        fen = request.get("fen")
        if not fen:
            raise HTTPException(status_code=400, detail="FEN string is required")
        
        # å¼ºåˆ¶ä½¿ç”¨BT4æ¨¡å‹
        model_name = "lc0/BT4-1024x15x32h"
        target_move = request.get("target_move")
        topk_vocab = request.get("topk_vocab", 2000)
        
        print(f"ğŸ” è¿è¡ŒLogit Lensåˆ†æ: FEN={fen[:50]}..., model={model_name}, target={target_move}")
        
        # è·å–æˆ–åˆ›å»ºLogit Lenså®ä¾‹
        global _logit_lens_instances
        if model_name not in _logit_lens_instances:
            # è·å–æ¨¡å‹
            hooked_model = get_hooked_model(model_name)
            # åˆ›å»ºLogit Lenså®ä¾‹
            _logit_lens_instances[model_name] = IntegratedPolicyLens(hooked_model)
        
        lens = _logit_lens_instances[model_name]
        
        # è¿è¡Œåˆ†æ
        result = lens.analyze_single_fen(
            fen=fen,
            target_move=target_move,
            topk_vocab=topk_vocab
        )
        
        if 'error' in result:
            raise HTTPException(status_code=400, detail=result['error'])
        
        print(f"âœ… Logit Lensåˆ†æå®Œæˆï¼Œåˆ†æäº† {result['num_layers']} å±‚")
        
        return {
            **result,
            "model_used": model_name
        }
        
    except Exception as e:
        print(f"âŒ Logit Lensåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Logit Lens analysis failed: {str(e)}")


@app.get("/logit_lens/status")
def logit_lens_status():
    """æ£€æŸ¥Logit LensæœåŠ¡çš„çŠ¶æ€"""
    return {
        "available": LOGIT_LENS_AVAILABLE,
        "hooked_transformer_available": HOOKED_TRANSFORMER_AVAILABLE
    }


@app.post("/logit_lens/mean_ablation")
def logit_lens_mean_ablation(request: dict):
    """
    è¿è¡ŒMean Ablationåˆ†æ
    
    Args:
        request: åŒ…å«åˆ†æå‚æ•°çš„è¯·æ±‚ä½“
            - fen: FENå­—ç¬¦ä¸² (å¿…éœ€)
            - hook_types: hookç±»å‹åˆ—è¡¨ (å¯é€‰ï¼Œé»˜è®¤: ['attn_out', 'mlp_out'])
            - target_move: ç›®æ ‡ç§»åŠ¨UCI (å¯é€‰)
            - topk_vocab: è€ƒè™‘çš„é¡¶éƒ¨è¯æ±‡æ•°é‡ (å¯é€‰ï¼Œé»˜è®¤: 2000)
    
    Returns:
        Mean Ablationåˆ†æç»“æœ (JSONæ ¼å¼)
    """
    try:
        # æ£€æŸ¥Logit LensæœåŠ¡æ˜¯å¦å¯ç”¨
        if not LOGIT_LENS_AVAILABLE:
            raise HTTPException(status_code=503, detail="Logit Lens service not available")
        
        # æå–å‚æ•°
        fen = request.get("fen")
        if not fen:
            raise HTTPException(status_code=400, detail="FEN string is required")
        
        # å¼ºåˆ¶ä½¿ç”¨BT4æ¨¡å‹
        model_name = "lc0/BT4-1024x15x32h"
        hook_types = request.get("hook_types", ['attn_out', 'mlp_out'])
        target_move = request.get("target_move")
        topk_vocab = request.get("topk_vocab", 2000)
        
        print(f"ğŸ” è¿è¡ŒMean Ablationåˆ†æ: FEN={fen[:50]}..., model={model_name}, hooks={hook_types}, target={target_move}")
        
        # è·å–æˆ–åˆ›å»ºLogit Lenså®ä¾‹
        global _logit_lens_instances
        if model_name not in _logit_lens_instances:
            # è·å–æ¨¡å‹
            hooked_model = get_hooked_model(model_name)
            # åˆ›å»ºLogit Lenså®ä¾‹
            _logit_lens_instances[model_name] = IntegratedPolicyLens(hooked_model)
        
        lens = _logit_lens_instances[model_name]
        
        # è¿è¡ŒMean Ablationåˆ†æ
        result = lens.analyze_mean_ablation(
            fen=fen,
            hook_types=hook_types,
            target_move=target_move,
            topk_vocab=topk_vocab
        )
        
        if 'error' in result:
            raise HTTPException(status_code=400, detail=result['error'])
        
        print(f"âœ… Mean Ablationåˆ†æå®Œæˆï¼Œåˆ†æäº† {result['num_layers']} å±‚ï¼Œ{len(result['hook_types'])} ç§hookç±»å‹")
        
        return {
            **result,
            "model_used": model_name
        }
        
    except Exception as e:
        print(f"âŒ Mean Ablationåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Mean Ablation analysis failed: {str(e)}")


# æ–°å¢ï¼šèµ°æ³•è¯„æµ‹æ¥å£ï¼ˆåŸºäºStockfishï¼‰
@app.post("/evaluate_move")
def evaluate_move(request: dict):
    """
    è¯„æµ‹ä¸€æ¬¡ç§»åŠ¨ï¼šè¾“å…¥ä¸Šä¸€æ­¥ä¹‹å‰çš„FENä¸è¯¥æ­¥UCIï¼Œè¿”å›0-100è¯„åˆ†ã€cpå·®ã€WDLç­‰ã€‚

    body: { "fen": str, "move": str, "time_limit": float? }
    """
    fen = request.get("fen")
    move = request.get("move")
    time_limit = request.get("time_limit", 0.2)
    if not fen or not move:
        raise HTTPException(status_code=400, detail="fenä¸moveå¿…å¡«")
    try:
        _ = chess.Board(fen)
    except Exception:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„FEN")

    res = evaluate_move_quality(fen, move, time_limit=time_limit)
    if res is None:
        raise HTTPException(status_code=400, detail="è¯„æµ‹å¤±è´¥æˆ–èµ°æ³•ä¸åˆæ³•")
    return res


# æˆ˜æœ¯ç‰¹å¾åˆ†ææ¥å£
@app.post("/tactic_features/analyze")
async def analyze_tactic_features_api(
    file: UploadFile = File(...),
    n_random: int = Form(200),
    n_fens: int = Form(200),
    top_k_lorsa: int = Form(10),
    top_k_tc: int = Form(10),
    specific_layer: Optional[str] = Form(None),
    specific_layer_top_k: int = Form(20),
):
    """
    åˆ†ææˆ˜æœ¯ç‰¹å¾ï¼šä¸Šä¼ FENæ–‡ä»¶ï¼Œä¸éšæœºFENæ¯”è¾ƒï¼Œæ‰¾å‡ºæœ€ç›¸å…³çš„ç‰¹å¾
    
    Args:
        file: ä¸Šä¼ çš„txtæ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªFEN
        model_name: æ¨¡å‹åç§°
        n_random: éšæœºFENæ•°é‡ï¼ˆå…¼å®¹æ—§å‚æ•°ï¼‰
        n_fens: FENæ•°é‡ï¼ˆæ–°å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ï¼‰
        top_k_lorsa: æ˜¾ç¤ºtop kä¸ªLoRSAç‰¹å¾
        top_k_tc: æ˜¾ç¤ºtop kä¸ªTCç‰¹å¾
        specific_layer: æŒ‡å®šå±‚å·ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæä¾›åˆ™é¢å¤–è¿”å›è¯¥å±‚çš„è¯¦ç»†ç‰¹å¾
        specific_layer_top_k: æŒ‡å®šå±‚çš„top kç‰¹å¾æ•°
    """
    if not TACTIC_FEATURES_AVAILABLE:
        raise HTTPException(status_code=503, detail="Tactic features analysis not available")
    
    if not HOOKED_TRANSFORMER_AVAILABLE:
        raise HTTPException(status_code=503, detail="HookedTransformer not available")
    
    try:
        # å¼ºåˆ¶ä½¿ç”¨BT4æ¨¡å‹
        model_name = "lc0/BT4-1024x15x32h"
        
        # ========== è°ƒè¯•ä¿¡æ¯ï¼šå‡½æ•°å¼€å§‹ ==========
        print("=" * 80)
        print("ğŸš€ å¼€å§‹å¤„ç†æˆ˜æœ¯ç‰¹å¾åˆ†æè¯·æ±‚")
        print(f"ğŸ“¥ æ¥æ”¶åˆ°çš„åŸå§‹å‚æ•°:")
        print(f"   - model_name: {model_name} (å¼ºåˆ¶ä½¿ç”¨BT4)")
        print(f"   - n_random: {n_random}")
        print(f"   - n_fens: {n_fens}")
        print(f"   - top_k_lorsa: {top_k_lorsa}")
        print(f"   - top_k_tc: {top_k_tc}")
        print(f"   - specific_layer (åŸå§‹): {specific_layer} (ç±»å‹: {type(specific_layer)})")
        print(f"   - specific_layer_top_k: {specific_layer_top_k}")
        print("=" * 80)
        
        # è§£æspecific_layerå‚æ•°
        parsed_specific_layer = None
        print(f"ğŸ” å¼€å§‹è§£æ specific_layer å‚æ•°...")
        print(f"   - specific_layer is None: {specific_layer is None}")
        if specific_layer is not None:
            print(f"   - specific_layer å€¼: '{specific_layer}'")
            print(f"   - specific_layer.strip() å: '{specific_layer.strip() if isinstance(specific_layer, str) else specific_layer}'")
        
        if specific_layer is not None and isinstance(specific_layer, str) and specific_layer.strip():
            try:
                parsed_specific_layer = int(specific_layer.strip())
                print(f"âœ… æˆåŠŸè§£ææŒ‡å®šå±‚å‚æ•°: {parsed_specific_layer} (åŸå§‹å€¼: '{specific_layer}')")
            except (ValueError, TypeError) as e:
                print(f"âŒ è§£æå±‚å·å‚æ•°å¤±è´¥: {e}")
                print(f"âš ï¸ æ— æ•ˆçš„å±‚å·å‚æ•°: '{specific_layer}'ï¼Œå°†å¿½ç•¥æŒ‡å®šå±‚åˆ†æ")
                parsed_specific_layer = None
        elif specific_layer is None:
            print(f"â„¹ï¸ æœªæä¾› specific_layer å‚æ•°ï¼Œå°†ä¸è¿›è¡ŒæŒ‡å®šå±‚åˆ†æ")
        else:
            print(f"âš ï¸ specific_layer å‚æ•°ä¸ºç©ºå­—ç¬¦ä¸²æˆ–æ— æ•ˆï¼Œå°†å¿½ç•¥")
        
        # ä½¿ç”¨n_fenså‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨n_random
        actual_n_fens = n_fens if n_fens != 200 or n_random == 200 else n_random
        print(f"ğŸ“Š å®é™…ä½¿ç”¨çš„FENæ•°é‡: {actual_n_fens}")
        
        print(f"ğŸ¯ æœ€ç»ˆè§£æç»“æœ:")
        print(f"   - parsed_specific_layer: {parsed_specific_layer}")
        print(f"   - specific_layer_top_k: {specific_layer_top_k}")
        print(f"   - actual_n_fens: {actual_n_fens}")
        if parsed_specific_layer is not None:
            print(f"âœ… å°†åˆ†ææŒ‡å®šå±‚: Layer {parsed_specific_layer}")
        else:
            print(f"â„¹ï¸ ä¸è¿›è¡ŒæŒ‡å®šå±‚åˆ†æ")
        print("=" * 80)
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        contents = await file.read()
        text = contents.decode('utf-8')
        tactic_fens = [line.strip() for line in text.strip().split('\n') if line.strip()]
        
        if not tactic_fens:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶ä¸ºç©ºæˆ–æ²¡æœ‰æœ‰æ•ˆçš„FENè¡Œ")
        
        # éªŒè¯FENæ ¼å¼
        valid_fens, invalid_fens = validate_fens(tactic_fens)
        
        # é™åˆ¶FENæ•°é‡ï¼šå¦‚æœæ–‡ä»¶ä¸­çš„FENå¤šäºè®¾ç½®çš„æ•°é‡ï¼Œå–å‰næ¡ï¼›å¦åˆ™å…¨éƒ¨ä½¿ç”¨
        if len(valid_fens) > actual_n_fens:
            print(f"ğŸ“Š æ–‡ä»¶ä¸­æœ‰ {len(valid_fens)} ä¸ªæœ‰æ•ˆFENï¼Œå–å‰ {actual_n_fens} ä¸ª")
            valid_fens = valid_fens[:actual_n_fens]
        else:
            print(f"ğŸ“Š æ–‡ä»¶ä¸­æœ‰ {len(valid_fens)} ä¸ªæœ‰æ•ˆFENï¼Œå…¨éƒ¨ä½¿ç”¨")
        
        if len(valid_fens) == 0:
            raise HTTPException(
                status_code=400,
                detail=f"æ²¡æœ‰æœ‰æ•ˆçš„FENå­—ç¬¦ä¸²ã€‚æ— æ•ˆFENç¤ºä¾‹: {invalid_fens[:5]}"
            )
        
        # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        hooked_model = get_hooked_model(model_name)
        
        # æ£€æŸ¥ç¼“å­˜çš„transcoderså’Œlorsas
        cached_transcoders, cached_lorsas = get_cached_transcoders_and_lorsas(model_name)
        
        num_layers = 15
        if cached_transcoders is not None and cached_lorsas is not None:
            if len(cached_transcoders) == num_layers and len(cached_lorsas) == num_layers:
                print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„transcoderså’Œlorsas: {model_name}")
                transcoders = cached_transcoders
                lorsas = cached_lorsas
            else:
                # ç¼“å­˜ä¸å®Œæ•´ï¼Œéœ€è¦åŠ è½½
                print(f"âš ï¸ ç¼“å­˜ä¸å®Œæ•´ï¼Œé‡æ–°åŠ è½½: {model_name}")
                transcoders = None
                lorsas = None
        else:
            transcoders = None
            lorsas = None
        
        # å¦‚æœç¼“å­˜ä¸å¯ç”¨ï¼Œåˆ™åŠ è½½
        if transcoders is None or lorsas is None:
            base_path = "/inspire/hdd/global_user/hezhengfu-240208120186/rlin_projects/rlin_projects/chess-SAEs-N"
            if 'BT4' in model_name:
                tc_base_path = f"{base_path}/result_BT4/tc"
                lorsa_base_path = f"{base_path}/result_BT4/lorsa"
            else:
                raise ValueError("Unsupported Model!")
            
            transcoders = {}
            lorsas = []
            
            for layer in range(num_layers):
                # åŠ è½½Transcoder
                tc_path = f"{tc_base_path}/L{layer}"
                if os.path.exists(tc_path):
                    transcoders[layer] = SparseAutoEncoder.from_pretrained(
                        tc_path,
                        dtype=torch.float32,
                        device=device,
                    )
                else:
                    raise HTTPException(
                        status_code=404,
                        detail=f"Transcoder not found at {tc_path}"
                    )
                
                # åŠ è½½LoRSA
                lorsa_path = f"{lorsa_base_path}/L{layer}"
                if os.path.exists(lorsa_path):
                    lorsas.append(LowRankSparseAttention.from_pretrained(
                        lorsa_path,
                        device=device,
                    ))
                else:
                    raise HTTPException(
                        status_code=404,
                        detail=f"LoRSA not found at {lorsa_path}"
                    )
            
            # ç¼“å­˜åŠ è½½çš„transcoderså’Œlorsas
            if CIRCUITS_SERVICE_AVAILABLE and set_cached_models is not None:
                # éœ€è¦åˆ›å»ºreplacement_modelæ‰èƒ½ç¼“å­˜ï¼Œè¿™é‡Œå…ˆç¼“å­˜transcoderså’Œlorsas
                _global_transcoders_cache[model_name] = transcoders
                _global_lorsas_cache[model_name] = lorsas
                _global_hooked_models[model_name] = hooked_model
        
        # æ‰§è¡Œåˆ†æ
        print("=" * 80)
        print(f"ğŸ”¬ å¼€å§‹æ‰§è¡Œç‰¹å¾åˆ†æ")
        print(f"   - æˆ˜æœ¯FENæ•°é‡: {len(valid_fens)}æ¡")
        print(f"   - éšæœºFENæ•°é‡: {actual_n_fens}æ¡")
        print(f"   - æ¨¡å‹å±‚æ•°: {num_layers}å±‚ (0-{num_layers-1})")
        if parsed_specific_layer is not None:
            print(f"   âœ… æŒ‡å®šå±‚åˆ†æå·²å¯ç”¨:")
            print(f"      - å±‚å·: Layer {parsed_specific_layer}")
            print(f"      - Top K: {specific_layer_top_k}")
            if parsed_specific_layer < 0 or parsed_specific_layer >= num_layers:
                print(f"      âš ï¸ è­¦å‘Š: å±‚å· {parsed_specific_layer} è¶…å‡ºæœ‰æ•ˆèŒƒå›´!")
        else:
            print(f"   â„¹ï¸ æœªæŒ‡å®šå±‚ï¼Œå°†åªè¿”å›æ‰€æœ‰å±‚çš„Top Kç‰¹å¾")
        print("=" * 80)
        
        result = analyze_tactic_features(
            tactic_fens=valid_fens,
            model=hooked_model,
            lorsas=lorsas,
            transcoders=transcoders,
            n_random=actual_n_fens,
        )
        
        if "error" in result:
            raise HTTPException(status_code=500, detail=result["error"])
        
        # æ’åºå¹¶å–top k
        lorsa_diffs = sorted(result["lorsa_diffs"], key=lambda x: x[2], reverse=True)[:top_k_lorsa]
        tc_diffs = sorted(result["tc_diffs"], key=lambda x: x[2], reverse=True)[:top_k_tc]
        
        # æ ¼å¼åŒ–ç»“æœ
        def format_diff(diff_tuple):
            layer, feature, diff, p_random, p_tactic, kind = diff_tuple
            return {
                "layer": layer,
                "feature": feature,
                "diff": float(diff),
                "p_random": float(p_random),
                "p_tactic": float(p_tactic),
                "kind": kind
            }
        
        response_data = {
            "valid_tactic_fens": result["valid_tactic_fens"],
            "invalid_tactic_fens": result["invalid_tactic_fens"],
            "random_fens": result["random_fens"],
            "tactic_fens": result["tactic_fens"],
            "top_lorsa_features": [format_diff(d) for d in lorsa_diffs],
            "top_tc_features": [format_diff(d) for d in tc_diffs],
            "invalid_fens_sample": result.get("invalid_fens_list", [])
        }
        
        # å¦‚æœæŒ‡å®šäº†å±‚å·ï¼Œè¿”å›è¯¥å±‚çš„è¯¦ç»†ç‰¹å¾
        print("=" * 80)
        print(f"ğŸ” æ£€æŸ¥æ˜¯å¦éœ€è¦è¿”å›æŒ‡å®šå±‚ç‰¹å¾...")
        print(f"   - parsed_specific_layer: {parsed_specific_layer}")
        print(f"   - num_layers: {num_layers}")
        print(f"   - æ¡ä»¶æ£€æŸ¥: parsed_specific_layer is not None = {parsed_specific_layer is not None}")
        if parsed_specific_layer is not None:
            print(f"   - æ¡ä»¶æ£€æŸ¥: 0 <= {parsed_specific_layer} < {num_layers} = {0 <= parsed_specific_layer < num_layers}")
        
        if parsed_specific_layer is not None and 0 <= parsed_specific_layer < num_layers:
            print(f"âœ… å¼€å§‹ç­›é€‰ Layer {parsed_specific_layer} çš„ç‰¹å¾...")
            
            # æ‰“å°æ‰€æœ‰ç‰¹å¾çš„æ€»æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            total_lorsa_diffs = len(result["lorsa_diffs"])
            total_tc_diffs = len(result["tc_diffs"])
            print(f"   - æ€»LoRSAç‰¹å¾æ•°: {total_lorsa_diffs}")
            print(f"   - æ€»TCç‰¹å¾æ•°: {total_tc_diffs}")
            
            # ç­›é€‰å‡ºæŒ‡å®šå±‚çš„ç‰¹å¾
            specific_lorsa = [d for d in result["lorsa_diffs"] if d[0] == parsed_specific_layer]
            specific_tc = [d for d in result["tc_diffs"] if d[0] == parsed_specific_layer]
            
            print(f"ğŸ“Š Layer {parsed_specific_layer} ç‰¹å¾ç»Ÿè®¡:")
            print(f"   - LoRSAç‰¹å¾: {len(specific_lorsa)}ä¸ª")
            print(f"   - TCç‰¹å¾: {len(specific_tc)}ä¸ª")
            
            if len(specific_lorsa) == 0:
                print(f"   âš ï¸ è­¦å‘Š: Layer {parsed_specific_layer} æ²¡æœ‰æ‰¾åˆ°ä»»ä½• LoRSA ç‰¹å¾!")
            if len(specific_tc) == 0:
                print(f"   âš ï¸ è­¦å‘Š: Layer {parsed_specific_layer} æ²¡æœ‰æ‰¾åˆ°ä»»ä½• TC ç‰¹å¾!")
            
            # æ’åºå¹¶å–top k
            specific_lorsa_sorted = sorted(specific_lorsa, key=lambda x: x[2], reverse=True)[:specific_layer_top_k]
            specific_tc_sorted = sorted(specific_tc, key=lambda x: x[2], reverse=True)[:specific_layer_top_k]
            
            print(f"   - æ’åºåå–Top {specific_layer_top_k}:")
            print(f"     * LoRSA: {len(specific_lorsa_sorted)}ä¸ª")
            print(f"     * TC: {len(specific_tc_sorted)}ä¸ª")
            
            # æ‰“å°å‰3ä¸ªç‰¹å¾çš„è¯¦ç»†ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if len(specific_lorsa_sorted) > 0:
                print(f"   - LoRSA Top 3 ç‰¹å¾ç¤ºä¾‹:")
                for i, feat in enumerate(specific_lorsa_sorted[:3]):
                    print(f"     [{i+1}] Layer={feat[0]}, Feature={feat[1]}, Diff={feat[2]:.6f}")
            
            if len(specific_tc_sorted) > 0:
                print(f"   - TC Top 3 ç‰¹å¾ç¤ºä¾‹:")
                for i, feat in enumerate(specific_tc_sorted[:3]):
                    print(f"     [{i+1}] Layer={feat[0]}, Feature={feat[1]}, Diff={feat[2]:.6f}")
            
            response_data["specific_layer"] = parsed_specific_layer
            response_data["specific_layer_lorsa"] = [format_diff(d) for d in specific_lorsa_sorted]
            response_data["specific_layer_tc"] = [format_diff(d) for d in specific_tc_sorted]
            
            print(f"âœ… å·²æ·»åŠ æŒ‡å®šå±‚ç‰¹å¾åˆ°å“åº”æ•°æ®:")
            print(f"   - specific_layer: {response_data.get('specific_layer')}")
            print(f"   - specific_layer_lorsa: {len(response_data.get('specific_layer_lorsa', []))}ä¸ª")
            print(f"   - specific_layer_tc: {len(response_data.get('specific_layer_tc', []))}ä¸ª")
        elif parsed_specific_layer is not None:
            print(f"âŒ æŒ‡å®šçš„å±‚å· {parsed_specific_layer} è¶…å‡ºæœ‰æ•ˆèŒƒå›´ (0-{num_layers-1})")
            print(f"   å°†å¿½ç•¥æŒ‡å®šå±‚åˆ†æ")
        else:
            print(f"â„¹ï¸ æœªæŒ‡å®šå±‚å·ï¼Œè·³è¿‡æŒ‡å®šå±‚ç‰¹å¾ç­›é€‰")
        
        print("=" * 80)
        print(f"ğŸ“¤ å‡†å¤‡è¿”å›å“åº”æ•°æ®:")
        print(f"   - åŸºç¡€ç»Ÿè®¡: valid_tactic_fens={response_data.get('valid_tactic_fens')}, tactic_fens={response_data.get('tactic_fens')}")
        print(f"   - Top LoRSAç‰¹å¾: {len(response_data.get('top_lorsa_features', []))}ä¸ª")
        print(f"   - Top TCç‰¹å¾: {len(response_data.get('top_tc_features', []))}ä¸ª")
        print(f"   - æŒ‡å®šå±‚: {response_data.get('specific_layer', 'æœªæŒ‡å®š')}")
        if response_data.get('specific_layer') is not None:
            print(f"   - æŒ‡å®šå±‚LoRSA: {len(response_data.get('specific_layer_lorsa', []))}ä¸ª")
            print(f"   - æŒ‡å®šå±‚TC: {len(response_data.get('specific_layer_tc', []))}ä¸ª")
        print("=" * 80)
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")


@app.get("/tactic_features/status")
def tactic_features_status():
    """æ£€æŸ¥æˆ˜æœ¯ç‰¹å¾åˆ†ææœåŠ¡çš„çŠ¶æ€"""
    return {
        "available": TACTIC_FEATURES_AVAILABLE,
        "hooked_transformer_available": HOOKED_TRANSFORMER_AVAILABLE
    }

# æ·»åŠ CORSä¸­é—´ä»¶ - å¿…é¡»åœ¨æ‰€æœ‰è·¯ç”±å®šä¹‰ä¹‹å
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
